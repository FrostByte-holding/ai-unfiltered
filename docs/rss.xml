<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI Unfiltered</title>
        <link>https://ai-unfiltered.com/</link>
        <description>Chinese AI • Open Source • Security • Incidents. Signal, not noise.</description>
        <language>en-us</language>
        <lastBuildDate>Fri, 06 Feb 2026 20:37:35 +0000</lastBuildDate>
        <atom:link href="https://ai-unfiltered.com/rss.xml" rel="self" type="application/rss+xml"/>
        
        <item>
            <title>Elevated error rates on claude.ai</title>
            <link>https://status.claude.com/incidents/2gjynbb7ydph</link>
            <guid>https://status.claude.com/incidents/2gjynbb7ydph</guid>
            <pubDate>Fri, 06 Feb 2026 19:30:00 +0000</pubDate>
            <source url="https://status.claude.com/incidents/2gjynbb7ydph">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 6, 19:30 UTCResolved - This issue has been resolved.</description>
        </item>
        <item>
            <title>Incident with Pull Requests</title>
            <link>https://www.githubstatus.com/incidents/41mrvyqnmnmb</link>
            <guid>https://www.githubstatus.com/incidents/41mrvyqnmnmb</guid>
            <pubDate>Fri, 06 Feb 2026 18:36:53 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/41mrvyqnmnmb">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 6, 18:36 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Feb 6, 18:36 UTCUpdate - Some GitHub Mobile app users may be unable to add review comments...</description>
        </item>
        <item>
            <title>Moltbook was peak AI theater</title>
            <link>https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/</link>
            <guid>https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/</guid>
            <pubDate>Fri, 06 Feb 2026 16:38:11 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/">MIT Tech Review AI</source>
            <category>research</category>
            <description>For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website’s tagline puts it: “Where AI agents share, discuss, and upvote. Humans welcome to observe.” We observed! Launched on...</description>
        </item>
        <item>
            <title>China-Linked DKnife AitM Framework Targets Routers for Traffic Hijacking, Malware Delivery</title>
            <link>https://thehackernews.com/2026/02/china-linked-dknife-aitm-framework.html</link>
            <guid>https://thehackernews.com/2026/02/china-linked-dknife-aitm-framework.html</guid>
            <pubDate>Fri, 06 Feb 2026 14:56:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/china-linked-dknife-aitm-framework.html">The Hacker News</source>
            <category>security</category>
            <description>Cybersecurity researchers have taken the wraps off a gateway-monitoring and adversary-in-the-middle (AitM) framework dubbed DKnife that&#x27;s operated by China-nexus threat actors since at least 2019. The framework comprises seven Linux-based implants that are designed to perform deep packet...</description>
        </item>
        <item>
            <title>The Download: helping cancer survivors to give birth, and cleaning up Bangladesh’s garment industry</title>
            <link>https://www.technologyreview.com/2026/02/06/1132375/the-download-helping-cancer-survivors-to-give-birth-and-cleaning-up-bangladeshs-garment-industry/</link>
            <guid>https://www.technologyreview.com/2026/02/06/1132375/the-download-helping-cancer-survivors-to-give-birth-and-cleaning-up-bangladeshs-garment-industry/</guid>
            <pubDate>Fri, 06 Feb 2026 13:10:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/06/1132375/the-download-helping-cancer-survivors-to-give-birth-and-cleaning-up-bangladeshs-garment-industry/">MIT Tech Review AI</source>
            <category>research</category>
            <description>This is today&amp;#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&amp;#8217;s going on in the world of technology. An experimental surgery is helping cancer survivors give birth An experimental surgical procedure that’s helping people have babies after they’ve had...</description>
        </item>
        <item>
            <title>Asian State-Backed Group TGR-STA-1030 Breaches 70 Government, Infrastructure Entities</title>
            <link>https://thehackernews.com/2026/02/asian-state-backed-group-tgr-sta-1030.html</link>
            <guid>https://thehackernews.com/2026/02/asian-state-backed-group-tgr-sta-1030.html</guid>
            <pubDate>Fri, 06 Feb 2026 12:07:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/asian-state-backed-group-tgr-sta-1030.html">The Hacker News</source>
            <category>security</category>
            <description>A previously undocumented cyber espionage group operating from Asia broke into the networks of at least 70 government and critical infrastructure organizations across 37 countries over the past year, according to new findings from Palo Alto Networks Unit 42. In addition, the hacking crew has been...</description>
        </item>
        <item>
            <title>Flickr Security Incident Tied to Third-Party Email System</title>
            <link>https://www.securityweek.com/flickr-security-incident-tied-to-third-party-email-system/</link>
            <guid>https://www.securityweek.com/flickr-security-incident-tied-to-third-party-email-system/</guid>
            <pubDate>Fri, 06 Feb 2026 12:00:34 +0000</pubDate>
            <source url="https://www.securityweek.com/flickr-security-incident-tied-to-third-party-email-system/">Security Week</source>
            <category>security</category>
            <description>Potential breach at Flickr exposes usernames, email addresses, IP addresses, and activity data. The post Flickr Security Incident Tied to Third-Party Email System appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Incident with Copilot</title>
            <link>https://www.githubstatus.com/incidents/y7www8s68myy</link>
            <guid>https://www.githubstatus.com/incidents/y7www8s68myy</guid>
            <pubDate>Fri, 06 Feb 2026 11:58:04 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/y7www8s68myy">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 6, 11:58 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Feb 6, 11:58 UTCUpdate - Copilot is operating normally.Feb 6, 11:57 UTCUpdate - We have...</description>
        </item>
        <item>
            <title>How Samsung Knox Helps Stop Your Network Security Breach</title>
            <link>https://thehackernews.com/2026/02/how-samsung-knox-helps-stop-your-network-security-breach.html</link>
            <guid>https://thehackernews.com/2026/02/how-samsung-knox-helps-stop-your-network-security-breach.html</guid>
            <pubDate>Fri, 06 Feb 2026 10:30:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/how-samsung-knox-helps-stop-your-network-security-breach.html">The Hacker News</source>
            <category>security</category>
            <description>As you know, enterprise network security has undergone significant evolution over the past decade. Firewalls have become more intelligent, threat detection methods have advanced, and access controls are now more detailed. However (and it&amp;rsquo;s a big &amp;ldquo;however&amp;rdquo;), the increasing use of...</description>
        </item>
        <item>
            <title>An experimental surgery is helping cancer survivors give birth</title>
            <link>https://www.technologyreview.com/2026/02/06/1132319/experimental-surgery-colorectal-cancer-survivors-pregnant-birth/</link>
            <guid>https://www.technologyreview.com/2026/02/06/1132319/experimental-surgery-colorectal-cancer-survivors-pregnant-birth/</guid>
            <pubDate>Fri, 06 Feb 2026 10:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/06/1132319/experimental-surgery-colorectal-cancer-survivors-pregnant-birth/">MIT Tech Review AI</source>
            <category>research</category>
            <description>This week I want to tell you about an experimental surgical procedure that’s helping people have babies. Specifically, it’s helping people who have had treatment for bowel or rectal cancer. Radiation and chemo can have pretty damaging side effects that mess up the uterus and ovaries. Surgeons are...</description>
        </item>
        <item>
            <title>Compromised dYdX npm and PyPI Packages Deliver Wallet Stealers and RAT Malware</title>
            <link>https://thehackernews.com/2026/02/compromised-dydx-npm-and-pypi-packages.html</link>
            <guid>https://thehackernews.com/2026/02/compromised-dydx-npm-and-pypi-packages.html</guid>
            <pubDate>Fri, 06 Feb 2026 08:40:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/compromised-dydx-npm-and-pypi-packages.html">The Hacker News</source>
            <category>security</category>
            <description>Cybersecurity researchers have discovered a new supply chain attack in which legitimate packages on npm and the Python Package Index (PyPI) repository have been compromised to push malicious versions to facilitate wallet credential theft and remote code execution. The compromised versions of the...</description>
        </item>
        <item>
            <title>China’s First 30,000-Card National Supercomputing Internet Core Node Enters Trial Operation</title>
            <link>https://pandaily.com/china-s-first-30-000-card-national-supercomputing-internet-core-node-enters-trial-operation</link>
            <guid>https://pandaily.com/china-s-first-30-000-card-national-supercomputing-internet-core-node-enters-trial-operation</guid>
            <pubDate>Fri, 06 Feb 2026 08:21:04 +0000</pubDate>
            <source url="https://pandaily.com/china-s-first-30-000-card-national-supercomputing-internet-core-node-enters-trial-operation">Pandaily</source>
            <category>chinese-ai</category>
            <description>China has put its first operational 30,000-card national supercomputing internet core node into trial operation, marking a major milestone in domestically built AI computing infrastructure.</description>
        </item>
        <item>
            <title>5 Bills to Boost Energy Sector Cyber Defenses Clear House Panel</title>
            <link>https://www.securityweek.com/5-bills-to-boost-energy-sector-cyber-defenses-clear-house-panel/</link>
            <guid>https://www.securityweek.com/5-bills-to-boost-energy-sector-cyber-defenses-clear-house-panel/</guid>
            <pubDate>Fri, 06 Feb 2026 08:19:03 +0000</pubDate>
            <source url="https://www.securityweek.com/5-bills-to-boost-energy-sector-cyber-defenses-clear-house-panel/">Security Week</source>
            <category>security</category>
            <description>The news comes after the Department of Energy conducted its annual Liberty Eclipse cybersecurity exercise. The post 5 Bills to Boost Energy Sector Cyber Defenses Clear House Panel appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>NIO: Operating Profit to Reach at Least $100 Million in Q4 2025</title>
            <link>https://pandaily.com/nio-operating-profit-to-reach-at-least-100-million-in-q4-2025</link>
            <guid>https://pandaily.com/nio-operating-profit-to-reach-at-least-100-million-in-q4-2025</guid>
            <pubDate>Fri, 06 Feb 2026 08:15:46 +0000</pubDate>
            <source url="https://pandaily.com/nio-operating-profit-to-reach-at-least-100-million-in-q4-2025">Pandaily</source>
            <category>chinese-ai</category>
            <description>On February 5, NIO, founded in 2014, announced that it has finally turned profitable, fulfilling the long-standing commitment made by its founder William Li. N...</description>
        </item>
        <item>
            <title>Pony.ai and Moore Threads Forge Strategic Partnership to Accelerate L4 Autonomous Driving</title>
            <link>https://pandaily.com/pony-ai-and-moore-threads-forge-strategic-partnership-to-accelerate-l4-autonomous-driving</link>
            <guid>https://pandaily.com/pony-ai-and-moore-threads-forge-strategic-partnership-to-accelerate-l4-autonomous-driving</guid>
            <pubDate>Fri, 06 Feb 2026 08:13:30 +0000</pubDate>
            <source url="https://pandaily.com/pony-ai-and-moore-threads-forge-strategic-partnership-to-accelerate-l4-autonomous-driving">Pandaily</source>
            <category>chinese-ai</category>
            <description>Pony.ai and Moore Threads have formed a strategic partnership to combine China’s domestically developed GPU computing power with advanced autonomous driving algorithms, accelerating L4 autonomous driving deployment and commercialization.</description>
        </item>
        <item>
            <title>Eradicating trivial vulnerabilities, at scale</title>
            <link>https://www.ncsc.gov.uk/blog-post/eradicating-trivial-vulnerabilities-at-scale</link>
            <guid>https://www.ncsc.gov.uk/blog-post/eradicating-trivial-vulnerabilities-at-scale</guid>
            <pubDate>Fri, 06 Feb 2026 08:11:58 +0000</pubDate>
            <source url="https://www.ncsc.gov.uk/blog-post/eradicating-trivial-vulnerabilities-at-scale">NCSC UK</source>
            <category>security</category>
            <description>A new NCSC research paper aims to reduce the presence of ‘unforgivable’ vulnerabilities.</description>
        </item>
        <item>
            <title>Xpeng GX Flagship SUV Officially Announced and Begins L4 Autonomous Driving Open Testing</title>
            <link>https://pandaily.com/xpeng-gx-flagship-suv-officially-announced-and-begins-l4-autonomous-driving-open-testing</link>
            <guid>https://pandaily.com/xpeng-gx-flagship-suv-officially-announced-and-begins-l4-autonomous-driving-open-testing</guid>
            <pubDate>Fri, 06 Feb 2026 08:11:48 +0000</pubDate>
            <source url="https://pandaily.com/xpeng-gx-flagship-suv-officially-announced-and-begins-l4-autonomous-driving-open-testing">Pandaily</source>
            <category>chinese-ai</category>
            <description>Xpeng has officially unveiled its flagship six‑seat SUV, the Xpeng GX, which features advanced SEPA 3.0 AI architecture and has begun open testing of L4 autonomous driving.</description>
        </item>
        <item>
            <title>Thanking the vulnerability research community with NCSC Challenge Coins</title>
            <link>https://www.ncsc.gov.uk/blog-post/thanking-vulnerability-research-community-ncsc-challenge-coins</link>
            <guid>https://www.ncsc.gov.uk/blog-post/thanking-vulnerability-research-community-ncsc-challenge-coins</guid>
            <pubDate>Fri, 06 Feb 2026 08:11:32 +0000</pubDate>
            <source url="https://www.ncsc.gov.uk/blog-post/thanking-vulnerability-research-community-ncsc-challenge-coins">NCSC UK</source>
            <category>security</category>
            <description>Reflecting on the positive impact of the Vulnerability Reporting Service – and introducing something new for selected contributors.</description>
        </item>
        <item>
            <title>Qwen App Launches “Largest Free Order” Campaign</title>
            <link>https://pandaily.com/qwen-app-launches-largest-free-order-campaign</link>
            <guid>https://pandaily.com/qwen-app-launches-largest-free-order-campaign</guid>
            <pubDate>Fri, 06 Feb 2026 08:10:22 +0000</pubDate>
            <source url="https://pandaily.com/qwen-app-launches-largest-free-order-campaign">Pandaily</source>
            <category>chinese-ai</category>
            <description>Alibaba’s Qwen App is offering a $430 million Lunar New Year “mega free order” campaign featuring free milk tea and shopping perks powered by AI.</description>
        </item>
        <item>
            <title>Critical SmarterMail Vulnerability Exploited in Ransomware Attacks</title>
            <link>https://www.securityweek.com/critical-smartermail-vulnerability-exploited-in-ransomware-attacks/</link>
            <guid>https://www.securityweek.com/critical-smartermail-vulnerability-exploited-in-ransomware-attacks/</guid>
            <pubDate>Fri, 06 Feb 2026 07:50:23 +0000</pubDate>
            <source url="https://www.securityweek.com/critical-smartermail-vulnerability-exploited-in-ransomware-attacks/">Security Week</source>
            <category>security</category>
            <description>The security defect allows unauthenticated attackers to execute arbitrary code remotely via malicious HTTP requests. The post Critical SmarterMail Vulnerability Exploited in Ransomware Attacks appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Claude Opus 4.6 Finds 500+ High-Severity Flaws Across Major Open-Source Libraries</title>
            <link>https://thehackernews.com/2026/02/claude-opus-46-finds-500-high-severity.html</link>
            <guid>https://thehackernews.com/2026/02/claude-opus-46-finds-500-high-severity.html</guid>
            <pubDate>Fri, 06 Feb 2026 05:49:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/claude-opus-46-finds-500-high-severity.html">The Hacker News</source>
            <category>security</category>
            <description>Artificial intelligence (AI) company Anthropic revealed that its latest large language model (LLM), Claude Opus 4.6, has found more than 500 previously unknown high-severity security flaws in open-source libraries, including Ghostscript, OpenSC, and CGIF. Claude Opus 4.6, which was launched on...</description>
        </item>
        <item>
            <title>Concerns Raised Over CISA’s Silent Ransomware Updates in KEV Catalog</title>
            <link>https://www.securityweek.com/questions-raised-over-cisas-silent-ransomware-updates-in-kev-catalog/</link>
            <guid>https://www.securityweek.com/questions-raised-over-cisas-silent-ransomware-updates-in-kev-catalog/</guid>
            <pubDate>Fri, 06 Feb 2026 05:28:39 +0000</pubDate>
            <source url="https://www.securityweek.com/questions-raised-over-cisas-silent-ransomware-updates-in-kev-catalog/">Security Week</source>
            <category>security</category>
            <description>CISA updated 59 KEV entries in 2025 to specify that the vulnerabilities have been exploited in ransomware attacks. The post Concerns Raised Over CISA&amp;#8217;s Silent Ransomware Updates in KEV Catalog appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Artificial Intelligence as Strange Intelligence: Against Linear Models of Intelligence</title>
            <link>https://arxiv.org/abs/2602.04986</link>
            <guid>https://arxiv.org/abs/2602.04986</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04986">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.04986v1 Announce Type: new Abstract: We endorse and expand upon Susan Schneider&#x27;s critique of the linear model of AI progress and introduce two novel concepts: &quot;familiar intelligence&quot; and &quot;strange intelligence&quot;. AI intelligence is likely to be strange intelligence, defying familiar...</description>
        </item>
        <item>
            <title>DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search</title>
            <link>https://arxiv.org/abs/2602.05014</link>
            <guid>https://arxiv.org/abs/2602.05014</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05014">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.05014v1 Announce Type: new Abstract: With the rapid progress of tool-using and agentic large language models (LLMs), Retrieval-Augmented Generation (RAG) is evolving from one-shot, passive retrieval into multi-turn, decision-driven evidence acquisition. Despite strong results in...</description>
        </item>
        <item>
            <title>MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation</title>
            <link>https://arxiv.org/abs/2602.05048</link>
            <guid>https://arxiv.org/abs/2602.05048</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05048">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.05048v1 Announce Type: new Abstract: Joint planning through language-based interactions is a key area of human-AI teaming. Planning problems in the open world often involve various aspects of incomplete information and unknowns, e.g., objects involved, human goals/intents -- thus leading...</description>
        </item>
        <item>
            <title>Evaluating Large Language Models on Solved and Unsolved Problems in Graph Theory: Implications for Computing Education</title>
            <link>https://arxiv.org/abs/2602.05059</link>
            <guid>https://arxiv.org/abs/2602.05059</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05059">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.05059v1 Announce Type: new Abstract: Large Language Models are increasingly used by students to explore advanced material in computer science, including graph theory. As these tools become integrated into undergraduate and graduate coursework, it is important to understand how reliably...</description>
        </item>
        <item>
            <title>Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents</title>
            <link>https://arxiv.org/abs/2602.05073</link>
            <guid>https://arxiv.org/abs/2602.05073</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05073">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.05073v1 Announce Type: new Abstract: Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on...</description>
        </item>
        <item>
            <title>Denoising diffusion networks for normative modeling in neuroimaging</title>
            <link>https://arxiv.org/abs/2602.04886</link>
            <guid>https://arxiv.org/abs/2602.04886</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04886">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.04886v1 Announce Type: new Abstract: Normative modeling estimates reference distributions of biological measures conditional on covariates, enabling centiles and clinically interpretable deviation scores to be derived. Most neuroimaging pipelines fit one model per imaging-derived...</description>
        </item>
        <item>
            <title>A Causal Perspective for Enhancing Jailbreak Attack and Defense</title>
            <link>https://arxiv.org/abs/2602.04893</link>
            <guid>https://arxiv.org/abs/2602.04893</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04893">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.04893v1 Announce Type: new Abstract: Uncovering the mechanisms behind &quot;jailbreaks&quot; in large language models (LLMs) is crucial for enhancing their safety and reliability, yet these mechanisms remain poorly understood. Existing studies predominantly analyze jailbreak prompts by probing...</description>
        </item>
        <item>
            <title>Momentum Attention: The Physics of In-Context Learning and Spectral Forensics for Mechanistic Interpretability</title>
            <link>https://arxiv.org/abs/2602.04902</link>
            <guid>https://arxiv.org/abs/2602.04902</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04902">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.04902v1 Announce Type: new Abstract: The Mechanistic Interpretability (MI) program has mapped the Transformer as a precise computational graph. We extend this graph with a conservation law and time-varying AC dynamics, viewing it as a physical circuit. We introduce Momentum Attention, a...</description>
        </item>
        <item>
            <title>Mind the Performance Gap: Capability-Behavior Trade-offs in Feature Steering</title>
            <link>https://arxiv.org/abs/2602.04903</link>
            <guid>https://arxiv.org/abs/2602.04903</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04903">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.04903v1 Announce Type: new Abstract: Feature steering has emerged as a promising approach for controlling LLM behavior through direct manipulation of internal representations, offering advantages over prompt engineering. However, its practical effectiveness in real-world applications...</description>
        </item>
        <item>
            <title>DCER: Dual-Stage Compression and Energy-Based Reconstruction</title>
            <link>https://arxiv.org/abs/2602.04904</link>
            <guid>https://arxiv.org/abs/2602.04904</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04904">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.04904v1 Announce Type: new Abstract: Multimodal fusion faces two robustness challenges: noisy inputs degrade representation quality, and missing modalities cause prediction failures. We propose DCER, a unified framework addressing both challenges through dual-stage compression and...</description>
        </item>
        <item>
            <title>BioACE: An Automated Framework for Biomedical Answer and Citation Evaluations</title>
            <link>https://arxiv.org/abs/2602.04982</link>
            <guid>https://arxiv.org/abs/2602.04982</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04982">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.04982v1 Announce Type: new Abstract: With the increasing use of large language models (LLMs) for generating answers to biomedical questions, it is crucial to evaluate the quality of the generated answers and the references provided to support the facts in the generated answers....</description>
        </item>
        <item>
            <title>CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System</title>
            <link>https://arxiv.org/abs/2602.05004</link>
            <guid>https://arxiv.org/abs/2602.05004</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05004">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.05004v1 Announce Type: new Abstract: Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict...</description>
        </item>
        <item>
            <title>Capacity Constraints and the Multilingual Penalty for Lexical Disambiguation</title>
            <link>https://arxiv.org/abs/2602.05035</link>
            <guid>https://arxiv.org/abs/2602.05035</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05035">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.05035v1 Announce Type: new Abstract: Multilingual language models (LMs) sometimes under-perform their monolingual counterparts, possibly due to capacity limitations. We quantify this ``multilingual penalty&#x27;&#x27; for lexical disambiguation--a task requiring precise semantic representations...</description>
        </item>
        <item>
            <title>Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories</title>
            <link>https://arxiv.org/abs/2602.05085</link>
            <guid>https://arxiv.org/abs/2602.05085</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05085">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.05085v1 Announce Type: new Abstract: In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks...</description>
        </item>
        <item>
            <title>Data Kernel Perspective Space Performance Guarantees for Synthetic Data from Transformer Models</title>
            <link>https://arxiv.org/abs/2602.05106</link>
            <guid>https://arxiv.org/abs/2602.05106</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05106">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.05106v1 Announce Type: new Abstract: Scarcity of labeled training data remains the long pole in the tent for building performant language technology and generative AI models. Transformer models -- particularly LLMs -- are increasingly being used to mitigate the data scarcity problem via...</description>
        </item>
        <item>
            <title>[AINews] OpenAI and Anthropic go to war: Claude Opus 4.6 vs GPT 5.3 Codex</title>
            <link>https://www.latent.space/p/ainews-openai-and-anthropic-go-to</link>
            <guid>https://www.latent.space/p/ainews-openai-and-anthropic-go-to</guid>
            <pubDate>Fri, 06 Feb 2026 04:10:33 +0000</pubDate>
            <source url="https://www.latent.space/p/ainews-openai-and-anthropic-go-to">Latent Space</source>
            <category>open-source</category>
            <description>The battle of the SOTA Coding Models steps up a notch</description>
        </item>
        <item>
            <title>Zscaler Acquires Browser Security Firm SquareX</title>
            <link>https://www.securityweek.com/zscaler-acquires-browser-security-firm-squarex/</link>
            <guid>https://www.securityweek.com/zscaler-acquires-browser-security-firm-squarex/</guid>
            <pubDate>Fri, 06 Feb 2026 02:48:22 +0000</pubDate>
            <source url="https://www.securityweek.com/zscaler-acquires-browser-security-firm-squarex/">Security Week</source>
            <category>security</category>
            <description>Zscaler says the acquisition will allow customers to embed lightweight extensions into any browser, providing increased security and eliminating the need for third-party browsers. The post Zscaler Acquires Browser Security Firm SquareX appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>The First Mechanistic Interpretability Frontier Lab — Myra Deng &amp; Mark Bissell of Goodfire AI</title>
            <link>https://www.latent.space/p/goodfire</link>
            <guid>https://www.latent.space/p/goodfire</guid>
            <pubDate>Thu, 05 Feb 2026 20:45:01 +0000</pubDate>
            <source url="https://www.latent.space/p/goodfire">Latent Space</source>
            <category>open-source</category>
            <description>Tickets for AIE Miami and AIE Europe are on sale now!</description>
        </item>
        <item>
            <title>RISE-Video: Can Video Generators Decode Implicit World Rules?</title>
            <link>https://tldr.takara.ai/p/2602.05986</link>
            <guid>https://tldr.takara.ai/p/2602.05986</guid>
            <pubDate>Thu, 05 Feb 2026 18:36:10 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.05986">HF Daily Papers</source>
            <category>open-source</category>
            <description>While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video...</description>
        </item>
        <item>
            <title>Better Source, Better Flow: Learning Condition-Dependent Source Distribution for Flow Matching</title>
            <link>https://tldr.takara.ai/p/2602.05951</link>
            <guid>https://tldr.takara.ai/p/2602.05951</guid>
            <pubDate>Thu, 05 Feb 2026 18:08:20 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.05951">HF Daily Papers</source>
            <category>open-source</category>
            <description>Flow matching has recently emerged as a promising alternative to diffusion-based generative models, particularly for text-to-image generation. Despite its flexibility in allowing arbitrary source distributions, most existing approaches rely on a standard Gaussian distribution, a choice inherited...</description>
        </item>
        <item>
            <title>Regularized Calibration with Successive Rounding for Post-Training Quantization</title>
            <link>https://tldr.takara.ai/p/2602.05902</link>
            <guid>https://tldr.takara.ai/p/2602.05902</guid>
            <pubDate>Thu, 05 Feb 2026 17:18:02 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.05902">HF Daily Papers</source>
            <category>open-source</category>
            <description>Large language models (LLMs) deliver robust performance across diverse applications, yet their deployment often faces challenges due to the memory and latency costs of storing and accessing billions of parameters. Post-training quantization (PTQ) enables efficient inference by mapping pretrained...</description>
        </item>
        <item>
            <title>Agent2Agent Threats in Safety-Critical LLM Assistants: A Human-Centric Taxonomy</title>
            <link>https://tldr.takara.ai/p/2602.05877</link>
            <guid>https://tldr.takara.ai/p/2602.05877</guid>
            <pubDate>Thu, 05 Feb 2026 16:53:41 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.05877">HF Daily Papers</source>
            <category>open-source</category>
            <description>The integration of Large Language Model (LLM)-based conversational agents into vehicles creates novel security challenges at the intersection of agentic AI, automotive safety, and inter-agent communication. As these intelligent assistants coordinate with external services via protocols such as...</description>
        </item>
        <item>
            <title>Introducing SyGra Studio</title>
            <link>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</link>
            <guid>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</guid>
            <pubDate>Thu, 05 Feb 2026 16:52:28 +0000</pubDate>
            <source url="https://huggingface.co/blog/ServiceNow-AI/sygra-studio">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
        <item>
            <title>DLM-Scope: Mechanistic Interpretability of Diffusion Language Models via Sparse Autoencoders</title>
            <link>https://tldr.takara.ai/p/2602.05859</link>
            <guid>https://tldr.takara.ai/p/2602.05859</guid>
            <pubDate>Thu, 05 Feb 2026 16:41:25 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.05859">HF Daily Papers</source>
            <category>open-source</category>
            <description>Sparse autoencoders (SAEs) have become a standard tool for mechanistic interpretability in autoregressive large language models (LLMs), enabling researchers to extract sparse, human-interpretable features and intervene on model behavior. Recently, as diffusion language models (DLMs) have become an...</description>
        </item>
        <item>
            <title>Conversation compaction degraded on claude.ai</title>
            <link>https://status.claude.com/incidents/plhlsqf2svt6</link>
            <guid>https://status.claude.com/incidents/plhlsqf2svt6</guid>
            <pubDate>Thu, 05 Feb 2026 15:58:12 +0000</pubDate>
            <source url="https://status.claude.com/incidents/plhlsqf2svt6">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 5, 15:58 UTCIdentified - The issue has been identified and a fix is being implemented.</description>
        </item>
        <item>
            <title>Consolidating systems for AI with iPaaS</title>
            <link>https://www.technologyreview.com/2026/02/05/1132200/consolidating-systems-for-ai-with-ipaas/</link>
            <guid>https://www.technologyreview.com/2026/02/05/1132200/consolidating-systems-for-ai-with-ipaas/</guid>
            <pubDate>Thu, 05 Feb 2026 15:20:37 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/05/1132200/consolidating-systems-for-ai-with-ipaas/">MIT Tech Review AI</source>
            <category>research</category>
            <description>For decades, enterprises reacted to shifting business pressures with stopgap technology solutions. To rein in rising infrastructure costs, they adopted cloud services that could scale on demand. When customers shifted their lives onto smartphones, companies rolled out mobile apps to keep pace. And...</description>
        </item>
        <item>
            <title>The Download: attempting to track AI, and the next generation of nuclear power</title>
            <link>https://www.technologyreview.com/2026/02/05/1132270/the-download-attempting-to-track-ai-and-the-next-generation-of-nuclear-power/</link>
            <guid>https://www.technologyreview.com/2026/02/05/1132270/the-download-attempting-to-track-ai-and-the-next-generation-of-nuclear-power/</guid>
            <pubDate>Thu, 05 Feb 2026 13:10:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/05/1132270/the-download-attempting-to-track-ai-and-the-next-generation-of-nuclear-power/">MIT Tech Review AI</source>
            <category>research</category>
            <description>This is today&amp;#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&amp;#8217;s going on in the world of technology. This is the most misunderstood graph in AI Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds...</description>
        </item>
        <item>
            <title>[AINews] ElevenLabs $500m Series D at $11B, Cerebras $1B Series H at $23B, Vibe Coding -&gt; Agentic Engineering</title>
            <link>https://www.latent.space/p/ainews-elevenlabs-500m-series-d-at</link>
            <guid>https://www.latent.space/p/ainews-elevenlabs-500m-series-d-at</guid>
            <pubDate>Thu, 05 Feb 2026 08:26:43 +0000</pubDate>
            <source url="https://www.latent.space/p/ainews-elevenlabs-500m-series-d-at">Latent Space</source>
            <category>open-source</category>
            <description>SOTA Audio models, Fast Chips, and Koding Agents are all you need.</description>
        </item>
    </channel>
</rss>

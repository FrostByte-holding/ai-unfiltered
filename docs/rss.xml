<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI Unfiltered</title>
        <link>https://ai-unfiltered.com/</link>
        <description>Chinese AI • Open Source • Security • Incidents. Signal, not noise.</description>
        <language>en-us</language>
        <lastBuildDate>Fri, 13 Feb 2026 08:48:58 +0000</lastBuildDate>
        <atom:link href="https://ai-unfiltered.com/rss.xml" rel="self" type="application/rss+xml"/>
        
        <item>
            <title>[AINews] new Gemini 3 Deep Think, Anthropic $30B @ $380B, GPT-5.3-Codex Spark, MiniMax M2.5</title>
            <link>https://www.latent.space/p/ainews-new-gemini-3-deep-think-anthropic</link>
            <guid>https://www.latent.space/p/ainews-new-gemini-3-deep-think-anthropic</guid>
            <pubDate>Fri, 13 Feb 2026 08:29:19 +0000</pubDate>
            <source url="https://www.latent.space/p/ainews-new-gemini-3-deep-think-anthropic">Latent Space</source>
            <category>open-source</category>
            <description>There&#x27;s too much going on!</description>
        </item>
        <item>
            <title>High errors with image generation</title>
            <link>https://status.openai.com//incidents/01KHB0X2GYKJEW6WV3G1SFYPCE</link>
            <guid>https://status.openai.com//incidents/01KHB0X2GYKJEW6WV3G1SFYPCE</guid>
            <pubDate>Fri, 13 Feb 2026 08:22:57 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KHB0X2GYKJEW6WV3G1SFYPCE">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: MonitoringWe have applied the mitigation and are monitoring the recovery.Affected components Images (Degraded performance) Image Generation (Degraded performance)</description>
        </item>
        <item>
            <title>Chrome 145 Patches 11 Vulnerabilities</title>
            <link>https://www.securityweek.com/chrome-145-patches-11-vulnerabilities/</link>
            <guid>https://www.securityweek.com/chrome-145-patches-11-vulnerabilities/</guid>
            <pubDate>Fri, 13 Feb 2026 08:18:22 +0000</pubDate>
            <source url="https://www.securityweek.com/chrome-145-patches-11-vulnerabilities/">Security Week</source>
            <category>security</category>
            <description>Three of the security defects are high-severity flaws, two of which were found and reported by Google. The post Chrome 145 Patches 11 Vulnerabilities appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Haizhi Technology Lists on HKEX: +250% on Debut, “Graph‑Model Fusion” Tackles LLM Hallucination</title>
            <link>https://pandaily.com/haizhi-technology-lists-on-hkex-250-on-debut-graph-model-fusion-tackles-llm-hallucination</link>
            <guid>https://pandaily.com/haizhi-technology-lists-on-hkex-250-on-debut-graph-model-fusion-tackles-llm-hallucination</guid>
            <pubDate>Fri, 13 Feb 2026 07:12:10 +0000</pubDate>
            <source url="https://pandaily.com/haizhi-technology-lists-on-hkex-250-on-debut-graph-model-fusion-tackles-llm-hallucination">Pandaily</source>
            <category>chinese-ai</category>
            <description>Haizhi debuted on HKEX with +250% first‑day gain, HK$38B cap, 5,065x oversubscription — as the world’s first public company tackling LLM hallucination via graph‑model fusion, despite still being unprofitable .</description>
        </item>
        <item>
            <title>Zhipu Surges to Become World’s Most Valuable LLM Company, Adds Second Sponsor for A‑Share Listing</title>
            <link>https://pandaily.com/zhipu-surges-to-become-world-s-most-valuable-llm-company-adds-second-sponsor-for-a-share-listing</link>
            <guid>https://pandaily.com/zhipu-surges-to-become-world-s-most-valuable-llm-company-adds-second-sponsor-for-a-share-listing</guid>
            <pubDate>Fri, 13 Feb 2026 07:10:21 +0000</pubDate>
            <source url="https://pandaily.com/zhipu-surges-to-become-world-s-most-valuable-llm-company-adds-second-sponsor-for-a-share-listing">Pandaily</source>
            <category>chinese-ai</category>
            <description>Zhipu open‑sourced GLM‑5 (“Pony Alpha”), the first open‑source “system architect” model matching Claude Opus 4.5 in coding — while hiking Coding Plan prices 30‑60%, signaling the end of AI price wars .</description>
        </item>
        <item>
            <title>3D AI Chip Startup Suanmiao Tech Raises Nearly RMB 1 Billion in Two Rounds</title>
            <link>https://pandaily.com/3-d-ai-chip-startup-suanmiao-tech-raises-nearly-rmb-1-billion-in-two-rounds</link>
            <guid>https://pandaily.com/3-d-ai-chip-startup-suanmiao-tech-raises-nearly-rmb-1-billion-in-two-rounds</guid>
            <pubDate>Fri, 13 Feb 2026 07:05:36 +0000</pubDate>
            <source url="https://pandaily.com/3-d-ai-chip-startup-suanmiao-tech-raises-nearly-rmb-1-billion-in-two-rounds">Pandaily</source>
            <category>chinese-ai</category>
            <description>3D AI chip startup Suanmiao raised nearly RMB 1B in Pre‑A/Pre‑A1 rounds to mass‑produce 100% domestic 3D inference chips, breaking the memory wall with 3D stacking — a legacy from its Ethereum mining dominance .</description>
        </item>
        <item>
            <title>MiniMax Unveils M2.5: $1/HR “Full‑Stack AI Employee” Rivals Claude Opus 4.6</title>
            <link>https://pandaily.com/mini-max-unveils-m2-5-1-hr-full-stack-ai-employee-rivals-claude-opus-4-6</link>
            <guid>https://pandaily.com/mini-max-unveils-m2-5-1-hr-full-stack-ai-employee-rivals-claude-opus-4-6</guid>
            <pubDate>Fri, 13 Feb 2026 07:03:19 +0000</pubDate>
            <source url="https://pandaily.com/mini-max-unveils-m2-5-1-hr-full-stack-ai-employee-rivals-claude-opus-4-6">Pandaily</source>
            <category>chinese-ai</category>
            <description>MiniMax open‑sourced M2.5, a 10B‑activated‑parameter coding model scoring 80.2% on SWE‑Bench Verified, with 100 TPS inference at $1/hr — driving 10K+ Agents built in 24 hours .</description>
        </item>
        <item>
            <title>AgiBot‘s Data Arm Maniformer Secures Hundreds of Millions in Seed &amp; Angel Funding</title>
            <link>https://pandaily.com/agi-bot-s-data-arm-maniformer-secures-hundreds-of-millions-in-seed-and-angel-funding</link>
            <guid>https://pandaily.com/agi-bot-s-data-arm-maniformer-secures-hundreds-of-millions-in-seed-and-angel-funding</guid>
            <pubDate>Fri, 13 Feb 2026 06:59:23 +0000</pubDate>
            <source url="https://pandaily.com/agi-bot-s-data-arm-maniformer-secures-hundreds-of-millions-in-seed-and-angel-funding">Pandaily</source>
            <category>chinese-ai</category>
            <description>AgiBot’s data arm Maniformer raised hundreds of millions of yuan in seed &amp; angel rounds led by Sequoia China to tackle the 5M+ hour embodied AI data gap, positioning itself as the industry’s data infrastructure backbone .</description>
        </item>
        <item>
            <title>China Revives Tianfu Cup Hacking Contest Under Increased Secrecy</title>
            <link>https://www.securityweek.com/china-revives-tianfu-cup-hacking-contest-under-increased-secrecy/</link>
            <guid>https://www.securityweek.com/china-revives-tianfu-cup-hacking-contest-under-increased-secrecy/</guid>
            <pubDate>Fri, 13 Feb 2026 06:49:26 +0000</pubDate>
            <source url="https://www.securityweek.com/china-revives-tianfu-cup-hacking-contest-under-increased-secrecy/">Security Week</source>
            <category>security</category>
            <description>Rewards for exploits are reportedly much smaller than in the contest’s glory days. The post China Revives Tianfu Cup Hacking Contest Under Increased Secrecy appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Explaining AI Without Code: A User Study on Explainable AI</title>
            <link>https://arxiv.org/abs/2602.11159</link>
            <guid>https://arxiv.org/abs/2602.11159</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11159">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.11159v1 Announce Type: new Abstract: The increasing use of Machine Learning (ML) in sensitive domains such as healthcare, finance, and public policy has raised concerns about the transparency of automated decisions. Explainable AI (XAI) addresses this by clarifying how models generate...</description>
        </item>
        <item>
            <title>Latent Generative Solvers for Generalizable Long-Term Physics Simulation</title>
            <link>https://arxiv.org/abs/2602.11229</link>
            <guid>https://arxiv.org/abs/2602.11229</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11229">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.11229v1 Announce Type: new Abstract: We study long-horizon surrogate simulation across heterogeneous PDE systems. We introduce Latent Generative Solvers (LGS), a two-stage framework that (i) maps diverse PDE states into a shared latent physics space with a pretrained VAE, and (ii) learns...</description>
        </item>
        <item>
            <title>On Decision-Valued Maps and Representational Dependence</title>
            <link>https://arxiv.org/abs/2602.11295</link>
            <guid>https://arxiv.org/abs/2602.11295</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11295">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.11295v1 Announce Type: new Abstract: A computational engine applied to different representations of the same data can produce different discrete outcomes, with some representations preserving the result and others changing it entirely. A decision-valued map records which representations...</description>
        </item>
        <item>
            <title>Voxtral Realtime</title>
            <link>https://arxiv.org/abs/2602.11298</link>
            <guid>https://arxiv.org/abs/2602.11298</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11298">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.11298v1 Announce Type: new Abstract: We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency. Unlike approaches that adapt offline models through chunking or sliding windows, Voxtral Realtime...</description>
        </item>
        <item>
            <title>The PBSAI Governance Ecosystem: A Multi-Agent AI Reference Architecture for Securing Enterprise AI Estates</title>
            <link>https://arxiv.org/abs/2602.11301</link>
            <guid>https://arxiv.org/abs/2602.11301</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11301">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.11301v1 Announce Type: new Abstract: Enterprises are rapidly deploying large language models, retrieval augmented generation pipelines, and tool using agents into production, often on shared high performance computing clusters and cloud accelerator platforms that also support defensive...</description>
        </item>
        <item>
            <title>Automated Optimization Modeling via a Localizable Error-Driven Perspective</title>
            <link>https://arxiv.org/abs/2602.11164</link>
            <guid>https://arxiv.org/abs/2602.11164</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11164">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.11164v1 Announce Type: new Abstract: Automated optimization modeling via Large Language Models (LLMs) has emerged as a promising approach to assist complex human decision-making. While post-training has become a pivotal technique to enhance LLMs&#x27; capabilities in this domain, its...</description>
        </item>
        <item>
            <title>KBVQ-MoE: KLT-guided SVD with Bias-Corrected Vector Quantization for MoE Large Language Models</title>
            <link>https://arxiv.org/abs/2602.11184</link>
            <guid>https://arxiv.org/abs/2602.11184</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11184">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.11184v1 Announce Type: new Abstract: Mixture of Experts (MoE) models have achieved great success by significantly improving performance while maintaining computational efficiency through sparse expert activation. However, their enormous parameter sizes and memory demands pose major...</description>
        </item>
        <item>
            <title>Spectra: Rethinking Optimizers for LLMs Under Spectral Anisotropy</title>
            <link>https://arxiv.org/abs/2602.11185</link>
            <guid>https://arxiv.org/abs/2602.11185</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11185">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.11185v1 Announce Type: new Abstract: Gradient signals in LLM training are highly anisotropic: recurrent linguistic structure concentrates energy into a small set of dominant spectral directions, while context specific information resides in a long tail. We show that this spike tail...</description>
        </item>
        <item>
            <title>GAC-KAN: An Ultra-Lightweight GNSS Interference Classifier for GenAI-Powered Consumer Edge Devices</title>
            <link>https://arxiv.org/abs/2602.11186</link>
            <guid>https://arxiv.org/abs/2602.11186</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11186">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.11186v1 Announce Type: new Abstract: The integration of Generative AI (GenAI) into Consumer Electronics (CE)--from AI-powered assistants in wearables to generative planning in autonomous Uncrewed Aerial Vehicles (UAVs)--has revolutionized user experiences. However, these GenAI...</description>
        </item>
        <item>
            <title>TDPNavigator-Placer: Thermal- and Wirelength-Aware Chiplet Placement in 2.5D Systems Through Multi-Agent Reinforcement Learning</title>
            <link>https://arxiv.org/abs/2602.11187</link>
            <guid>https://arxiv.org/abs/2602.11187</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11187">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.11187v1 Announce Type: new Abstract: The rapid growth of electronics has accelerated the adoption of 2.5D integrated circuits, where effective automated chiplet placement is essential as systems scale to larger and more heterogeneous chiplet assemblies. Existing placement methods...</description>
        </item>
        <item>
            <title>HybridRAG: A Practical LLM-based ChatBot Framework based on Pre-Generated Q&amp;A over Raw Unstructured Documents</title>
            <link>https://arxiv.org/abs/2602.11156</link>
            <guid>https://arxiv.org/abs/2602.11156</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11156">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.11156v1 Announce Type: new Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for grounding Large Language Model (LLM)-based chatbot responses on external knowledge. However, existing RAG studies typically assume well-structured textual sources (e.g....</description>
        </item>
        <item>
            <title>Response-Based Knowledge Distillation for Multilingual Jailbreak Prevention Unwittingly Compromises Safety</title>
            <link>https://arxiv.org/abs/2602.11157</link>
            <guid>https://arxiv.org/abs/2602.11157</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11157">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.11157v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly deployed worldwide, yet their safety alignment remains predominantly English-centric. This allows for vulnerabilities in non-English contexts, especially with low-resource languages. We introduce a novel...</description>
        </item>
        <item>
            <title>Retrieval Heads are Dynamic</title>
            <link>https://arxiv.org/abs/2602.11162</link>
            <guid>https://arxiv.org/abs/2602.11162</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11162">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.11162v1 Announce Type: new Abstract: Recent studies have identified &quot;retrieval heads&quot; in Large Language Models (LLMs) responsible for extracting information from input contexts. However, prior works largely rely on static statistics aggregated across datasets, identifying heads that...</description>
        </item>
        <item>
            <title>Nested Named Entity Recognition in Plasma Physics Research Articles</title>
            <link>https://arxiv.org/abs/2602.11163</link>
            <guid>https://arxiv.org/abs/2602.11163</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11163">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.11163v1 Announce Type: new Abstract: Named Entity Recognition (NER) is an important task in natural language processing that aims to identify and extract key entities from unstructured text. We present a novel application of NER in plasma physics research articles and address the...</description>
        </item>
        <item>
            <title>Assessing LLM Reliability on Temporally Recent Open-Domain Questions</title>
            <link>https://arxiv.org/abs/2602.11165</link>
            <guid>https://arxiv.org/abs/2602.11165</guid>
            <pubDate>Fri, 13 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.11165">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.11165v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly deployed for open-domain question answering, yet their alignment with human perspectives on temporally recent information remains underexplored. We introduce RECOM (Reddit Evaluation for Correspondence of...</description>
        </item>
        <item>
            <title>Owning the AI Pareto Frontier — Jeff Dean</title>
            <link>https://www.latent.space/p/jeffdean</link>
            <guid>https://www.latent.space/p/jeffdean</guid>
            <pubDate>Thu, 12 Feb 2026 22:02:35 +0000</pubDate>
            <source url="https://www.latent.space/p/jeffdean">Latent Space</source>
            <category>open-source</category>
            <description>From rewriting Google&amp;#8217;s search stack in the early 2000s to reviving sparse trillion-parameter models and co-designing TPUs with frontier ML research, Jeff Dean has quietly shaped nearly every layer of the modern AI stack.</description>
        </item>
        <item>
            <title>ChatGPT Conversation Issues</title>
            <link>https://status.openai.com//incidents/01KH9WCWZ41K9ST9FGB1V15DFC</link>
            <guid>https://status.openai.com//incidents/01KH9WCWZ41K9ST9FGB1V15DFC</guid>
            <pubDate>Thu, 12 Feb 2026 21:56:32 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KH9WCWZ41K9ST9FGB1V15DFC">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: ResolvedAll impacted services have now fully recovered.Affected components Conversations (Operational)</description>
        </item>
        <item>
            <title>Disruption with some GitHub services</title>
            <link>https://www.githubstatus.com/incidents/y7kzv1ps2qrm</link>
            <guid>https://www.githubstatus.com/incidents/y7kzv1ps2qrm</guid>
            <pubDate>Thu, 12 Feb 2026 20:34:55 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/y7kzv1ps2qrm">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 12, 20:34 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Feb 12, 19:59 UTCUpdate - Next Edit Suggestions availability is recovering. We are...</description>
        </item>
        <item>
            <title>Google Reports State-Backed Hackers Using Gemini AI for Recon and Attack Support</title>
            <link>https://thehackernews.com/2026/02/google-reports-state-backed-hackers.html</link>
            <guid>https://thehackernews.com/2026/02/google-reports-state-backed-hackers.html</guid>
            <pubDate>Thu, 12 Feb 2026 17:57:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/google-reports-state-backed-hackers.html">The Hacker News</source>
            <category>security</category>
            <description>Google on Thursday said it observed the North Korea-linked threat actor known as UNC2970 using its generative artificial intelligence (AI) model Gemini to conduct reconnaissance on its targets, as various hacking groups continue to weaponize the tool for accelerating various phases of the cyber...</description>
        </item>
        <item>
            <title>Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria</title>
            <link>https://tldr.takara.ai/p/2602.12181</link>
            <guid>https://tldr.takara.ai/p/2602.12181</guid>
            <pubDate>Thu, 12 Feb 2026 17:11:20 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.12181">HF Daily Papers</source>
            <category>open-source</category>
            <description>Convex Markov Games (cMGs) were recently introduced as a broad class of multi-agent learning problems that generalize Markov games to settings where strategic agents optimize general utilities beyond additive rewards. While cMGs expand the modeling frontier, their theoretical foundations,...</description>
        </item>
        <item>
            <title>Lazarus Campaign Plants Malicious Packages in npm and PyPI Ecosystems</title>
            <link>https://thehackernews.com/2026/02/lazarus-campaign-plants-malicious.html</link>
            <guid>https://thehackernews.com/2026/02/lazarus-campaign-plants-malicious.html</guid>
            <pubDate>Thu, 12 Feb 2026 16:55:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/lazarus-campaign-plants-malicious.html">The Hacker News</source>
            <category>security</category>
            <description>Cybersecurity researchers have discovered a fresh set of malicious packages across npm and the Python Package Index (PyPI) repository linked to a fake recruitment-themed campaign orchestrated by the North Korea-linked Lazarus Group. The coordinated campaign has been codenamed graphalgo in reference...</description>
        </item>
        <item>
            <title>Intermittent disruption with Copilot completions and inline suggestions</title>
            <link>https://www.githubstatus.com/incidents/1x0f4x1wwqmb</link>
            <guid>https://www.githubstatus.com/incidents/1x0f4x1wwqmb</guid>
            <pubDate>Thu, 12 Feb 2026 16:50:01 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/1x0f4x1wwqmb">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 12, 16:50 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Feb 12, 15:33 UTCUpdate - We are experiencing degraded availability in Western Europe for...</description>
        </item>
        <item>
            <title>Gemini 3 Deep Think: Advancing science, research and engineering</title>
            <link>https://deepmind.google/blog/gemini-3-deep-think-advancing-science-research-and-engineering/</link>
            <guid>https://deepmind.google/blog/gemini-3-deep-think-advancing-science-research-and-engineering/</guid>
            <pubDate>Thu, 12 Feb 2026 16:15:09 +0000</pubDate>
            <source url="https://deepmind.google/blog/gemini-3-deep-think-advancing-science-research-and-engineering/">DeepMind Blog</source>
            <category>research</category>
            <description>Our most specialized reasoning mode is now updated to solve modern science, research and engineering challenges.</description>
        </item>
        <item>
            <title>How to Eliminate the Technical Debt of Insecure AI-Assisted Software Development</title>
            <link>https://www.securityweek.com/how-to-eliminate-the-technical-debt-of-insecure-ai-assisted-software-development/</link>
            <guid>https://www.securityweek.com/how-to-eliminate-the-technical-debt-of-insecure-ai-assisted-software-development/</guid>
            <pubDate>Thu, 12 Feb 2026 16:15:00 +0000</pubDate>
            <source url="https://www.securityweek.com/how-to-eliminate-the-technical-debt-of-insecure-ai-assisted-software-development/">Security Week</source>
            <category>security</category>
            <description>Developers must view AI as a collaborator to be closely monitored, rather than an autonomous entity to be unleashed. Without such a mindset, crippling tech debt is inevitable. The post How to Eliminate the Technical Debt of Insecure AI-Assisted Software Development appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>high error rate in text-embedding-3-small</title>
            <link>https://status.openai.com//incidents/01KH94NGSXNH9H4WBPXB3RFZWX</link>
            <guid>https://status.openai.com//incidents/01KH94NGSXNH9H4WBPXB3RFZWX</guid>
            <pubDate>Thu, 12 Feb 2026 16:10:15 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KH94NGSXNH9H4WBPXB3RFZWX">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: MonitoringWe have applied the mitigation and are monitoring the recovery. You may still be experiencing high latency.Affected components Embeddings (Operational)</description>
        </item>
        <item>
            <title>Multi Graph Search for High-Dimensional Robot Motion Planning</title>
            <link>https://tldr.takara.ai/p/2602.12096</link>
            <guid>https://tldr.takara.ai/p/2602.12096</guid>
            <pubDate>Thu, 12 Feb 2026 15:50:15 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.12096">HF Daily Papers</source>
            <category>open-source</category>
            <description>Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often...</description>
        </item>
        <item>
            <title>Elevated errors on Opus 4.6</title>
            <link>https://status.claude.com/incidents/95wtp412zh3z</link>
            <guid>https://status.claude.com/incidents/95wtp412zh3z</guid>
            <pubDate>Thu, 12 Feb 2026 15:17:57 +0000</pubDate>
            <source url="https://status.claude.com/incidents/95wtp412zh3z">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 12, 15:17 UTCResolved - This incident has been resolved.Feb 12, 14:45 UTCMonitoring - A fix has been implemented and we are monitoring the results.Feb 12, 14:18 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation</title>
            <link>https://tldr.takara.ai/p/2602.12002</link>
            <guid>https://tldr.takara.ai/p/2602.12002</guid>
            <pubDate>Thu, 12 Feb 2026 14:31:10 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.12002">HF Daily Papers</source>
            <category>open-source</category>
            <description>Accurate documentation of newborn resuscitation is essential for quality improvement and adherence to clinical guidelines, yet remains underutilized in practice. Previous work using 3D-CNNs and Vision Transformers (ViT) has shown promising results in detecting key activities from newborn...</description>
        </item>
        <item>
            <title>The Download: AI-enhanced cybercrime, and secure AI assistants</title>
            <link>https://www.technologyreview.com/2026/02/12/1132819/the-download-ai-enhanced-cybercrime-and-secure-ai-assistants/</link>
            <guid>https://www.technologyreview.com/2026/02/12/1132819/the-download-ai-enhanced-cybercrime-and-secure-ai-assistants/</guid>
            <pubDate>Thu, 12 Feb 2026 13:10:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/12/1132819/the-download-ai-enhanced-cybercrime-and-secure-ai-assistants/">MIT Tech Review AI</source>
            <category>research</category>
            <description>This is today&amp;#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&amp;#8217;s going on in the world of technology. AI is already making online crimes easier. It could get much worse. Just as software engineers are using artificial intelligence to help write code...</description>
        </item>
        <item>
            <title>ApolloMD Data Breach Impacts 626,000 Individuals</title>
            <link>https://www.securityweek.com/apollomd-data-breach-impacts-626000-individuals/</link>
            <guid>https://www.securityweek.com/apollomd-data-breach-impacts-626000-individuals/</guid>
            <pubDate>Thu, 12 Feb 2026 12:23:33 +0000</pubDate>
            <source url="https://www.securityweek.com/apollomd-data-breach-impacts-626000-individuals/">Security Week</source>
            <category>security</category>
            <description>The company says hackers stole the personal information of patients of affiliated physicians and practices. The post ApolloMD Data Breach Impacts 626,000 Individuals appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>ThreatsDay Bulletin: AI Prompt RCE, Claude 0-Click, RenEngine Loader, Auto 0-Days &amp; 25+ Stories</title>
            <link>https://thehackernews.com/2026/02/threatsday-bulletin-ai-prompt-rce.html</link>
            <guid>https://thehackernews.com/2026/02/threatsday-bulletin-ai-prompt-rce.html</guid>
            <pubDate>Thu, 12 Feb 2026 11:51:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/threatsday-bulletin-ai-prompt-rce.html">The Hacker News</source>
            <category>security</category>
            <description>Threat activity this week shows one consistent signal — attackers are leaning harder on what already works. Instead of flashy new exploits, many operations are built around quiet misuse of trusted tools, familiar workflows, and overlooked exposures that sit in plain sight. Another shift is how...</description>
        </item>
        <item>
            <title>Resource-Aware Deployment Optimization for Collaborative Intrusion Detection in Layered Networks</title>
            <link>https://tldr.takara.ai/p/2602.11851</link>
            <guid>https://tldr.takara.ai/p/2602.11851</guid>
            <pubDate>Thu, 12 Feb 2026 11:42:58 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.11851">HF Daily Papers</source>
            <category>open-source</category>
            <description>Collaborative Intrusion Detection Systems (CIDS) are increasingly adopted to counter cyberattacks, as their collaborative nature enables them to adapt to diverse scenarios across heterogeneous environments. As distributed critical infrastructure operates in rapidly evolving environments, such as...</description>
        </item>
        <item>
            <title>Microsoft to Enable ‘Windows Baseline Security’ With New Runtime Integrity Safeguards</title>
            <link>https://www.securityweek.com/microsoft-to-enable-windows-baseline-security-with-new-runtime-integrity-safeguards/</link>
            <guid>https://www.securityweek.com/microsoft-to-enable-windows-baseline-security-with-new-runtime-integrity-safeguards/</guid>
            <pubDate>Thu, 12 Feb 2026 11:27:30 +0000</pubDate>
            <source url="https://www.securityweek.com/microsoft-to-enable-windows-baseline-security-with-new-runtime-integrity-safeguards/">Security Week</source>
            <category>security</category>
            <description>Windows will have runtime safeguards enabled by default, ensuring that only properly signed software runs. The post Microsoft to Enable &amp;#8216;Windows Baseline Security&amp;#8217; With New Runtime Integrity Safeguards appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Disruption with some GitHub services</title>
            <link>https://www.githubstatus.com/incidents/5txsjlt9299p</link>
            <guid>https://www.githubstatus.com/incidents/5txsjlt9299p</guid>
            <pubDate>Thu, 12 Feb 2026 11:12:16 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/5txsjlt9299p">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 12, 11:12 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Feb 12, 11:01 UTCUpdate - We have resolved the issue and are seeing full recovery.Feb 12,...</description>
        </item>
        <item>
            <title>AI is already making online crimes easier. It could get much worse.</title>
            <link>https://www.technologyreview.com/2026/02/12/1132386/ai-already-making-online-swindles-easier/</link>
            <guid>https://www.technologyreview.com/2026/02/12/1132386/ai-already-making-online-swindles-easier/</guid>
            <pubDate>Thu, 12 Feb 2026 11:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/12/1132386/ai-already-making-online-swindles-easier/">MIT Tech Review AI</source>
            <category>research</category>
            <description>Anton Cherepanov is always on the lookout for something interesting. And in late August last year, he spotted just that. It was a file uploaded to VirusTotal, a site cybersecurity researchers like him use to analyze submissions for potential viruses and other types of malicious software, often...</description>
        </item>
        <item>
            <title>Why EVs are gaining ground in Africa</title>
            <link>https://www.technologyreview.com/2026/02/12/1132790/evs-progress-africa/</link>
            <guid>https://www.technologyreview.com/2026/02/12/1132790/evs-progress-africa/</guid>
            <pubDate>Thu, 12 Feb 2026 11:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/12/1132790/evs-progress-africa/">MIT Tech Review AI</source>
            <category>research</category>
            <description>EVs are getting cheaper and more common all over the world. But the technology still faces major challenges in some markets, including many countries in Africa. Some regions across the continent still have limited grid and charging infrastructure, and those that do have widespread electricity...</description>
        </item>
        <item>
            <title>The CTEM Divide: Why 84% of Security Programs Are Falling Behind</title>
            <link>https://thehackernews.com/2026/02/the-ctem-divide-why-84-of-security.html</link>
            <guid>https://thehackernews.com/2026/02/the-ctem-divide-why-84-of-security.html</guid>
            <pubDate>Thu, 12 Feb 2026 10:30:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/the-ctem-divide-why-84-of-security.html">The Hacker News</source>
            <category>security</category>
            <description>A new 2026 market intelligence study of 128 enterprise security decision-makers (available here) reveals a stark divide forming between organizations – one that has nothing to do with budget size or industry and everything to do with a single framework decision. Organizations implementing...</description>
        </item>
        <item>
            <title>What’s next for Chinese open-source AI</title>
            <link>https://www.technologyreview.com/2026/02/12/1132811/whats-next-for-chinese-open-source-ai/</link>
            <guid>https://www.technologyreview.com/2026/02/12/1132811/whats-next-for-chinese-open-source-ai/</guid>
            <pubDate>Thu, 12 Feb 2026 10:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/12/1132811/whats-next-for-chinese-open-source-ai/">MIT Tech Review AI</source>
            <category>research</category>
            <description>MIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them&amp;#160;here. The past year has marked a turning point for Chinese AI. Since DeepSeek released its R1 reasoning model in January 2025,...</description>
        </item>
        <item>
            <title>Cross-Architecture Model Diffing with Crosscoders: Unsupervised Discovery of Differences Between LLMs</title>
            <link>https://tldr.takara.ai/p/2602.11729</link>
            <guid>https://tldr.takara.ai/p/2602.11729</guid>
            <pubDate>Thu, 12 Feb 2026 08:53:25 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.11729">HF Daily Papers</source>
            <category>open-source</category>
            <description>Model diffing, the process of comparing models&#x27; internal representations to identify their differences, is a promising approach for uncovering safety-critical behaviors in new models. However, its application has so far been primarily focused on comparing a base model with its finetune. Since new...</description>
        </item>
        <item>
            <title>Incident with Codespaces</title>
            <link>https://www.githubstatus.com/incidents/7m8kxmjq0y7m</link>
            <guid>https://www.githubstatus.com/incidents/7m8kxmjq0y7m</guid>
            <pubDate>Thu, 12 Feb 2026 08:32:24 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/7m8kxmjq0y7m">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 12, 08:32 UTCUpdate - We now understand the source of the VM create/resume failures and are working with our partners to mitigate the impact.Feb 12, 08:02 UTCUpdate - We are seeing an increase in Codespaces creation and resuming failures across multiple regions, primarily in EMEA. Our team are...</description>
        </item>
        <item>
            <title>[AINews] Z.ai GLM-5: New SOTA Open Weights LLM</title>
            <link>https://www.latent.space/p/ainews-zai-glm-5-new-sota-open-weights</link>
            <guid>https://www.latent.space/p/ainews-zai-glm-5-new-sota-open-weights</guid>
            <pubDate>Thu, 12 Feb 2026 07:40:22 +0000</pubDate>
            <source url="https://www.latent.space/p/ainews-zai-glm-5-new-sota-open-weights">Latent Space</source>
            <category>open-source</category>
            <description>We have Opus 4.5 at home</description>
        </item>
    </channel>
</rss>

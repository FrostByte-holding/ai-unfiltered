<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI Unfiltered</title>
        <link>https://ai-unfiltered.com/</link>
        <description>Chinese AI • Open Source • Security • Incidents. Signal, not noise.</description>
        <language>en-us</language>
        <lastBuildDate>Thu, 22 Jan 2026 20:31:13 +0000</lastBuildDate>
        <atom:link href="https://ai-unfiltered.com/rss.xml" rel="self" type="application/rss+xml"/>
        
        <item>
            <title>AWS - US West (Oregon): INC0150440</title>
            <link>https://status.snowflake.com/incidents/0w11t7x10rzg</link>
            <guid>https://status.snowflake.com/incidents/0w11t7x10rzg</guid>
            <pubDate>Thu, 22 Jan 2026 19:48:31 +0000</pubDate>
            <source url="https://status.snowflake.com/incidents/0w11t7x10rzg">Snowflake Status</source>
            <category>incidents</category>
            <description>Jan 22, 19:48 UTCUpdate - Current status: Our investigation has led us to focus on a potential issue with the Snowsight application-hosting layer. We&#x27;re restarting the systems related to the Snowsight application-hosting layer, and our initial observation of telemetry indicates that this is...</description>
        </item>
        <item>
            <title>Claude Code Authentication Issues</title>
            <link>https://status.claude.com/incidents/58sxy43h7kvf</link>
            <guid>https://status.claude.com/incidents/58sxy43h7kvf</guid>
            <pubDate>Thu, 22 Jan 2026 16:36:07 +0000</pubDate>
            <source url="https://status.claude.com/incidents/58sxy43h7kvf">Anthropic Status</source>
            <category>incidents</category>
            <description>Jan 22, 16:36 UTCMonitoring - A fix has been implemented and we are monitoring the results.Jan 22, 16:29 UTCIdentified - The issue has been identified and a fix is being implemented.Jan 22, 16:22 UTCInvestigating - We are currently investigating an issue affecting Claude Code authentication. Users...</description>
        </item>
        <item>
            <title>Elevated errors on claude.ai</title>
            <link>https://status.claude.com/incidents/ct82mw4kc0kt</link>
            <guid>https://status.claude.com/incidents/ct82mw4kc0kt</guid>
            <pubDate>Thu, 22 Jan 2026 16:10:07 +0000</pubDate>
            <source url="https://status.claude.com/incidents/ct82mw4kc0kt">Anthropic Status</source>
            <category>incidents</category>
            <description>Jan 22, 16:10 UTCUpdate - We are continuing to investigate this issue.Jan 22, 16:06 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>Disruption with some GitHub services</title>
            <link>https://www.githubstatus.com/incidents/cqb5hcy0gx18</link>
            <guid>https://www.githubstatus.com/incidents/cqb5hcy0gx18</guid>
            <pubDate>Thu, 22 Jan 2026 15:22:59 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/cqb5hcy0gx18">GitHub Status</source>
            <category>incidents</category>
            <description>Jan 22, 15:22 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Jan 22, 15:22 UTCUpdate - We have identified an issue in one of our services and have...</description>
        </item>
        <item>
            <title>Codex Github Issues</title>
            <link>https://status.openai.com//incidents/01KFK1A9AAJ246K5G966PSQQJK</link>
            <guid>https://status.openai.com//incidents/01KFK1A9AAJ246K5G966PSQQJK</guid>
            <pubDate>Thu, 22 Jan 2026 14:55:44 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KFK1A9AAJ246K5G966PSQQJK">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: ResolvedAll impacted services have now fully recovered.Affected components Codex (Operational)</description>
        </item>
        <item>
            <title>The Download: Yann LeCun’s new venture, and lithium’s on the rise</title>
            <link>https://www.technologyreview.com/2026/01/22/1131680/the-download-yann-lecun-lithium-rise/</link>
            <guid>https://www.technologyreview.com/2026/01/22/1131680/the-download-yann-lecun-lithium-rise/</guid>
            <pubDate>Thu, 22 Jan 2026 13:10:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/01/22/1131680/the-download-yann-lecun-lithium-rise/">MIT Tech Review AI</source>
            <category>research</category>
            <description>This is today&amp;#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&amp;#8217;s going on in the world of technology. Yann LeCun’s new venture is a contrarian bet against large language models Yann LeCun is a Turing Award recipient and a top AI researcher, but he has...</description>
        </item>
        <item>
            <title>New Wave of Attacks Targeting FortiGate Firewalls</title>
            <link>https://www.securityweek.com/new-wave-of-attacks-targeting-fortigate-firewalls/</link>
            <guid>https://www.securityweek.com/new-wave-of-attacks-targeting-fortigate-firewalls/</guid>
            <pubDate>Thu, 22 Jan 2026 12:10:02 +0000</pubDate>
            <source url="https://www.securityweek.com/new-wave-of-attacks-targeting-fortigate-firewalls/">Security Week</source>
            <category>security</category>
            <description>Hackers bypass the FortiCloud SSO login authentication to create new accounts and change device configurations. The post New Wave of Attacks Targeting FortiGate Firewalls appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Claroty Raises $150 Million in Series F Funding</title>
            <link>https://www.securityweek.com/claroty-raises-150-million-in-series-f-funding/</link>
            <guid>https://www.securityweek.com/claroty-raises-150-million-in-series-f-funding/</guid>
            <pubDate>Thu, 22 Jan 2026 11:58:28 +0000</pubDate>
            <source url="https://www.securityweek.com/claroty-raises-150-million-in-series-f-funding/">Security Week</source>
            <category>security</category>
            <description>Claroty has raised a total of roughly $900 million and its valuation has reportedly reached $3 billion. The post Claroty Raises $150 Million in Series F Funding appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Filling the Most Common Gaps in Google Workspace Security</title>
            <link>https://thehackernews.com/2026/01/filling-most-common-gaps-in-google.html</link>
            <guid>https://thehackernews.com/2026/01/filling-most-common-gaps-in-google.html</guid>
            <pubDate>Thu, 22 Jan 2026 11:30:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/01/filling-most-common-gaps-in-google.html">The Hacker News</source>
            <category>security</category>
            <description>Security teams at agile, fast-growing companies often have the same mandate: secure the business without slowing it down. Most teams inherit a tech stack optimized for breakneck growth, not resilience. In these environments, the security team is the helpdesk, the compliance expert, and the incident...</description>
        </item>
        <item>
            <title>Furl Raises $10 Million for Autonomous Vulnerability Remediation</title>
            <link>https://www.securityweek.com/furl-raises-10-million-for-autonomous-vulnerability-remediation/</link>
            <guid>https://www.securityweek.com/furl-raises-10-million-for-autonomous-vulnerability-remediation/</guid>
            <pubDate>Thu, 22 Jan 2026 11:07:34 +0000</pubDate>
            <source url="https://www.securityweek.com/furl-raises-10-million-for-autonomous-vulnerability-remediation/">Security Week</source>
            <category>security</category>
            <description>The startup will use the new funding to accelerate product development and deepen remediation capabilities. The post Furl Raises $10 Million for Autonomous Vulnerability Remediation appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Why 2026 is a hot year for lithium</title>
            <link>https://www.technologyreview.com/2026/01/22/1131563/lithium-2026/</link>
            <guid>https://www.technologyreview.com/2026/01/22/1131563/lithium-2026/</guid>
            <pubDate>Thu, 22 Jan 2026 11:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/01/22/1131563/lithium-2026/">MIT Tech Review AI</source>
            <category>research</category>
            <description>In 2026, I’m going to be closely watching the price of lithium. If you’re not in the habit of obsessively tracking commodity markets, I certainly don’t blame you. (Though the news lately definitely makes the case that minerals can have major implications for global politics and the economy.) But...</description>
        </item>
        <item>
            <title>Malicious PyPI Package Impersonates SymPy, Deploys XMRig Miner on Linux Hosts</title>
            <link>https://thehackernews.com/2026/01/malicious-pypi-package-impersonates.html</link>
            <guid>https://thehackernews.com/2026/01/malicious-pypi-package-impersonates.html</guid>
            <pubDate>Thu, 22 Jan 2026 10:04:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/01/malicious-pypi-package-impersonates.html">The Hacker News</source>
            <category>security</category>
            <description>A new malicious package discovered in the Python Package Index (PyPI) has been found to impersonate a popular library for symbolic mathematics to deploy malicious payloads, including a cryptocurrency miner, on Linux hosts. The package, named sympy-dev, mimics SymPy, replicating the latter&#x27;s project...</description>
        </item>
        <item>
            <title>Yann LeCun’s new venture is a contrarian bet against large language models</title>
            <link>https://www.technologyreview.com/2026/01/22/1131661/yann-lecuns-new-venture-ami-labs/</link>
            <guid>https://www.technologyreview.com/2026/01/22/1131661/yann-lecuns-new-venture-ami-labs/</guid>
            <pubDate>Thu, 22 Jan 2026 10:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/01/22/1131661/yann-lecuns-new-venture-ami-labs/">MIT Tech Review AI</source>
            <category>research</category>
            <description>Yann LeCun is a Turing Award recipient and a top AI researcher, but he has long been a contrarian figure in the tech world. He believes that the industry’s current obsession with large language models is wrong-headed and will ultimately fail to solve many pressing problems.&amp;#160; Instead, he thinks...</description>
        </item>
        <item>
            <title>SmarterMail Auth Bypass Exploited in the Wild Two Days After Patch Release</title>
            <link>https://thehackernews.com/2026/01/smartermail-auth-bypass-exploited-in.html</link>
            <guid>https://thehackernews.com/2026/01/smartermail-auth-bypass-exploited-in.html</guid>
            <pubDate>Thu, 22 Jan 2026 09:46:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/01/smartermail-auth-bypass-exploited-in.html">The Hacker News</source>
            <category>security</category>
            <description>A new security flaw in SmarterTools SmarterMail email software has come under active exploitation in the wild, two days after the release of a patch. The vulnerability, which currently does not have a CVE identifier, is tracked by watchTowr Labs as WT-2026-0001. It was patched by SmarterTools on...</description>
        </item>
        <item>
            <title>Atlassian, GitLab, Zoom Release Security Patches</title>
            <link>https://www.securityweek.com/atlassian-gitlab-zoom-release-security-patches/</link>
            <guid>https://www.securityweek.com/atlassian-gitlab-zoom-release-security-patches/</guid>
            <pubDate>Thu, 22 Jan 2026 09:39:54 +0000</pubDate>
            <source url="https://www.securityweek.com/atlassian-gitlab-zoom-release-security-patches/">Security Week</source>
            <category>security</category>
            <description>Fixes were rolled out for over two dozen vulnerabilities, including critical- and high-severity bugs. The post Atlassian, GitLab, Zoom Release Security Patches appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Hackers Targeting Cisco Unified CM Zero-Day</title>
            <link>https://www.securityweek.com/hackers-targeting-cisco-unified-cm-zero-day/</link>
            <guid>https://www.securityweek.com/hackers-targeting-cisco-unified-cm-zero-day/</guid>
            <pubDate>Thu, 22 Jan 2026 08:52:24 +0000</pubDate>
            <source url="https://www.securityweek.com/hackers-targeting-cisco-unified-cm-zero-day/">Security Week</source>
            <category>security</category>
            <description>Cisco has released patches for CVE-2026-20045, a critical vulnerability that can be exploited for unauthenticated remote code execution. The post Hackers Targeting Cisco Unified CM Zero-Day appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>YIYUAN longevity Raises roughly $5-7 million in Angel Round to Build Quantifiable Anti-Aging Services</title>
            <link>https://pandaily.com/yiyuan-longevity-raises-roughly-5-7-million-in-angel-round-to-build-quantifiable-anti-aging-services</link>
            <guid>https://pandaily.com/yiyuan-longevity-raises-roughly-5-7-million-in-angel-round-to-build-quantifiable-anti-aging-services</guid>
            <pubDate>Thu, 22 Jan 2026 08:28:24 +0000</pubDate>
            <source url="https://pandaily.com/yiyuan-longevity-raises-roughly-5-7-million-in-angel-round-to-build-quantifiable-anti-aging-services">Pandaily</source>
            <category>chinese-ai</category>
            <description>Longevity startup YIYUAN LONGEVITY has raised tens of millions in angel funding to commercialize its quantifiable anti-aging service system, which includes a proprietary oxygen chamber and a “1+N” health consultant model.</description>
        </item>
        <item>
            <title>Dreame Technology Named Strategic Smart Technology Partner of the 2026 CCTV Spring Festival Gala</title>
            <link>https://pandaily.com/dreame-technology-named-strategic-smart-technology-partner-of-the-2026-cctv-spring-festival-gala</link>
            <guid>https://pandaily.com/dreame-technology-named-strategic-smart-technology-partner-of-the-2026-cctv-spring-festival-gala</guid>
            <pubDate>Thu, 22 Jan 2026 08:22:15 +0000</pubDate>
            <source url="https://pandaily.com/dreame-technology-named-strategic-smart-technology-partner-of-the-2026-cctv-spring-festival-gala">Pandaily</source>
            <category>chinese-ai</category>
            <description>Dreame Technology has been named the Intelligent Technology Ecosystem Strategic Partner for the 2026 CCTV Spring Festival Gala, marking a high-profile fusion of a leading tech brand with China’s premier cultural event.</description>
        </item>
        <item>
            <title>Extreme Vision Secures Overseas Listing Filing, Targets HKEX Chapter 18C</title>
            <link>https://pandaily.com/extreme-vision-secures-overseas-listing-filing-targets-hkex-chapter-18-c</link>
            <guid>https://pandaily.com/extreme-vision-secures-overseas-listing-filing-targets-hkex-chapter-18-c</guid>
            <pubDate>Thu, 22 Jan 2026 08:17:42 +0000</pubDate>
            <source url="https://pandaily.com/extreme-vision-secures-overseas-listing-filing-targets-hkex-chapter-18-c">Pandaily</source>
            <category>chinese-ai</category>
            <description>AI computer vision provider Extreme Vision has obtained its overseas listing filing just one day after applying, moving swiftly towards a Hong Kong IPO under the specialist tech company rules .</description>
        </item>
        <item>
            <title>Tsinghua University Open-Sources Project-Instinct to Advance “Instinct-Level” Robotic Motion Intelligence</title>
            <link>https://pandaily.com/tsinghua-university-open-sources-project-instinct-to-advance-instinct-level-robotic-motion-intelligence</link>
            <guid>https://pandaily.com/tsinghua-university-open-sources-project-instinct-to-advance-instinct-level-robotic-motion-intelligence</guid>
            <pubDate>Thu, 22 Jan 2026 08:13:39 +0000</pubDate>
            <source url="https://pandaily.com/tsinghua-university-open-sources-project-instinct-to-advance-instinct-level-robotic-motion-intelligence">Pandaily</source>
            <category>chinese-ai</category>
            <description>Researchers from Tsinghua University have open-sourced ‘Project-Instinct,’ a modular framework enabling humanoid robots to perform instinctive, high-dynamic movements like parkour and hiking over complex terrain.</description>
        </item>
        <item>
            <title>Longcheer Technology Lists in Hong Kong, Becomes the First Consumer Electronics ODM Stock</title>
            <link>https://pandaily.com/longcheer-technology-lists-in-hong-kong-becomes-the-first-consumer-electronics-odm-stock</link>
            <guid>https://pandaily.com/longcheer-technology-lists-in-hong-kong-becomes-the-first-consumer-electronics-odm-stock</guid>
            <pubDate>Thu, 22 Jan 2026 08:09:03 +0000</pubDate>
            <source url="https://pandaily.com/longcheer-technology-lists-in-hong-kong-becomes-the-first-consumer-electronics-odm-stock">Pandaily</source>
            <category>chinese-ai</category>
            <description>Longcheer Technology, the world’s largest smartphone ODM, has successfully achieved a dual listing on the Hong Kong Stock Exchange. Its shares opened 12.9% above the IPO price, with cornerstone investors including Qualcomm and Xiaomi participating.</description>
        </item>
        <item>
            <title>Automated FortiGate Attacks Exploit FortiCloud SSO to Alter Firewall Configurations</title>
            <link>https://thehackernews.com/2026/01/automated-fortigate-attacks-exploit.html</link>
            <guid>https://thehackernews.com/2026/01/automated-fortigate-attacks-exploit.html</guid>
            <pubDate>Thu, 22 Jan 2026 05:55:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/01/automated-fortigate-attacks-exploit.html">The Hacker News</source>
            <category>security</category>
            <description>Cybersecurity company Arctic Wolf has warned of a &quot;new cluster of automated malicious activity&quot; that involves unauthorized firewall configuration changes on Fortinet FortiGate devices. The activity, it said, commenced on January 15, 2026, adding it shares similarities with a December 2025 campaign...</description>
        </item>
        <item>
            <title>The Ontological Neutrality Theorem: Why Neutral Ontological Substrates Must Be Pre-Causal and Pre-Normative</title>
            <link>https://arxiv.org/abs/2601.14271</link>
            <guid>https://arxiv.org/abs/2601.14271</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14271">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2601.14271v1 Announce Type: new Abstract: Modern data systems must support accountability across persistent legal, political, and analytic disagreement. This requirement imposes strict constraints on the design of any ontology intended to function as a shared substrate. We establish an...</description>
        </item>
        <item>
            <title>Epistemic Constitutionalism Or: how to avoid coherence bias</title>
            <link>https://arxiv.org/abs/2601.14295</link>
            <guid>https://arxiv.org/abs/2601.14295</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14295">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2601.14295v1 Announce Type: new Abstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for...</description>
        </item>
        <item>
            <title>VisTIRA: Closing the Image-Text Modality Gap in Visual Math Reasoning via Structured Tool Integration</title>
            <link>https://arxiv.org/abs/2601.14440</link>
            <guid>https://arxiv.org/abs/2601.14440</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14440">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2601.14440v1 Announce Type: new Abstract: Vision-language models (VLMs) lag behind text-only language models on mathematical reasoning when the same problems are presented as images rather than text. We empirically characterize this as a modality gap: the same question in text form yields...</description>
        </item>
        <item>
            <title>On the Generalization Gap in LLM Planning: Tests and Verifier-Reward RL</title>
            <link>https://arxiv.org/abs/2601.14456</link>
            <guid>https://arxiv.org/abs/2601.14456</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14456">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2601.14456v1 Announce Type: new Abstract: Recent work shows that fine-tuned Large Language Models (LLMs) can achieve high valid plan rates on PDDL planning tasks. However, it remains unclear whether this reflects transferable planning competence or domain-specific memorization. In this work,...</description>
        </item>
        <item>
            <title>Scalable Knee-Point Guided Activity Group Selection in Multi-Tree Genetic Programming for Dynamic Multi-Mode Project Scheduling</title>
            <link>https://arxiv.org/abs/2601.14485</link>
            <guid>https://arxiv.org/abs/2601.14485</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14485">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2601.14485v1 Announce Type: new Abstract: The dynamic multi-mode resource-constrained project scheduling problem is a challenging scheduling problem that requires making decisions on both the execution order of activities and their corresponding execution modes. Genetic programming has been...</description>
        </item>
        <item>
            <title>Call2Instruct: Automated Pipeline for Generating Q&amp;A Datasets from Call Center Recordings for LLM Fine-Tuning</title>
            <link>https://arxiv.org/abs/2601.14263</link>
            <guid>https://arxiv.org/abs/2601.14263</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14263">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2601.14263v1 Announce Type: new Abstract: The adaptation of Large-Scale Language Models (LLMs) to specific domains depends on high-quality fine-tuning datasets, particularly in instructional format (e.g., Question-Answer - Q&amp;amp;A). However, generating these datasets, particularly from...</description>
        </item>
        <item>
            <title>GCG Attack On A Diffusion LLM</title>
            <link>https://arxiv.org/abs/2601.14266</link>
            <guid>https://arxiv.org/abs/2601.14266</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14266">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2601.14266v1 Announce Type: new Abstract: While most LLMs are autoregressive, diffusion-based LLMs have recently emerged as an alternative method for generation. Greedy Coordinate Gradient (GCG) attacks have proven effective against autoregressive models, but their applicability to diffusion...</description>
        </item>
        <item>
            <title>Divide and Refine: Enhancing Multimodal Representation and Explainability for Emotion Recognition in Conversation</title>
            <link>https://arxiv.org/abs/2601.14274</link>
            <guid>https://arxiv.org/abs/2601.14274</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14274">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2601.14274v1 Announce Type: new Abstract: Multimodal emotion recognition in conversation (MERC) requires representations that effectively integrate signals from multiple modalities. These signals include modality-specific cues, information shared across modalities, and interactions that...</description>
        </item>
        <item>
            <title>Quality or Quantity? Error-Informed Selective Online Learning with Gaussian Processes in Multi-Agent Systems: Extended Version</title>
            <link>https://arxiv.org/abs/2601.14275</link>
            <guid>https://arxiv.org/abs/2601.14275</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14275">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2601.14275v1 Announce Type: new Abstract: Effective cooperation is pivotal in distributed learning for multi-agent systems, where the interplay between the quantity and quality of the machine learning models is crucial. This paper reveals the irrationality of indiscriminate inclusion of all...</description>
        </item>
        <item>
            <title>Which Quantization Should I Use? A Unified Evaluation of llama.cpp Quantization on Llama-3.1-8B-Instruct</title>
            <link>https://arxiv.org/abs/2601.14277</link>
            <guid>https://arxiv.org/abs/2601.14277</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14277">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2601.14277v1 Announce Type: new Abstract: Quantization is a practical technique for making large language models easier to deploy by reducing the precision used to store and operate on model weights. This can lower memory use and improve runtime feasibility on constrained hardware, which is...</description>
        </item>
        <item>
            <title>From Chaos to Clarity: Schema-Constrained AI for Auditable Biomedical Evidence Extraction from Full-Text PDFs</title>
            <link>https://arxiv.org/abs/2601.14267</link>
            <guid>https://arxiv.org/abs/2601.14267</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14267">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2601.14267v1 Announce Type: new Abstract: Biomedical evidence synthesis relies on accurate extraction of methodological, laboratory, and outcome variables from full-text research articles, yet these variables are embedded in complex scientific PDFs that make manual abstraction time-consuming...</description>
        </item>
        <item>
            <title>The Slow Drift of Support: Boundary Failures in Multi-Turn Mental Health LLM Dialogues</title>
            <link>https://arxiv.org/abs/2601.14269</link>
            <guid>https://arxiv.org/abs/2601.14269</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14269">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2601.14269v1 Announce Type: new Abstract: Large language models (LLMs) have been widely used for mental health support. However, current safety evaluations in this field are mostly limited to detecting whether LLMs output prohibited words in single-turn conversations, neglecting the gradual...</description>
        </item>
        <item>
            <title>Opening the Black Box: A Survey on the Mechanisms of Multi-Step Reasoning in Large Language Models</title>
            <link>https://arxiv.org/abs/2601.14270</link>
            <guid>https://arxiv.org/abs/2601.14270</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14270">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2601.14270v1 Announce Type: new Abstract: Large Language Models (LLMs) have demonstrated remarkable abilities to solve problems requiring multiple reasoning steps, yet the internal mechanisms enabling such capabilities remain elusive. Unlike existing surveys that primarily focus on...</description>
        </item>
        <item>
            <title>Hallucination-Free Automatic Question &amp; Answer Generation for Intuitive Learning</title>
            <link>https://arxiv.org/abs/2601.14280</link>
            <guid>https://arxiv.org/abs/2601.14280</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14280">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2601.14280v1 Announce Type: new Abstract: Hallucinations in large language models (LLMs), defined as fluent yet incorrect or incoherent outputs, pose a significant challenge to the automatic generation of educational multiple-choice questions (MCQs). We identified four key hallucination types...</description>
        </item>
        <item>
            <title>RPC-Bench: A Fine-grained Benchmark for Research Paper Comprehension</title>
            <link>https://arxiv.org/abs/2601.14289</link>
            <guid>https://arxiv.org/abs/2601.14289</guid>
            <pubDate>Thu, 22 Jan 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2601.14289">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2601.14289v1 Announce Type: new Abstract: Understanding research papers remains challenging for foundation models due to specialized scientific discourse and complex figures and tables, yet existing benchmarks offer limited fine-grained evaluation at scale. To address this gap, we introduce...</description>
        </item>
        <item>
            <title>Cisco Fixes Actively Exploited Zero-Day CVE-2026-20045 in Unified CM and Webex</title>
            <link>https://thehackernews.com/2026/01/cisco-fixes-actively-exploited-zero-day.html</link>
            <guid>https://thehackernews.com/2026/01/cisco-fixes-actively-exploited-zero-day.html</guid>
            <pubDate>Thu, 22 Jan 2026 04:06:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/01/cisco-fixes-actively-exploited-zero-day.html">The Hacker News</source>
            <category>security</category>
            <description>Cisco has released fresh patches to address what it described as a &quot;critical&quot; security vulnerability impacting multiple Unified Communications (CM) products and Webex Calling Dedicated Instance that it has been actively exploited as a zero-day in the wild. The vulnerability, CVE-2026-20045 (CVSS...</description>
        </item>
        <item>
            <title>Cloudflare Workers Issues in EU</title>
            <link>https://www.cloudflarestatus.com/incidents/v6cn2z93d1k6</link>
            <guid>https://www.cloudflarestatus.com/incidents/v6cn2z93d1k6</guid>
            <pubDate>Thu, 22 Jan 2026 01:10:00 +0000</pubDate>
            <source url="https://www.cloudflarestatus.com/incidents/v6cn2z93d1k6">Cloudflare Status</source>
            <category>incidents</category>
            <description>Jan 22, 01:10 UTCResolved - Between 01:10-02:22 UTC customers reaching Stockholm, Oslo, Helsinki, St Petersburg and Amsterdam may have experienced an elevated number of Workers errors.</description>
        </item>
        <item>
            <title>AWS - US West (Oregon): INC0150359</title>
            <link>https://status.snowflake.com/incidents/s2j1bnnjshl4</link>
            <guid>https://status.snowflake.com/incidents/s2j1bnnjshl4</guid>
            <pubDate>Wed, 21 Jan 2026 20:14:42 +0000</pubDate>
            <source url="https://status.snowflake.com/incidents/s2j1bnnjshl4">Snowflake Status</source>
            <category>incidents</category>
            <description>Jan 21, 20:14 UTCUpdate - Current status: We have refined our understanding of how this issue manifests, and determined that it is isolated to Snowsight. Our investigation is currently focused on potential issues with the Snowsight application-hosting layer and the Snowsight-specific database...</description>
        </item>
        <item>
            <title>Policy pages for Copilot are timing out</title>
            <link>https://www.githubstatus.com/incidents/6d5kv6l8d8q3</link>
            <guid>https://www.githubstatus.com/incidents/6d5kv6l8d8q3</guid>
            <pubDate>Wed, 21 Jan 2026 20:12:36 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/6d5kv6l8d8q3">GitHub Status</source>
            <category>incidents</category>
            <description>Jan 21, 20:12 UTCUpdate - We are continuing to investigate latency and timeout issues affecting Copilot policy pages.Jan 21, 19:37 UTCUpdate - We are investigating timeouts for customers visiting the Copilot policy pages for organizations and enterprises.Jan 21, 19:31 UTCInvestigating - We are...</description>
        </item>
        <item>
            <title>Get Good at Agents</title>
            <link>https://www.interconnects.ai/p/get-good-at-agents</link>
            <guid>https://www.interconnects.ai/p/get-good-at-agents</guid>
            <pubDate>Wed, 21 Jan 2026 17:05:15 +0000</pubDate>
            <source url="https://www.interconnects.ai/p/get-good-at-agents">Interconnects</source>
            <category>open-source</category>
            <description>The tools are getting so powerful that we need to change how we scope, manage, and approach our work.</description>
        </item>
        <item>
            <title>Elevated errors on Claude Sonnet 4.5</title>
            <link>https://status.claude.com/incidents/yrxt885v63jw</link>
            <guid>https://status.claude.com/incidents/yrxt885v63jw</guid>
            <pubDate>Wed, 21 Jan 2026 15:32:09 +0000</pubDate>
            <source url="https://status.claude.com/incidents/yrxt885v63jw">Anthropic Status</source>
            <category>incidents</category>
            <description>Jan 21, 15:32 UTCResolved - This incident has been resolved.Jan 21, 15:28 UTCMonitoring - A fix has been implemented and we are monitoring the results.Jan 21, 15:01 UTCIdentified - The issue has been identified and a fix is being implemented.Jan 21, 14:44 UTCInvestigating - We are currently...</description>
        </item>
        <item>
            <title>Rethinking AI’s future in an augmented workplace</title>
            <link>https://www.technologyreview.com/2026/01/21/1131366/rethinking-ais-future-in-an-augmented-workplace/</link>
            <guid>https://www.technologyreview.com/2026/01/21/1131366/rethinking-ais-future-in-an-augmented-workplace/</guid>
            <pubDate>Wed, 21 Jan 2026 15:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/01/21/1131366/rethinking-ais-future-in-an-augmented-workplace/">MIT Tech Review AI</source>
            <category>research</category>
            <description>There are many paths AI evolution could take. On one end of the spectrum, AI is dismissed as a marginal fad, another bubble fueled by notoriety and misallocated capital. On the other end, it’s cast as a dystopian force, destined to eliminate jobs on a large scale and destabilize economies. Markets...</description>
        </item>
        <item>
            <title>Everyone wants AI sovereignty. No one can truly have it.</title>
            <link>https://www.technologyreview.com/2026/01/21/1131513/everyone-wants-ai-sovereignty-no-one-can-truly-have-it/</link>
            <guid>https://www.technologyreview.com/2026/01/21/1131513/everyone-wants-ai-sovereignty-no-one-can-truly-have-it/</guid>
            <pubDate>Wed, 21 Jan 2026 14:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/01/21/1131513/everyone-wants-ai-sovereignty-no-one-can-truly-have-it/">MIT Tech Review AI</source>
            <category>research</category>
            <description>Governments plan to pour $1.3 trillion into AI infrastructure by 2030 to invest in “sovereign AI,” with the premise being that countries should be in control of their own AI capabilities. The funds include financing for domestic data centers, locally trained models, independent supply chains, and...</description>
        </item>
        <item>
            <title>Rethinking Video Generation Model for the Embodied World</title>
            <link>https://tldr.takara.ai/p/2601.15282</link>
            <guid>https://tldr.takara.ai/p/2601.15282</guid>
            <pubDate>Wed, 21 Jan 2026 13:59:18 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2601.15282">HF Daily Papers</source>
            <category>open-source</category>
            <description>Video generation models have significantly advanced embodied intelligence, unlocking new possibilities for generating diverse robot data that capture perception, reasoning, and action in the physical world. However, synthesizing high-quality videos that accurately reflect real-world robotic...</description>
        </item>
        <item>
            <title>Copilot Chat - Grok Code Fast 1 Outage</title>
            <link>https://www.githubstatus.com/incidents/qq1gg4klp5vm</link>
            <guid>https://www.githubstatus.com/incidents/qq1gg4klp5vm</guid>
            <pubDate>Wed, 21 Jan 2026 12:38:59 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/qq1gg4klp5vm">GitHub Status</source>
            <category>incidents</category>
            <description>Jan 21, 12:38 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Jan 21, 12:09 UTCUpdate - We are experiencing degraded availability for the Grok Code Fast...</description>
        </item>
        <item>
            <title>Facilitating Proactive and Reactive Guidance for Decision Making on the Web: A Design Probe with WebSeek</title>
            <link>https://tldr.takara.ai/p/2601.15100</link>
            <guid>https://tldr.takara.ai/p/2601.15100</guid>
            <pubDate>Wed, 21 Jan 2026 10:38:57 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2601.15100">HF Daily Papers</source>
            <category>open-source</category>
            <description>Web AI agents such as ChatGPT Agent and GenSpark are increasingly used for routine web-based tasks, yet they still rely on text-based input prompts, lack proactive detection of user intent, and offer no support for interactive data analysis and decision making. We present WebSeek, a...</description>
        </item>
        <item>
            <title>The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems</title>
            <link>https://tldr.takara.ai/p/2601.15059</link>
            <guid>https://tldr.takara.ai/p/2601.15059</guid>
            <pubDate>Wed, 21 Jan 2026 10:05:27 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2601.15059">HF Daily Papers</source>
            <category>open-source</category>
            <description>Modern CI/CD pipelines integrating agent-generated code exhibit a structural failure in responsibility attribution. Decisions are executed through formally correct approval processes, yet no entity possesses both the authority to approve those decisions and the epistemic capacity to meaningfully...</description>
        </item>
        <item>
            <title>AssetOpsBench: Bridging the Gap Between AI Agent Benchmarks and Industrial Reality</title>
            <link>https://huggingface.co/blog/ibm-research/assetopsbench-playground-on-hugging-face</link>
            <guid>https://huggingface.co/blog/ibm-research/assetopsbench-playground-on-hugging-face</guid>
            <pubDate>Wed, 21 Jan 2026 06:25:31 +0000</pubDate>
            <source url="https://huggingface.co/blog/ibm-research/assetopsbench-playground-on-hugging-face">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
    </channel>
</rss>

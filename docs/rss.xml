<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI Unfiltered</title>
        <link>https://ai-unfiltered.com/</link>
        <description>Chinese AI • Open Source • Security • Incidents. Signal, not noise.</description>
        <language>en-us</language>
        <lastBuildDate>Fri, 06 Feb 2026 05:16:21 +0000</lastBuildDate>
        <atom:link href="https://ai-unfiltered.com/rss.xml" rel="self" type="application/rss+xml"/>
        
        <item>
            <title>Artificial Intelligence as Strange Intelligence: Against Linear Models of Intelligence</title>
            <link>https://arxiv.org/abs/2602.04986</link>
            <guid>https://arxiv.org/abs/2602.04986</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04986">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.04986v1 Announce Type: new Abstract: We endorse and expand upon Susan Schneider&#x27;s critique of the linear model of AI progress and introduce two novel concepts: &quot;familiar intelligence&quot; and &quot;strange intelligence&quot;. AI intelligence is likely to be strange intelligence, defying familiar...</description>
        </item>
        <item>
            <title>DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search</title>
            <link>https://arxiv.org/abs/2602.05014</link>
            <guid>https://arxiv.org/abs/2602.05014</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05014">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.05014v1 Announce Type: new Abstract: With the rapid progress of tool-using and agentic large language models (LLMs), Retrieval-Augmented Generation (RAG) is evolving from one-shot, passive retrieval into multi-turn, decision-driven evidence acquisition. Despite strong results in...</description>
        </item>
        <item>
            <title>MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation</title>
            <link>https://arxiv.org/abs/2602.05048</link>
            <guid>https://arxiv.org/abs/2602.05048</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05048">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.05048v1 Announce Type: new Abstract: Joint planning through language-based interactions is a key area of human-AI teaming. Planning problems in the open world often involve various aspects of incomplete information and unknowns, e.g., objects involved, human goals/intents -- thus leading...</description>
        </item>
        <item>
            <title>Evaluating Large Language Models on Solved and Unsolved Problems in Graph Theory: Implications for Computing Education</title>
            <link>https://arxiv.org/abs/2602.05059</link>
            <guid>https://arxiv.org/abs/2602.05059</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05059">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.05059v1 Announce Type: new Abstract: Large Language Models are increasingly used by students to explore advanced material in computer science, including graph theory. As these tools become integrated into undergraduate and graduate coursework, it is important to understand how reliably...</description>
        </item>
        <item>
            <title>Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents</title>
            <link>https://arxiv.org/abs/2602.05073</link>
            <guid>https://arxiv.org/abs/2602.05073</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05073">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.05073v1 Announce Type: new Abstract: Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on...</description>
        </item>
        <item>
            <title>Denoising diffusion networks for normative modeling in neuroimaging</title>
            <link>https://arxiv.org/abs/2602.04886</link>
            <guid>https://arxiv.org/abs/2602.04886</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04886">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.04886v1 Announce Type: new Abstract: Normative modeling estimates reference distributions of biological measures conditional on covariates, enabling centiles and clinically interpretable deviation scores to be derived. Most neuroimaging pipelines fit one model per imaging-derived...</description>
        </item>
        <item>
            <title>A Causal Perspective for Enhancing Jailbreak Attack and Defense</title>
            <link>https://arxiv.org/abs/2602.04893</link>
            <guid>https://arxiv.org/abs/2602.04893</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04893">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.04893v1 Announce Type: new Abstract: Uncovering the mechanisms behind &quot;jailbreaks&quot; in large language models (LLMs) is crucial for enhancing their safety and reliability, yet these mechanisms remain poorly understood. Existing studies predominantly analyze jailbreak prompts by probing...</description>
        </item>
        <item>
            <title>Momentum Attention: The Physics of In-Context Learning and Spectral Forensics for Mechanistic Interpretability</title>
            <link>https://arxiv.org/abs/2602.04902</link>
            <guid>https://arxiv.org/abs/2602.04902</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04902">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.04902v1 Announce Type: new Abstract: The Mechanistic Interpretability (MI) program has mapped the Transformer as a precise computational graph. We extend this graph with a conservation law and time-varying AC dynamics, viewing it as a physical circuit. We introduce Momentum Attention, a...</description>
        </item>
        <item>
            <title>Mind the Performance Gap: Capability-Behavior Trade-offs in Feature Steering</title>
            <link>https://arxiv.org/abs/2602.04903</link>
            <guid>https://arxiv.org/abs/2602.04903</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04903">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.04903v1 Announce Type: new Abstract: Feature steering has emerged as a promising approach for controlling LLM behavior through direct manipulation of internal representations, offering advantages over prompt engineering. However, its practical effectiveness in real-world applications...</description>
        </item>
        <item>
            <title>DCER: Dual-Stage Compression and Energy-Based Reconstruction</title>
            <link>https://arxiv.org/abs/2602.04904</link>
            <guid>https://arxiv.org/abs/2602.04904</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04904">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.04904v1 Announce Type: new Abstract: Multimodal fusion faces two robustness challenges: noisy inputs degrade representation quality, and missing modalities cause prediction failures. We propose DCER, a unified framework addressing both challenges through dual-stage compression and...</description>
        </item>
        <item>
            <title>BioACE: An Automated Framework for Biomedical Answer and Citation Evaluations</title>
            <link>https://arxiv.org/abs/2602.04982</link>
            <guid>https://arxiv.org/abs/2602.04982</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.04982">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.04982v1 Announce Type: new Abstract: With the increasing use of large language models (LLMs) for generating answers to biomedical questions, it is crucial to evaluate the quality of the generated answers and the references provided to support the facts in the generated answers....</description>
        </item>
        <item>
            <title>CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System</title>
            <link>https://arxiv.org/abs/2602.05004</link>
            <guid>https://arxiv.org/abs/2602.05004</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05004">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.05004v1 Announce Type: new Abstract: Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict...</description>
        </item>
        <item>
            <title>Capacity Constraints and the Multilingual Penalty for Lexical Disambiguation</title>
            <link>https://arxiv.org/abs/2602.05035</link>
            <guid>https://arxiv.org/abs/2602.05035</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05035">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.05035v1 Announce Type: new Abstract: Multilingual language models (LMs) sometimes under-perform their monolingual counterparts, possibly due to capacity limitations. We quantify this ``multilingual penalty&#x27;&#x27; for lexical disambiguation--a task requiring precise semantic representations...</description>
        </item>
        <item>
            <title>Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories</title>
            <link>https://arxiv.org/abs/2602.05085</link>
            <guid>https://arxiv.org/abs/2602.05085</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05085">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.05085v1 Announce Type: new Abstract: In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks...</description>
        </item>
        <item>
            <title>Data Kernel Perspective Space Performance Guarantees for Synthetic Data from Transformer Models</title>
            <link>https://arxiv.org/abs/2602.05106</link>
            <guid>https://arxiv.org/abs/2602.05106</guid>
            <pubDate>Fri, 06 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.05106">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.05106v1 Announce Type: new Abstract: Scarcity of labeled training data remains the long pole in the tent for building performant language technology and generative AI models. Transformer models -- particularly LLMs -- are increasingly being used to mitigate the data scarcity problem via...</description>
        </item>
        <item>
            <title>[AINews] OpenAI and Anthropic go to war: Claude Opus 4.6 vs GPT 5.3 Codex</title>
            <link>https://www.latent.space/p/ainews-openai-and-anthropic-go-to</link>
            <guid>https://www.latent.space/p/ainews-openai-and-anthropic-go-to</guid>
            <pubDate>Fri, 06 Feb 2026 04:10:33 +0000</pubDate>
            <source url="https://www.latent.space/p/ainews-openai-and-anthropic-go-to">Latent Space</source>
            <category>open-source</category>
            <description>The battle of the SOTA Coding Models steps up a notch</description>
        </item>
        <item>
            <title>Coowa Achieves Operating Profitability, Defines Urban New Infrastructure Through Physical AI</title>
            <link>https://pandaily.com/coowa-achieves-operating-profitability-defines-urban-new-infrastructure-through-physical-ai</link>
            <guid>https://pandaily.com/coowa-achieves-operating-profitability-defines-urban-new-infrastructure-through-physical-ai</guid>
            <pubDate>Fri, 06 Feb 2026 03:33:28 +0000</pubDate>
            <source url="https://pandaily.com/coowa-achieves-operating-profitability-defines-urban-new-infrastructure-through-physical-ai">Pandaily</source>
            <category>chinese-ai</category>
            <description>Coowa is scaling Physical AI from concept to citywide infrastructure as it reaches profitability and expands robot services across major global cities.</description>
        </item>
        <item>
            <title>Geek+ Reports US$595 Million in Orders for 2025, to Be Included in Hong Kong Stock Connect on February 6</title>
            <link>https://pandaily.com/geek-reports-us-595-million-in-orders-for-2025-to-be-included-in-hong-kong-stock-connect-on-february-6</link>
            <guid>https://pandaily.com/geek-reports-us-595-million-in-orders-for-2025-to-be-included-in-hong-kong-stock-connect-on-february-6</guid>
            <pubDate>Fri, 06 Feb 2026 03:23:52 +0000</pubDate>
            <source url="https://pandaily.com/geek-reports-us-595-million-in-orders-for-2025-to-be-included-in-hong-kong-stock-connect-on-february-6">Pandaily</source>
            <category>chinese-ai</category>
            <description>Geek+ is accelerating its global expansion as strong 2025 order growth and inclusion in Hong Kong Stock Connect reinforce its position in the warehouse robotics market.</description>
        </item>
        <item>
            <title>ModelBest Announces First AI Hardware “Pinea Pi,” Launching This Year</title>
            <link>https://pandaily.com/model-best-announces-first-ai-hardware-pinea-pi-launching-this-year</link>
            <guid>https://pandaily.com/model-best-announces-first-ai-hardware-pinea-pi-launching-this-year</guid>
            <pubDate>Fri, 06 Feb 2026 03:18:12 +0000</pubDate>
            <source url="https://pandaily.com/model-best-announces-first-ai-hardware-pinea-pi-launching-this-year">Pandaily</source>
            <category>chinese-ai</category>
            <description>ModelBest is bringing AI-native edge development to the mainstream with Pinea Pi, a Jetson-based board designed for embodied intelligence and offline multimodal AI.</description>
        </item>
        <item>
            <title>Li Xiang: The New Li L9 Is a Pioneering Embodied Intelligence Robot</title>
            <link>https://pandaily.com/li-xiang-the-new-li-l9-is-a-pioneering-embodied-intelligence-robot</link>
            <guid>https://pandaily.com/li-xiang-the-new-li-l9-is-a-pioneering-embodied-intelligence-robot</guid>
            <pubDate>Fri, 06 Feb 2026 03:15:52 +0000</pubDate>
            <source url="https://pandaily.com/li-xiang-the-new-li-l9-is-a-pioneering-embodied-intelligence-robot">Pandaily</source>
            <category>chinese-ai</category>
            <description>Li Auto’s CEO Li Xiang positions the all-new Li L9 not just as a flagship SUV, but as the starting point of embodied intelligence robots for everyday life.</description>
        </item>
        <item>
            <title>Tencent Takes Equity Stake in Neolix RoboVan</title>
            <link>https://pandaily.com/tencent-takes-equity-stake-in-neolix-robo-van</link>
            <guid>https://pandaily.com/tencent-takes-equity-stake-in-neolix-robo-van</guid>
            <pubDate>Fri, 06 Feb 2026 03:14:09 +0000</pubDate>
            <source url="https://pandaily.com/tencent-takes-equity-stake-in-neolix-robo-van">Pandaily</source>
            <category>chinese-ai</category>
            <description>Tencent’s investment signals growing confidence in Neolix RoboVan’s push to scale L4 autonomous delivery across Chinese cities.</description>
        </item>
        <item>
            <title>Zscaler Acquires Browser Security Firm SquareX</title>
            <link>https://www.securityweek.com/zscaler-acquires-browser-security-firm-squarex/</link>
            <guid>https://www.securityweek.com/zscaler-acquires-browser-security-firm-squarex/</guid>
            <pubDate>Fri, 06 Feb 2026 02:48:22 +0000</pubDate>
            <source url="https://www.securityweek.com/zscaler-acquires-browser-security-firm-squarex/">Security Week</source>
            <category>security</category>
            <description>Zscaler says the acquisition will allow customers to embed lightweight extensions into any browser, providing increased security and eliminating the need for third-party browsers. The post Zscaler Acquires Browser Security Firm SquareX appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>The First Mechanistic Interpretability Frontier Lab — Myra Deng &amp; Mark Bissell of Goodfire AI</title>
            <link>https://www.latent.space/p/goodfire</link>
            <guid>https://www.latent.space/p/goodfire</guid>
            <pubDate>Thu, 05 Feb 2026 20:45:01 +0000</pubDate>
            <source url="https://www.latent.space/p/goodfire">Latent Space</source>
            <category>open-source</category>
            <description>Tickets for AIE Miami and AIE Europe are on sale now!</description>
        </item>
        <item>
            <title>AISURU/Kimwolf Botnet Launches Record-Setting 31.4 Tbps DDoS Attack</title>
            <link>https://thehackernews.com/2026/02/aisurukimwolf-botnet-launches-record.html</link>
            <guid>https://thehackernews.com/2026/02/aisurukimwolf-botnet-launches-record.html</guid>
            <pubDate>Thu, 05 Feb 2026 17:25:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/aisurukimwolf-botnet-launches-record.html">The Hacker News</source>
            <category>security</category>
            <description>The distributed denial-of-service (DDoS) botnet known as AISURU/Kimwolf has been attributed to a record-setting attack that peaked at 31.4 Terabits per second (Tbps) and lasted only 35 seconds. Cloudflare, which automatically detected and mitigated the activity, said it&#x27;s part of a growing number...</description>
        </item>
        <item>
            <title>Introducing SyGra Studio</title>
            <link>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</link>
            <guid>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</guid>
            <pubDate>Thu, 05 Feb 2026 16:52:28 +0000</pubDate>
            <source url="https://huggingface.co/blog/ServiceNow-AI/sygra-studio">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
        <item>
            <title>Conversation compaction degraded on claude.ai</title>
            <link>https://status.claude.com/incidents/plhlsqf2svt6</link>
            <guid>https://status.claude.com/incidents/plhlsqf2svt6</guid>
            <pubDate>Thu, 05 Feb 2026 15:58:12 +0000</pubDate>
            <source url="https://status.claude.com/incidents/plhlsqf2svt6">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 5, 15:58 UTCIdentified - The issue has been identified and a fix is being implemented.</description>
        </item>
        <item>
            <title>Consolidating systems for AI with iPaaS</title>
            <link>https://www.technologyreview.com/2026/02/05/1132200/consolidating-systems-for-ai-with-ipaas/</link>
            <guid>https://www.technologyreview.com/2026/02/05/1132200/consolidating-systems-for-ai-with-ipaas/</guid>
            <pubDate>Thu, 05 Feb 2026 15:20:37 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/05/1132200/consolidating-systems-for-ai-with-ipaas/">MIT Tech Review AI</source>
            <category>research</category>
            <description>For decades, enterprises reacted to shifting business pressures with stopgap technology solutions. To rein in rising infrastructure costs, they adopted cloud services that could scale on demand. When customers shifted their lives onto smartphones, companies rolled out mobile apps to keep pace. And...</description>
        </item>
        <item>
            <title>Substack Discloses Security Incident After Hacker Leaks Data</title>
            <link>https://www.securityweek.com/substack-discloses-security-incident-after-hacker-leaks-data/</link>
            <guid>https://www.securityweek.com/substack-discloses-security-incident-after-hacker-leaks-data/</guid>
            <pubDate>Thu, 05 Feb 2026 15:13:55 +0000</pubDate>
            <source url="https://www.securityweek.com/substack-discloses-security-incident-after-hacker-leaks-data/">Security Week</source>
            <category>security</category>
            <description>The hacker claims to have stolen nearly 700,000 Substack user records, including email addresses and phone numbers. The post Substack Discloses Security Incident After Hacker Leaks Data appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Researchers Expose Network of 150 Cloned Law Firm Websites in AI-Powered Scam Campaign</title>
            <link>https://www.securityweek.com/researchers-expose-network-of-150-cloned-law-firm-websites-in-ai-powered-scam-campaign/</link>
            <guid>https://www.securityweek.com/researchers-expose-network-of-150-cloned-law-firm-websites-in-ai-powered-scam-campaign/</guid>
            <pubDate>Thu, 05 Feb 2026 14:00:00 +0000</pubDate>
            <source url="https://www.securityweek.com/researchers-expose-network-of-150-cloned-law-firm-websites-in-ai-powered-scam-campaign/">Security Week</source>
            <category>security</category>
            <description>Criminals are using AI to clone professional websites at an industrial scale. A new report shows how one AI-powered network grew to 150+ domains by hiding behind Cloudflare and rotating IP ranges. The post Researchers Expose Network of 150 Cloned Law Firm Websites in AI-Powered Scam Campaign...</description>
        </item>
        <item>
            <title>VS Code Configs Expose GitHub Codespaces to Attacks</title>
            <link>https://www.securityweek.com/vs-code-configs-expose-github-codespaces-to-attacks/</link>
            <guid>https://www.securityweek.com/vs-code-configs-expose-github-codespaces-to-attacks/</guid>
            <pubDate>Thu, 05 Feb 2026 13:41:48 +0000</pubDate>
            <source url="https://www.securityweek.com/vs-code-configs-expose-github-codespaces-to-attacks/">Security Week</source>
            <category>security</category>
            <description>VS Code-integrated configuration files are automatically executed in Codespaces when the user opens a repository or pull request. The post VS Code Configs Expose GitHub Codespaces to Attacks appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>The Download: attempting to track AI, and the next generation of nuclear power</title>
            <link>https://www.technologyreview.com/2026/02/05/1132270/the-download-attempting-to-track-ai-and-the-next-generation-of-nuclear-power/</link>
            <guid>https://www.technologyreview.com/2026/02/05/1132270/the-download-attempting-to-track-ai-and-the-next-generation-of-nuclear-power/</guid>
            <pubDate>Thu, 05 Feb 2026 13:10:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/05/1132270/the-download-attempting-to-track-ai-and-the-next-generation-of-nuclear-power/">MIT Tech Review AI</source>
            <category>research</category>
            <description>This is today&amp;#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&amp;#8217;s going on in the world of technology. This is the most misunderstood graph in AI Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds...</description>
        </item>
        <item>
            <title>Nullify Secures $12.5 Million in Seed Funding for Cybersecurity AI Workforce</title>
            <link>https://www.securityweek.com/nullify-secures-12-5-million-in-seed-funding-for-cybersecurity-ai-workforce/</link>
            <guid>https://www.securityweek.com/nullify-secures-12-5-million-in-seed-funding-for-cybersecurity-ai-workforce/</guid>
            <pubDate>Thu, 05 Feb 2026 13:02:15 +0000</pubDate>
            <source url="https://www.securityweek.com/nullify-secures-12-5-million-in-seed-funding-for-cybersecurity-ai-workforce/">Security Week</source>
            <category>security</category>
            <description>This latest infusion, led by SYN Ventures, brings the company’s total funding to $16.9 million. The post Nullify Secures $12.5 Million in Seed Funding for Cybersecurity AI Workforce appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>ThreatsDay Bulletin: Codespaces RCE, AsyncRAT C2, BYOVD Abuse, AI Cloud Intrusions &amp; 15+ Stories</title>
            <link>https://thehackernews.com/2026/02/threatsday-bulletin-codespaces-rce.html</link>
            <guid>https://thehackernews.com/2026/02/threatsday-bulletin-codespaces-rce.html</guid>
            <pubDate>Thu, 05 Feb 2026 12:57:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/threatsday-bulletin-codespaces-rce.html">The Hacker News</source>
            <category>security</category>
            <description>This week didn&amp;rsquo;t produce one big headline. It produced many small signals &amp;mdash; the kind that quietly shape what attacks will look like next. Researchers tracked intrusions that start in ordinary places: developer workflows, remote tools, cloud access, identity paths, and even routine user...</description>
        </item>
        <item>
            <title>The Buyer’s Guide to AI Usage Control</title>
            <link>https://thehackernews.com/2026/02/the-buyers-guide-to-ai-usage-control.html</link>
            <guid>https://thehackernews.com/2026/02/the-buyers-guide-to-ai-usage-control.html</guid>
            <pubDate>Thu, 05 Feb 2026 11:30:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/the-buyers-guide-to-ai-usage-control.html">The Hacker News</source>
            <category>security</category>
            <description>Today’s “AI everywhere” reality is woven into everyday workflows across the enterprise, embedded in SaaS platforms, browsers, copilots, extensions, and a rapidly expanding universe of shadow tools that appear faster than security teams can track. Yet most organizations still rely on legacy controls...</description>
        </item>
        <item>
            <title>Three questions about next-generation nuclear power, answered</title>
            <link>https://www.technologyreview.com/2026/02/05/1132197/nuclear-questions/</link>
            <guid>https://www.technologyreview.com/2026/02/05/1132197/nuclear-questions/</guid>
            <pubDate>Thu, 05 Feb 2026 11:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/05/1132197/nuclear-questions/">MIT Tech Review AI</source>
            <category>research</category>
            <description>Nuclear power continues to be one of the hottest topics in energy today, and in our recent online Roundtables discussion about next-generation nuclear power, hyperscale AI data centers, and the grid, we got dozens of great audience questions. These ran the gamut, and while we answered quite a few...</description>
        </item>
        <item>
            <title>Infy Hackers Resume Operations with New C2 Servers After Iran Internet Blackout Ends</title>
            <link>https://thehackernews.com/2026/02/infy-hackers-resume-operations-with-new.html</link>
            <guid>https://thehackernews.com/2026/02/infy-hackers-resume-operations-with-new.html</guid>
            <pubDate>Thu, 05 Feb 2026 10:25:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/infy-hackers-resume-operations-with-new.html">The Hacker News</source>
            <category>security</category>
            <description>The elusive Iranian threat group known as Infy (aka Prince of Persia) has evolved its tactics as part of efforts to hide its tracks, even as it readied new command-and-control (C2) infrastructure coinciding with the end of the widespread internet blackout the regime imposed at the start of the...</description>
        </item>
        <item>
            <title>This is the most misunderstood graph in AI</title>
            <link>https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/</link>
            <guid>https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/</guid>
            <pubDate>Thu, 05 Feb 2026 10:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/">MIT Tech Review AI</source>
            <category>research</category>
            <description>MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. You can read more from the series here. Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It...</description>
        </item>
        <item>
            <title>[AINews] ElevenLabs $500m Series D at $11B, Cerebras $1B Series H at $23B, Vibe Coding -&gt; Agentic Engineering</title>
            <link>https://www.latent.space/p/ainews-elevenlabs-500m-series-d-at</link>
            <guid>https://www.latent.space/p/ainews-elevenlabs-500m-series-d-at</guid>
            <pubDate>Thu, 05 Feb 2026 08:26:43 +0000</pubDate>
            <source url="https://www.latent.space/p/ainews-elevenlabs-500m-series-d-at">Latent Space</source>
            <category>open-source</category>
            <description>SOTA Audio models, Fast Chips, and Koding Agents are all you need.</description>
        </item>
        <item>
            <title>Critical n8n Flaw CVE-2026-25049 Enables System Command Execution via Malicious Workflows</title>
            <link>https://thehackernews.com/2026/02/critical-n8n-flaw-cve-2026-25049.html</link>
            <guid>https://thehackernews.com/2026/02/critical-n8n-flaw-cve-2026-25049.html</guid>
            <pubDate>Thu, 05 Feb 2026 06:16:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/critical-n8n-flaw-cve-2026-25049.html">The Hacker News</source>
            <category>security</category>
            <description>A new, critical security vulnerability has been disclosed in the n8n workflow automation platform that, if successfully exploited, could result in the execution of arbitrary system commands. The flaw, tracked as CVE-2026-25049 (CVSS score: 9.4), is the result of inadequate sanitization that...</description>
        </item>
        <item>
            <title>Increased ChatGPT errors for some users</title>
            <link>https://status.openai.com//incidents/01KGNJACX0T5CYY1YWS8RNW6S6</link>
            <guid>https://status.openai.com//incidents/01KGNJACX0T5CYY1YWS8RNW6S6</guid>
            <pubDate>Thu, 05 Feb 2026 00:48:56 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KGNJACX0T5CYY1YWS8RNW6S6">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: ResolvedAll impacted services have now fully recovered.Affected components Voice mode (Operational) Search (Operational) Compliance API (Operational) Agent (Operational) Deep Research (Operational) Connectors/Apps (Operational) ChatGPT Atlas (Operational) Login (Operational) File uploads...</description>
        </item>
        <item>
            <title>LitS: A novel Neighborhood Descriptor for Point Clouds</title>
            <link>https://tldr.takara.ai/p/2602.04838</link>
            <guid>https://tldr.takara.ai/p/2602.04838</guid>
            <pubDate>Wed, 04 Feb 2026 18:31:02 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.04838">HF Daily Papers</source>
            <category>open-source</category>
            <description>With the advancement of 3D scanning technologies, point clouds have become fundamental for representing 3D spatial data, with applications that span across various scientific and technological fields. Practical analysis of this data depends crucially on available neighborhood descriptors to...</description>
        </item>
        <item>
            <title>Why Nvidia builds open models with Bryan Catanzaro</title>
            <link>https://www.interconnects.ai/p/why-nvidia-builds-open-models-with</link>
            <guid>https://www.interconnects.ai/p/why-nvidia-builds-open-models-with</guid>
            <pubDate>Wed, 04 Feb 2026 18:00:28 +0000</pubDate>
            <source url="https://www.interconnects.ai/p/why-nvidia-builds-open-models-with">Interconnects</source>
            <category>open-source</category>
            <description>Interconnects interview #17 on the past, present, and future of the Nemotron project.</description>
        </item>
        <item>
            <title>X2HDR: HDR Image Generation in a Perceptually Uniform Space</title>
            <link>https://tldr.takara.ai/p/2602.04814</link>
            <guid>https://tldr.takara.ai/p/2602.04814</guid>
            <pubDate>Wed, 04 Feb 2026 17:59:51 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.04814">HF Daily Papers</source>
            <category>open-source</category>
            <description>High-dynamic-range (HDR) formats and displays are becoming increasingly prevalent, yet state-of-the-art image generators (e.g., Stable Diffusion and FLUX) typically remain limited to low-dynamic-range (LDR) output due to the lack of large-scale HDR training data. In this work, we show that existing...</description>
        </item>
        <item>
            <title>VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?</title>
            <link>https://tldr.takara.ai/p/2602.04802</link>
            <guid>https://tldr.takara.ai/p/2602.04802</guid>
            <pubDate>Wed, 04 Feb 2026 17:48:55 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.04802">HF Daily Papers</source>
            <category>open-source</category>
            <description>Vision-Language Models (VLMs) have achieved impressive performance in cross-modal understanding across textual and visual inputs, yet existing benchmarks predominantly focus on pure-text queries. In real-world scenarios, language also frequently appears as visualized text embedded in images,...</description>
        </item>
        <item>
            <title>ChatGPT Availability Impacted</title>
            <link>https://status.openai.com//incidents/01KGMVV926ZSCD1MSDBS07AWYA</link>
            <guid>https://status.openai.com//incidents/01KGMVV926ZSCD1MSDBS07AWYA</guid>
            <pubDate>Wed, 04 Feb 2026 17:43:00 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KGMVV926ZSCD1MSDBS07AWYA">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: MonitoringWe have applied the mitigation and are monitoring the recovery.Affected components File uploads (Operational) GPTs (Operational) Deep Research (Operational) Codex (Operational) Connectors/Apps (Operational) ChatGPT Atlas (Operational) Login (Operational) Voice mode (Operational)...</description>
        </item>
        <item>
            <title>Interval-Based AUC (iAUC): Extending ROC Analysis to Uncertainty-Aware Classification</title>
            <link>https://tldr.takara.ai/p/2602.04775</link>
            <guid>https://tldr.takara.ai/p/2602.04775</guid>
            <pubDate>Wed, 04 Feb 2026 17:12:04 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.04775">HF Daily Papers</source>
            <category>open-source</category>
            <description>In high-stakes risk prediction, quantifying uncertainty through interval-valued predictions is essential for reliable decision-making. However, standard evaluation tools like the receiver operating characteristic (ROC) curve and the area under the curve (AUC) are designed for point scores and fail...</description>
        </item>
        <item>
            <title>Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty</title>
            <link>https://tldr.takara.ai/p/2602.04763</link>
            <guid>https://tldr.takara.ai/p/2602.04763</guid>
            <pubDate>Wed, 04 Feb 2026 17:01:31 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.04763">HF Daily Papers</source>
            <category>open-source</category>
            <description>Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and...</description>
        </item>
        <item>
            <title>Elevated errors on Claude models</title>
            <link>https://status.claude.com/incidents/pvbysfjjrf8m</link>
            <guid>https://status.claude.com/incidents/pvbysfjjrf8m</guid>
            <pubDate>Wed, 04 Feb 2026 16:53:31 +0000</pubDate>
            <source url="https://status.claude.com/incidents/pvbysfjjrf8m">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 4, 16:53 UTCIdentified - The issue has been identified and a fix is being implemented.Feb 4, 16:39 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3’s Top Model</title>
            <link>https://huggingface.co/blog/nvidia/nemotron-colembed-v2</link>
            <guid>https://huggingface.co/blog/nvidia/nemotron-colembed-v2</guid>
            <pubDate>Wed, 04 Feb 2026 15:00:40 +0000</pubDate>
            <source url="https://huggingface.co/blog/nvidia/nemotron-colembed-v2">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
        <item>
            <title>From guardrails to governance: A CEO’s guide for securing agentic systems</title>
            <link>https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/</link>
            <guid>https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/</guid>
            <pubDate>Wed, 04 Feb 2026 14:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/">MIT Tech Review AI</source>
            <category>research</category>
            <description>The previous article in this series, “Rules fail at the prompt, succeed at the boundary,” focused on the first AI-orchestrated espionage campaign and the failure of prompt-level control. This article is the prescription. The question every CEO is now getting from their board is some version of:...</description>
        </item>
    </channel>
</rss>

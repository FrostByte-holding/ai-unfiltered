<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI Unfiltered</title>
        <link>https://ai-unfiltered.com/</link>
        <description>Chinese AI • Open Source • Security • Incidents. Signal, not noise.</description>
        <language>en-us</language>
        <lastBuildDate>Thu, 19 Feb 2026 05:22:31 +0000</lastBuildDate>
        <atom:link href="https://ai-unfiltered.com/rss.xml" rel="self" type="application/rss+xml"/>
        
        <item>
            <title>Towards Efficient Constraint Handling in Neural Solvers for Routing Problems</title>
            <link>https://arxiv.org/abs/2602.16012</link>
            <guid>https://arxiv.org/abs/2602.16012</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.16012">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.16012v1 Announce Type: new Abstract: Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling...</description>
        </item>
        <item>
            <title>Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection</title>
            <link>https://arxiv.org/abs/2602.16037</link>
            <guid>https://arxiv.org/abs/2602.16037</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.16037">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.16037v1 Announce Type: new Abstract: Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement...</description>
        </item>
        <item>
            <title>How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment</title>
            <link>https://arxiv.org/abs/2602.16039</link>
            <guid>https://arxiv.org/abs/2602.16039</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.16039">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.16039v1 Announce Type: new Abstract: The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they...</description>
        </item>
        <item>
            <title>Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination</title>
            <link>https://arxiv.org/abs/2602.16050</link>
            <guid>https://arxiv.org/abs/2602.16050</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.16050">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.16050v1 Announce Type: new Abstract: Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated...</description>
        </item>
        <item>
            <title>Improving Interactive In-Context Learning from Natural Language Feedback</title>
            <link>https://arxiv.org/abs/2602.16066</link>
            <guid>https://arxiv.org/abs/2602.16066</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.16066">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.16066v1 Announce Type: new Abstract: Adapting one&#x27;s thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static...</description>
        </item>
        <item>
            <title>A Koopman-Bayesian Framework for High-Fidelity, Perceptually Optimized Haptic Surgical Simulation</title>
            <link>https://arxiv.org/abs/2602.15834</link>
            <guid>https://arxiv.org/abs/2602.15834</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.15834">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.15834v1 Announce Type: new Abstract: We introduce a unified framework that combines nonlinear dynamics, perceptual psychophysics and high frequency haptic rendering to enhance realism in surgical simulation. The interaction of the surgical device with soft tissue is elevated to an...</description>
        </item>
        <item>
            <title>Memes-as-Replies: Can Models Select Humorous Manga Panel Responses?</title>
            <link>https://arxiv.org/abs/2602.15842</link>
            <guid>https://arxiv.org/abs/2602.15842</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.15842">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.15842v1 Announce Type: new Abstract: Memes are a popular element of modern web communication, used not only as static artifacts but also as interactive replies within conversations. While computational research has focused on analyzing the intrinsic properties of memes, the dynamic and...</description>
        </item>
        <item>
            <title>Kalman-Inspired Runtime Stability and Recovery in Hybrid Reasoning Systems</title>
            <link>https://arxiv.org/abs/2602.15855</link>
            <guid>https://arxiv.org/abs/2602.15855</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.15855">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.15855v1 Announce Type: new Abstract: Hybrid reasoning systems that combine learned components with model-based inference are increasingly deployed in tool-augmented decision loops, yet their runtime behavior under partial observability and sustained evidence mismatch remains poorly...</description>
        </item>
        <item>
            <title>Genetic Generalized Additive Models</title>
            <link>https://arxiv.org/abs/2602.15877</link>
            <guid>https://arxiv.org/abs/2602.15877</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.15877">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.15877v1 Announce Type: new Abstract: Generalized Additive Models (GAMs) balance predictive accuracy and interpretability, but manually configuring their structure is challenging. We propose using the multi-objective genetic algorithm NSGA-II to automatically optimize GAMs, jointly...</description>
        </item>
        <item>
            <title>IT-OSE: Exploring Optimal Sample Size for Industrial Data Augmentation</title>
            <link>https://arxiv.org/abs/2602.15878</link>
            <guid>https://arxiv.org/abs/2602.15878</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.15878">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.15878v1 Announce Type: new Abstract: In industrial scenarios, data augmentation is an effective approach to improve model performance. However, its benefits are not unidirectionally beneficial. There is no theoretical research or established estimation for the optimal sample size (OSS)...</description>
        </item>
        <item>
            <title>The Perplexity Paradox: Why Code Compresses Better Than Math in LLM Prompts</title>
            <link>https://arxiv.org/abs/2602.15843</link>
            <guid>https://arxiv.org/abs/2602.15843</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.15843">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.15843v1 Announce Type: new Abstract: In &quot;Compress or Route?&quot; (Johnson, 2026), we found that code generation tolerates aggressive prompt compression (r &gt;= 0.6) while chain-of-thought reasoning degrades gradually. That study was limited to HumanEval (164 problems), left the &quot;perplexity...</description>
        </item>
        <item>
            <title>Language Model Representations for Efficient Few-Shot Tabular Classification</title>
            <link>https://arxiv.org/abs/2602.15844</link>
            <guid>https://arxiv.org/abs/2602.15844</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.15844">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.15844v1 Announce Type: new Abstract: The Web is a rich source of structured data in the form of tables, from product catalogs and knowledge bases to scientific datasets. However, the heterogeneity of the structure and semantics of these tables makes it challenging to build a unified...</description>
        </item>
        <item>
            <title>KD4MT: A Survey of Knowledge Distillation for Machine Translation</title>
            <link>https://arxiv.org/abs/2602.15845</link>
            <guid>https://arxiv.org/abs/2602.15845</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.15845">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.15845v1 Announce Type: new Abstract: Knowledge Distillation (KD) as a research area has gained a lot of traction in recent years as a compression tool to address challenges related to ever-larger models in NLP. Remarkably, Machine Translation (MT) offers a much more nuanced take on this...</description>
        </item>
        <item>
            <title>Gated Tree Cross-attention for Checkpoint-Compatible Syntax Injection in Decoder-Only LLMs</title>
            <link>https://arxiv.org/abs/2602.15846</link>
            <guid>https://arxiv.org/abs/2602.15846</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.15846">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.15846v1 Announce Type: new Abstract: Decoder-only large language models achieve strong broad performance but are brittle to minor grammatical perturbations, undermining reliability for downstream reasoning. However, directly injecting explicit syntactic structure into an existing...</description>
        </item>
        <item>
            <title>Do Personality Traits Interfere? Geometric Limitations of Steering in Large Language Models</title>
            <link>https://arxiv.org/abs/2602.15847</link>
            <guid>https://arxiv.org/abs/2602.15847</guid>
            <pubDate>Thu, 19 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.15847">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.15847v1 Announce Type: new Abstract: Personality steering in large language models (LLMs) commonly relies on injecting trait-specific steering vectors, implicitly assuming that personality traits can be controlled independently. In this work, we examine whether this assumption holds by...</description>
        </item>
        <item>
            <title>Occasional loss of WARP connectivity on iOS</title>
            <link>https://www.cloudflarestatus.com/incidents/q2dl751rxp53</link>
            <guid>https://www.cloudflarestatus.com/incidents/q2dl751rxp53</guid>
            <pubDate>Thu, 19 Feb 2026 03:36:54 +0000</pubDate>
            <source url="https://www.cloudflarestatus.com/incidents/q2dl751rxp53">Cloudflare Status</source>
            <category>incidents</category>
            <description>Feb 19, 03:36 UTCIdentified - Cloudflare has identified an issue with WARP connectivity on iOS and a fix is being implemented. It is possible for the latest version of the Cloudflare One Agent app on iOS to end up in a bad state where it cannot connect to Cloudflare&#x27;s edge network. When the app is...</description>
        </item>
        <item>
            <title>The Reasonable Effectiveness of Virtue Ethics in AI Alignment</title>
            <link>https://thegradient.pub/virtue-ethics-ai-alignment/</link>
            <guid>https://thegradient.pub/virtue-ethics-ai-alignment/</guid>
            <pubDate>Wed, 18 Feb 2026 23:25:52 +0000</pubDate>
            <source url="https://thegradient.pub/virtue-ethics-ai-alignment/">The Gradient</source>
            <category>open-source</category>
            <description>Preface This essay argues that rational people don&amp;#x2019;t have goals, and that rational AIs shouldn&amp;#x2019;t have goals. Human actions are rational not because we direct them at some final &amp;#x2018;goals,&amp;#x2019; but because we align actions to practices[1]: networks of actions,...</description>
        </item>
        <item>
            <title>Workers AI elevated error rates</title>
            <link>https://www.cloudflarestatus.com/incidents/vbnc13cks551</link>
            <guid>https://www.cloudflarestatus.com/incidents/vbnc13cks551</guid>
            <pubDate>Wed, 18 Feb 2026 19:47:40 +0000</pubDate>
            <source url="https://www.cloudflarestatus.com/incidents/vbnc13cks551">Cloudflare Status</source>
            <category>incidents</category>
            <description>Feb 18, 19:47 UTCMonitoring - A fix has been implemented and we are monitoring the results.Feb 18, 18:42 UTCIdentified - Users might experience higher 429 errors</description>
        </item>
        <item>
            <title>Degraded performance in merge queue</title>
            <link>https://www.githubstatus.com/incidents/p1ymhg64hdfq</link>
            <guid>https://www.githubstatus.com/incidents/p1ymhg64hdfq</guid>
            <pubDate>Wed, 18 Feb 2026 19:20:16 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/p1ymhg64hdfq">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 18, 19:20 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Feb 18, 19:18 UTCUpdate - We have seen significant recovery in merge queue we are...</description>
        </item>
        <item>
            <title>Citizen Lab Finds Cellebrite Tool Used on Kenyan Activist’s Phone in Police Custody</title>
            <link>https://thehackernews.com/2026/02/citizen-lab-finds-cellebrite-tool-used.html</link>
            <guid>https://thehackernews.com/2026/02/citizen-lab-finds-cellebrite-tool-used.html</guid>
            <pubDate>Wed, 18 Feb 2026 17:30:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/citizen-lab-finds-cellebrite-tool-used.html">The Hacker News</source>
            <category>security</category>
            <description>New research from the Citizen Lab has found signs that Kenyan authorities used a commercial forensic extraction tool manufactured by Israeli company Cellebrite to break into a prominent dissident&#x27;s phone, making it the latest case of abuse of the technology targeting civil society. The...</description>
        </item>
        <item>
            <title>Sora 2 Degraded Performance</title>
            <link>https://status.openai.com//incidents/01KHRP7P1JF885BYA8SDWBDBR1</link>
            <guid>https://status.openai.com//incidents/01KHRP7P1JF885BYA8SDWBDBR1</guid>
            <pubDate>Wed, 18 Feb 2026 16:40:22 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KHRP7P1JF885BYA8SDWBDBR1">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: ResolvedAll impacted services have now fully recovered.Affected components Video generation (Operational)</description>
        </item>
        <item>
            <title>Grandstream GXP1600 VoIP Phones Exposed to Unauthenticated Remote Code Execution</title>
            <link>https://thehackernews.com/2026/02/grandstream-gxp1600-voip-phones-exposed.html</link>
            <guid>https://thehackernews.com/2026/02/grandstream-gxp1600-voip-phones-exposed.html</guid>
            <pubDate>Wed, 18 Feb 2026 16:35:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/grandstream-gxp1600-voip-phones-exposed.html">The Hacker News</source>
            <category>security</category>
            <description>Cybersecurity researchers have disclosed a critical security flaw in the Grandstream GXP1600 series of VoIP phones that could allow an attacker to seize control of susceptible devices. The vulnerability, tracked as CVE-2026-2329, carries a CVSS score of 9.3 out of a maximum of 10.0. It has been...</description>
        </item>
        <item>
            <title>IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST</title>
            <link>https://huggingface.co/blog/ibm-research/itbenchandmast</link>
            <guid>https://huggingface.co/blog/ibm-research/itbenchandmast</guid>
            <pubDate>Wed, 18 Feb 2026 16:15:45 +0000</pubDate>
            <source url="https://huggingface.co/blog/ibm-research/itbenchandmast">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
        <item>
            <title>A new way to express yourself: Gemini can now create music</title>
            <link>https://deepmind.google/blog/a-new-way-to-express-yourself-gemini-can-now-create-music/</link>
            <guid>https://deepmind.google/blog/a-new-way-to-express-yourself-gemini-can-now-create-music/</guid>
            <pubDate>Wed, 18 Feb 2026 16:01:38 +0000</pubDate>
            <source url="https://deepmind.google/blog/a-new-way-to-express-yourself-gemini-can-now-create-music/">DeepMind Blog</source>
            <category>research</category>
            <description>The Gemini app now features our most advanced music generation model Lyria 3, empowering anyone to make 30-second tracks using text or images.</description>
        </item>
        <item>
            <title>Google DeepMind wants to know if chatbots are just virtue signaling</title>
            <link>https://www.technologyreview.com/2026/02/18/1133299/google-deepmind-wants-to-know-if-chatbots-are-just-virtue-signaling/</link>
            <guid>https://www.technologyreview.com/2026/02/18/1133299/google-deepmind-wants-to-know-if-chatbots-are-just-virtue-signaling/</guid>
            <pubDate>Wed, 18 Feb 2026 16:00:22 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/18/1133299/google-deepmind-wants-to-know-if-chatbots-are-just-virtue-signaling/">MIT Tech Review AI</source>
            <category>research</category>
            <description>Google DeepMind is calling for the moral behavior of large language models—such as what they do when called on to act as companions, therapists, medical advisors, and so on—to be scrutinized with the same kind of rigor as their ability to code or do math. As LLMs improve, people are asking them to...</description>
        </item>
        <item>
            <title>Elevated error rates across multiple models</title>
            <link>https://status.claude.com/incidents/kqxx66h5qsy2</link>
            <guid>https://status.claude.com/incidents/kqxx66h5qsy2</guid>
            <pubDate>Wed, 18 Feb 2026 15:59:55 +0000</pubDate>
            <source url="https://status.claude.com/incidents/kqxx66h5qsy2">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 18, 15:59 UTCUpdate - We are continuing to monitor for any further issues.Feb 18, 15:47 UTCMonitoring - A fix has been implemented and we are monitoring the results.Feb 18, 15:36 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>New Keenadu Android Malware Found on Thousands of Devices</title>
            <link>https://www.securityweek.com/new-keenadu-android-malware-found-on-thousands-of-devices/</link>
            <guid>https://www.securityweek.com/new-keenadu-android-malware-found-on-thousands-of-devices/</guid>
            <pubDate>Wed, 18 Feb 2026 15:41:25 +0000</pubDate>
            <source url="https://www.securityweek.com/new-keenadu-android-malware-found-on-thousands-of-devices/">Security Week</source>
            <category>security</category>
            <description>The malware has been preinstalled on many devices but it has also been distributed through Google Play and other app stores. The post New Keenadu Android Malware Found on Thousands of Devices appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Elevated errors on Claude Sonnet 4.6</title>
            <link>https://status.claude.com/incidents/3qnc3g20hgp8</link>
            <guid>https://status.claude.com/incidents/3qnc3g20hgp8</guid>
            <pubDate>Wed, 18 Feb 2026 15:35:30 +0000</pubDate>
            <source url="https://status.claude.com/incidents/3qnc3g20hgp8">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 18, 15:35 UTCResolved - This incident has been resolved.Feb 18, 14:22 UTCMonitoring - A fix has been implemented and we are monitoring the results.Feb 18, 13:29 UTCIdentified - The issue has been identified and a fix is being implemented.Feb 18, 13:20 UTCInvestigating - We are currently...</description>
        </item>
        <item>
            <title>Cogent Security Raises $42 Million for AI-Driven Vulnerability Management</title>
            <link>https://www.securityweek.com/cogent-security-raises-42-million-for-ai-driven-vulnerability-management/</link>
            <guid>https://www.securityweek.com/cogent-security-raises-42-million-for-ai-driven-vulnerability-management/</guid>
            <pubDate>Wed, 18 Feb 2026 14:47:07 +0000</pubDate>
            <source url="https://www.securityweek.com/cogent-security-raises-42-million-for-ai-driven-vulnerability-management/">Security Week</source>
            <category>security</category>
            <description>The Series A funding round, led by Bain Capital, brings the total raised by Cogent to $53 million. The post Cogent Security Raises $42 Million for AI-Driven Vulnerability Management appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Vulnerabilities in Popular PDF Platforms Allowed Account Takeover, Data Exfiltration</title>
            <link>https://www.securityweek.com/vulnerabilities-in-popular-pdf-platforms-allowed-account-takeover-data-exfiltration/</link>
            <guid>https://www.securityweek.com/vulnerabilities-in-popular-pdf-platforms-allowed-account-takeover-data-exfiltration/</guid>
            <pubDate>Wed, 18 Feb 2026 13:16:19 +0000</pubDate>
            <source url="https://www.securityweek.com/vulnerabilities-in-popular-pdf-platforms-allowed-account-takeover-data-exfiltration/">Security Week</source>
            <category>security</category>
            <description>Novee researchers discovered 16 vulnerabilities in Foxit and Apryse PDF tools that could have been exploited via malicious documents or URLs. The post Vulnerabilities in Popular PDF Platforms Allowed Account Takeover, Data Exfiltration appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Critical Flaws Found in Four VS Code Extensions with Over 125 Million Installs</title>
            <link>https://thehackernews.com/2026/02/critical-flaws-found-in-four-vs-code.html</link>
            <guid>https://thehackernews.com/2026/02/critical-flaws-found-in-four-vs-code.html</guid>
            <pubDate>Wed, 18 Feb 2026 13:16:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/critical-flaws-found-in-four-vs-code.html">The Hacker News</source>
            <category>security</category>
            <description>Cybersecurity researchers have disclosed multiple security vulnerabilities in four popular Microsoft Visual Studio Code (VS Code) extensions that, if successfully exploited, could allow threat actors to steal local files and execute code remotely. The extensions, which have been collectively...</description>
        </item>
        <item>
            <title>The Download: a blockchain enigma, and the algorithms governing our lives</title>
            <link>https://www.technologyreview.com/2026/02/18/1133291/the-download-a-blockchain-enigma-and-the-algorithms-governing-our-lives/</link>
            <guid>https://www.technologyreview.com/2026/02/18/1133291/the-download-a-blockchain-enigma-and-the-algorithms-governing-our-lives/</guid>
            <pubDate>Wed, 18 Feb 2026 13:10:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/18/1133291/the-download-a-blockchain-enigma-and-the-algorithms-governing-our-lives/">MIT Tech Review AI</source>
            <category>research</category>
            <description>This is today&amp;#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&amp;#8217;s going on in the world of technology. Welcome to the dark side of crypto’s permissionless dream Jean-Paul Thorbjornsen, an Australian man in his mid-30s, with a rural Catholic upbringing,...</description>
        </item>
        <item>
            <title>Elevated errors on Claude Opus 4.5</title>
            <link>https://status.claude.com/incidents/cn4x4rg7cg0l</link>
            <guid>https://status.claude.com/incidents/cn4x4rg7cg0l</guid>
            <pubDate>Wed, 18 Feb 2026 12:09:10 +0000</pubDate>
            <source url="https://status.claude.com/incidents/cn4x4rg7cg0l">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 18, 12:09 UTCResolved - This incident has been resolved.Feb 18, 11:56 UTCUpdate - We are continuing to monitor for any further issues.Feb 18, 11:42 UTCMonitoring - A fix has been implemented and we are monitoring the results.Feb 18, 10:49 UTCIdentified - The issue has been identified and a fix...</description>
        </item>
        <item>
            <title>Cybersecurity Tech Predictions for 2026: Operating in a World of Permanent Instability</title>
            <link>https://thehackernews.com/2026/02/cybersecurity-tech-predictions-for-2026.html</link>
            <guid>https://thehackernews.com/2026/02/cybersecurity-tech-predictions-for-2026.html</guid>
            <pubDate>Wed, 18 Feb 2026 11:58:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/cybersecurity-tech-predictions-for-2026.html">The Hacker News</source>
            <category>security</category>
            <description>In 2025, navigating the digital seas still felt like a matter of direction. Organizations charted routes, watched the horizon, and adjusted course to reach safe harbors of resilience, trust, and compliance. In 2026, the seas are no longer calm between storms. Cybersecurity now unfolds in a state...</description>
        </item>
        <item>
            <title>The robots who predict the future</title>
            <link>https://www.technologyreview.com/2026/02/18/1132579/robots-predict-future-book-review/</link>
            <guid>https://www.technologyreview.com/2026/02/18/1132579/robots-predict-future-book-review/</guid>
            <pubDate>Wed, 18 Feb 2026 11:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/18/1132579/robots-predict-future-book-review/">MIT Tech Review AI</source>
            <category>research</category>
            <description>To be human is, fundamentally, to be a forecaster. Occasionally a pretty good one. Trying to see the future, whether through the lens of past experience or the logic of cause and effect, has helped us hunt, avoid being hunted, plant crops, forge social bonds, and in general survive in a world that...</description>
        </item>
        <item>
            <title>Welcome to the dark side of crypto’s permissionless dream</title>
            <link>https://www.technologyreview.com/2026/02/18/1132587/jean-paul-thorbjornsen-dark-side-crypto-permissionless-dream/</link>
            <guid>https://www.technologyreview.com/2026/02/18/1132587/jean-paul-thorbjornsen-dark-side-crypto-permissionless-dream/</guid>
            <pubDate>Wed, 18 Feb 2026 11:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/18/1132587/jean-paul-thorbjornsen-dark-side-crypto-permissionless-dream/">MIT Tech Review AI</source>
            <category>research</category>
            <description>“We’re out of airspace now. We can do whatever we want,” Jean-Paul Thorbjornsen tells me from the pilot’s seat of his Aston Martin helicopter. As we fly over suburbs outside Melbourne, Australia, it’s becoming clear that doing whatever he wants is Thorbjornsen’s MO.&amp;#160; Upper-middle-class homes...</description>
        </item>
        <item>
            <title>Dell RecoverPoint for VMs Zero-Day CVE-2026-22769 Exploited Since Mid-2024</title>
            <link>https://thehackernews.com/2026/02/dell-recoverpoint-for-vms-zero-day-cve.html</link>
            <guid>https://thehackernews.com/2026/02/dell-recoverpoint-for-vms-zero-day-cve.html</guid>
            <pubDate>Wed, 18 Feb 2026 10:32:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/dell-recoverpoint-for-vms-zero-day-cve.html">The Hacker News</source>
            <category>security</category>
            <description>A maximum severity security vulnerability in Dell RecoverPoint for Virtual Machines has been exploited as a zero-day by a suspected China-nexus threat cluster dubbed UNC6201 since mid-2024, according to a new report from Google Mandiant and Google Threat Intelligence Group (GTIG). The activity...</description>
        </item>
        <item>
            <title>CISA: Hackers Exploiting Vulnerability in Product of Taiwan Security Firm TeamT5</title>
            <link>https://www.securityweek.com/cisa-hackers-exploiting-vulnerability-in-product-of-taiwan-security-firm-teamt5/</link>
            <guid>https://www.securityweek.com/cisa-hackers-exploiting-vulnerability-in-product-of-taiwan-security-firm-teamt5/</guid>
            <pubDate>Wed, 18 Feb 2026 10:26:03 +0000</pubDate>
            <source url="https://www.securityweek.com/cisa-hackers-exploiting-vulnerability-in-product-of-taiwan-security-firm-teamt5/">Security Week</source>
            <category>security</category>
            <description>The vulnerability added to CISA’s KEV catalog affects ThreatSonar Anti-Ransomware and it was patched in 2024. The post CISA: Hackers Exploiting Vulnerability in Product of Taiwan Security Firm TeamT5 appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Palo Alto Networks to Acquire Koi in Reported $400 Million Transaction</title>
            <link>https://www.securityweek.com/palo-alto-networks-to-acquire-koi-in-reported-400-million-transaction/</link>
            <guid>https://www.securityweek.com/palo-alto-networks-to-acquire-koi-in-reported-400-million-transaction/</guid>
            <pubDate>Wed, 18 Feb 2026 08:24:46 +0000</pubDate>
            <source url="https://www.securityweek.com/palo-alto-networks-to-acquire-koi-in-reported-400-million-transaction/">Security Week</source>
            <category>security</category>
            <description>Koi has developed an endpoint security solution that Palo Alto will use to enhance its products. The post Palo Alto Networks to Acquire Koi in Reported $400 Million Transaction appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>[AINews] Claude Sonnet 4.6: clean upgrade of 4.5, mostly better with some caveats</title>
            <link>https://www.latent.space/p/ainews-claude-sonnet-46-clean-upgrade</link>
            <guid>https://www.latent.space/p/ainews-claude-sonnet-46-clean-upgrade</guid>
            <pubDate>Wed, 18 Feb 2026 06:48:36 +0000</pubDate>
            <source url="https://www.latent.space/p/ainews-claude-sonnet-46-clean-upgrade">Latent Space</source>
            <category>open-source</category>
            <description>Anthropic notches another W.</description>
        </item>
        <item>
            <title>Cowork new task page not loading</title>
            <link>https://status.claude.com/incidents/ftrsh0r62qks</link>
            <guid>https://status.claude.com/incidents/ftrsh0r62qks</guid>
            <pubDate>Wed, 18 Feb 2026 04:07:16 +0000</pubDate>
            <source url="https://status.claude.com/incidents/ftrsh0r62qks">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 18, 04:07 UTCResolved - This incident has been resolved.Feb 18, 03:38 UTCIdentified - The issue has been identified and a fix is being implemented.Feb 18, 03:23 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>CSS errors on Claude.ai</title>
            <link>https://status.claude.com/incidents/d6lxkq6m53yy</link>
            <guid>https://status.claude.com/incidents/d6lxkq6m53yy</guid>
            <pubDate>Wed, 18 Feb 2026 00:10:08 +0000</pubDate>
            <source url="https://status.claude.com/incidents/d6lxkq6m53yy">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 18, 00:10 UTCResolved - This incident has been resolved.Feb 17, 23:59 UTCUpdate - We are continuing to monitor for any further issues.Feb 17, 23:59 UTCMonitoring - A fix has been implemented and we are monitoring the results.Feb 17, 23:56 UTCInvestigating - We are currently investigating this...</description>
        </item>
        <item>
            <title>One-Shot Any Web App with Gradio&#x27;s gr.HTML</title>
            <link>https://huggingface.co/blog/gradio-html-one-shot-apps</link>
            <guid>https://huggingface.co/blog/gradio-html-one-shot-apps</guid>
            <pubDate>Wed, 18 Feb 2026 00:00:00 +0000</pubDate>
            <source url="https://huggingface.co/blog/gradio-html-one-shot-apps">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
        <item>
            <title>NVIDIA Nemotron 2 Nano 9B Japanese: 日本のソブリンAIを支える最先端小規模言語モデル</title>
            <link>https://huggingface.co/blog/nvidia/nemotron-nano-9b-v2-japanese-ja</link>
            <guid>https://huggingface.co/blog/nvidia/nemotron-nano-9b-v2-japanese-ja</guid>
            <pubDate>Tue, 17 Feb 2026 23:28:52 +0000</pubDate>
            <source url="https://huggingface.co/blog/nvidia/nemotron-nano-9b-v2-japanese-ja">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
        <item>
            <title>Intermittent authentication failures on GitHub</title>
            <link>https://www.githubstatus.com/incidents/xs6xtcv196g7</link>
            <guid>https://www.githubstatus.com/incidents/xs6xtcv196g7</guid>
            <pubDate>Tue, 17 Feb 2026 19:06:24 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/xs6xtcv196g7">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 17, 19:06 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Feb 17, 18:55 UTCUpdate - We are continuing to monitor the mitigation and continuing to see...</description>
        </item>
        <item>
            <title>Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching</title>
            <link>https://tldr.takara.ai/p/2602.15827</link>
            <guid>https://tldr.takara.ai/p/2602.15827</guid>
            <pubDate>Tue, 17 Feb 2026 18:59:11 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.15827">HF Daily Papers</source>
            <category>open-source</category>
            <description>While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In particular, agile parkour in complex environments demands not only low-level robustness, but also...</description>
        </item>
        <item>
            <title>The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety</title>
            <link>https://tldr.takara.ai/p/2602.15799</link>
            <guid>https://tldr.takara.ai/p/2602.15799</guid>
            <pubDate>Tue, 17 Feb 2026 18:39:15 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.15799">HF Daily Papers</source>
            <category>open-source</category>
            <description>Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show that the prevailing explanation, that fine-tuning updates should be orthogonal to safety-critical...</description>
        </item>
        <item>
            <title>Neural Scaling Laws for Boosted Jet Tagging</title>
            <link>https://tldr.takara.ai/p/2602.15781</link>
            <guid>https://tldr.takara.ai/p/2602.15781</guid>
            <pubDate>Tue, 17 Feb 2026 18:13:01 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.15781">HF Daily Papers</source>
            <category>open-source</category>
            <description>The success of Large Language Models (LLMs) has established that scaling compute, through joint increases in model capacity and dataset size, is the primary driver of performance in modern machine learning. While machine learning has long been an integral component of High Energy Physics (HEP) data...</description>
        </item>
        <item>
            <title>*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation</title>
            <link>https://tldr.takara.ai/p/2602.15778</link>
            <guid>https://tldr.takara.ai/p/2602.15778</guid>
            <pubDate>Tue, 17 Feb 2026 18:10:00 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.15778">HF Daily Papers</source>
            <category>open-source</category>
            <description>Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that...</description>
        </item>
        <item>
            <title>ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution</title>
            <link>https://tldr.takara.ai/p/2602.15769</link>
            <guid>https://tldr.takara.ai/p/2602.15769</guid>
            <pubDate>Tue, 17 Feb 2026 18:01:35 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.15769">HF Daily Papers</source>
            <category>open-source</category>
            <description>Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users also need to know where those answers come from. In this work, we study structured data...</description>
        </item>
    </channel>
</rss>

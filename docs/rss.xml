<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI Unfiltered</title>
        <link>https://ai-unfiltered.com/</link>
        <description>Chinese AI • Open Source • Security • Incidents. Signal, not noise.</description>
        <language>en-us</language>
        <lastBuildDate>Tue, 03 Feb 2026 08:40:55 +0000</lastBuildDate>
        <atom:link href="https://ai-unfiltered.com/rss.xml" rel="self" type="application/rss+xml"/>
        
        <item>
            <title>Ant Group Launches “AI Credit” Incentive Program to Accelerate Company-Wide AI Adoption</title>
            <link>https://pandaily.com/ant-group-launches-ai-credit-incentive-program-to-accelerate-company-wide-ai-adoption</link>
            <guid>https://pandaily.com/ant-group-launches-ai-credit-incentive-program-to-accelerate-company-wide-ai-adoption</guid>
            <pubDate>Tue, 03 Feb 2026 08:32:15 +0000</pubDate>
            <source url="https://pandaily.com/ant-group-launches-ai-credit-incentive-program-to-accelerate-company-wide-ai-adoption">Pandaily</source>
            <category>chinese-ai</category>
            <description>Ant Group has unveiled the “AI Credit” incentive program to reward breakthrough AI contributions and push the company toward full-scale AI transformation.</description>
        </item>
        <item>
            <title>BYD Officially Launches Its Fourth Major Sub-Brand:Linghui</title>
            <link>https://pandaily.com/byd-officially-launches-its-fourth-major-sub-brand-linghui</link>
            <guid>https://pandaily.com/byd-officially-launches-its-fourth-major-sub-brand-linghui</guid>
            <pubDate>Tue, 03 Feb 2026 08:31:04 +0000</pubDate>
            <source url="https://pandaily.com/byd-officially-launches-its-fourth-major-sub-brand-linghui">Pandaily</source>
            <category>chinese-ai</category>
            <description>BYD has launched Linghui as its fourth independent sub-brand, targeting large-scale B2B mobility with a full lineup of electrified vehicles built on proven platforms.</description>
        </item>
        <item>
            <title>Former Alibaba Executives Join as,Qingtian Rent Launches Nationwide City Partner Strategy</title>
            <link>https://pandaily.com/former-alibaba-executives-join-as-qingtian-rent-launches-nationwide-city-partner-strategy</link>
            <guid>https://pandaily.com/former-alibaba-executives-join-as-qingtian-rent-launches-nationwide-city-partner-strategy</guid>
            <pubDate>Tue, 03 Feb 2026 08:26:06 +0000</pubDate>
            <source url="https://pandaily.com/former-alibaba-executives-join-as-qingtian-rent-launches-nationwide-city-partner-strategy">Pandaily</source>
            <category>chinese-ai</category>
            <description>Qingtian Rent is strengthening its leadership team with former Alibaba executives while rolling out a nationwide city partner strategy to accelerate scalable robot leasing services.</description>
        </item>
        <item>
            <title>Deep Intelligent Pharma Raises Another US$60 Million in New Financing Round</title>
            <link>https://pandaily.com/deep-intelligent-pharma-raises-another-us-60-million-in-new-financing-round</link>
            <guid>https://pandaily.com/deep-intelligent-pharma-raises-another-us-60-million-in-new-financing-round</guid>
            <pubDate>Tue, 03 Feb 2026 08:23:13 +0000</pubDate>
            <source url="https://pandaily.com/deep-intelligent-pharma-raises-another-us-60-million-in-new-financing-round">Pandaily</source>
            <category>chinese-ai</category>
            <description>Deep Intelligent Pharma has secured another US$60 million in funding as it pushes AI beyond preclinical research toward full-stack, autonomous clinical trial intelligence.</description>
        </item>
        <item>
            <title>X-Humanoid Secures Over US$100 Million in First Market-Oriented Funding Round</title>
            <link>https://pandaily.com/x-humanoid-secures-over-us-100-million-in-first-market-oriented-funding-round</link>
            <guid>https://pandaily.com/x-humanoid-secures-over-us-100-million-in-first-market-oriented-funding-round</guid>
            <pubDate>Tue, 03 Feb 2026 08:19:06 +0000</pubDate>
            <source url="https://pandaily.com/x-humanoid-secures-over-us-100-million-in-first-market-oriented-funding-round">Pandaily</source>
            <category>chinese-ai</category>
            <description>X-Humanoid has raised over US$100 million in its first market-oriented funding round, accelerating the commercialization and large-scale deployment of its embodied intelligence humanoid robots.</description>
        </item>
        <item>
            <title>[AINews] OpenAI Codex App: death of the VSCode fork, multitasking worktrees, Skills Automations</title>
            <link>https://www.latent.space/p/ainews-openai-codex-app-death-of</link>
            <guid>https://www.latent.space/p/ainews-openai-codex-app-death-of</guid>
            <pubDate>Tue, 03 Feb 2026 07:35:33 +0000</pubDate>
            <source url="https://www.latent.space/p/ainews-openai-codex-app-death-of">Latent Space</source>
            <category>open-source</category>
            <description>The meta is moving fast.</description>
        </item>
        <item>
            <title>Mozilla Adds One-Click Option to Disable Generative AI Features in Firefox</title>
            <link>https://thehackernews.com/2026/02/mozilla-adds-one-click-option-to.html</link>
            <guid>https://thehackernews.com/2026/02/mozilla-adds-one-click-option-to.html</guid>
            <pubDate>Tue, 03 Feb 2026 05:39:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/mozilla-adds-one-click-option-to.html">The Hacker News</source>
            <category>security</category>
            <description>Mozilla on Monday announced a new controls section in its Firefox desktop browser settings that allows users to completely turn off generative artificial intelligence (GenAI) features. &quot;It provides a single place to block current and future generative AI features in Firefox,&quot; Ajit Varma, head of...</description>
        </item>
        <item>
            <title>Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes</title>
            <link>https://arxiv.org/abs/2602.00053</link>
            <guid>https://arxiv.org/abs/2602.00053</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00053">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00053v1 Announce Type: new Abstract: Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing...</description>
        </item>
        <item>
            <title>Learning to Price: Interpretable Attribute-Level Models for Dynamic Markets</title>
            <link>https://arxiv.org/abs/2602.00188</link>
            <guid>https://arxiv.org/abs/2602.00188</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00188">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00188v1 Announce Type: new Abstract: Dynamic pricing in high-dimensional markets poses fundamental challenges of scalability, uncertainty, and interpretability. Existing low-rank bandit formulations learn efficiently but rely on latent features that obscure how individual product...</description>
        </item>
        <item>
            <title>From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models</title>
            <link>https://arxiv.org/abs/2602.00190</link>
            <guid>https://arxiv.org/abs/2602.00190</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00190">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00190v1 Announce Type: new Abstract: Deep learning agents can achieve high performance in complex game domains without often understanding the underlying causal game mechanics. To address this, we investigate Causal Induction: the ability to infer governing laws from observational data,...</description>
        </item>
        <item>
            <title>Complete Identification of Deep ReLU Neural Networks by Many-Valued Logic</title>
            <link>https://arxiv.org/abs/2602.00266</link>
            <guid>https://arxiv.org/abs/2602.00266</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00266">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00266v1 Announce Type: new Abstract: Deep ReLU neural networks admit nontrivial functional symmetries: vastly different architectures and parameters (weights and biases) can realize the same function. We address the complete identification problem -- given a function f, deriving the...</description>
        </item>
        <item>
            <title>Localizing and Correcting Errors for LLM-based Planners</title>
            <link>https://arxiv.org/abs/2602.00276</link>
            <guid>https://arxiv.org/abs/2602.00276</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00276">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00276v1 Announce Type: new Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities on math and coding, but frequently fail on symbolic classical planning tasks. Our studies, as well as prior work, show that LLM-generated plans routinely violate domain...</description>
        </item>
        <item>
            <title>OGD4All: A Framework for Accessible Interaction with Geospatial Open Government Data Based on Large Language Models</title>
            <link>https://arxiv.org/abs/2602.00012</link>
            <guid>https://arxiv.org/abs/2602.00012</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00012">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.00012v1 Announce Type: new Abstract: We present OGD4All, a transparent, auditable, and reproducible framework based on Large Language Models (LLMs) to enhance citizens&#x27; interaction with geospatial Open Government Data (OGD). The system combines semantic data retrieval, agentic reasoning...</description>
        </item>
        <item>
            <title>Measurement for Opaque Systems: Multi-source Triangulation with Interpretable Machine Learning</title>
            <link>https://arxiv.org/abs/2602.00022</link>
            <guid>https://arxiv.org/abs/2602.00022</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00022">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.00022v1 Announce Type: new Abstract: We propose a measurement framework for difficult-to-access contexts that uses indirect data traces, interpretable machine-learning models, and theory-guided triangulation to fill inaccessible measurement spaces. Many high-stakes systems of scientific...</description>
        </item>
        <item>
            <title>Representation Learning Enhanced Deep Reinforcement Learning for Optimal Operation of Hydrogen-based Multi-Energy Systems</title>
            <link>https://arxiv.org/abs/2602.00027</link>
            <guid>https://arxiv.org/abs/2602.00027</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00027">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.00027v1 Announce Type: new Abstract: Hydrogen-based multi-energy systems (HMES) have emerged as a promising low-carbon and energy-efficient solution, as it can enable the coordinated operation of electricity, heating and cooling supply and demand to enhance operational flexibility,...</description>
        </item>
        <item>
            <title>ELLMPEG: An Edge-based Agentic LLM Video Processing Tool</title>
            <link>https://arxiv.org/abs/2602.00028</link>
            <guid>https://arxiv.org/abs/2602.00028</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00028">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.00028v1 Announce Type: new Abstract: Large language models (LLMs), the foundation of generative AI systems like ChatGPT, are transforming many fields and applications, including multimedia, enabling more advanced content generation, analysis, and interaction. However, cloud-based LLM...</description>
        </item>
        <item>
            <title>RAPTOR-AI for Disaster OODA Loop: Hierarchical Multimodal RAG with Experience-Driven Agentic Decision-Making</title>
            <link>https://arxiv.org/abs/2602.00030</link>
            <guid>https://arxiv.org/abs/2602.00030</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00030">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.00030v1 Announce Type: new Abstract: Effective humanitarian assistance and disaster relief (HADR) requires rapid situational understanding, reliable decision support, and the ability to generalize across diverse and previously unseen disaster contexts. This work introduces an agentic...</description>
        </item>
        <item>
            <title>PPoGA: Predictive Plan-on-Graph with Action for Knowledge Graph Question Answering</title>
            <link>https://arxiv.org/abs/2602.00007</link>
            <guid>https://arxiv.org/abs/2602.00007</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00007">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.00007v1 Announce Type: new Abstract: Large Language Models (LLMs) augmented with Knowledge Graphs (KGs) have advanced complex question answering, yet they often remain susceptible to failure when their initial high-level reasoning plan is flawed. This limitation, analogous to cognitive...</description>
        </item>
        <item>
            <title>Unlocking Electronic Health Records: A Hybrid Graph RAG Approach to Safe Clinical AI for Patient QA</title>
            <link>https://arxiv.org/abs/2602.00009</link>
            <guid>https://arxiv.org/abs/2602.00009</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00009">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.00009v1 Announce Type: new Abstract: Electronic health record (EHR) systems present clinicians with vast repositories of clinical information, creating a significant cognitive burden where critical details are easily overlooked. While Large Language Models (LLMs) offer transformative...</description>
        </item>
        <item>
            <title>G-MemLLM: Gated Latent Memory Augmentation for Long-Context Reasoning in Large Language Models</title>
            <link>https://arxiv.org/abs/2602.00015</link>
            <guid>https://arxiv.org/abs/2602.00015</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00015">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.00015v1 Announce Type: new Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, yet they remain constrained by the finite capacity of their context windows and the inherent difficulty of maintaining long-term factual...</description>
        </item>
        <item>
            <title>PTCBENCH: Benchmarking Contextual Stability of Personality Traits in LLM Systems</title>
            <link>https://arxiv.org/abs/2602.00016</link>
            <guid>https://arxiv.org/abs/2602.00016</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00016">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.00016v1 Announce Type: new Abstract: With the increasing deployment of large language models (LLMs) in affective agents and AI systems, maintaining a consistent and authentic LLM personality becomes critical for user trust and engagement. However, existing work overlooks a fundamental...</description>
        </item>
        <item>
            <title>SafeTalkCoach: Diversity-Driven Multi-Agent Simulation for Parent-Teen Health Conversations</title>
            <link>https://arxiv.org/abs/2602.00017</link>
            <guid>https://arxiv.org/abs/2602.00017</guid>
            <pubDate>Tue, 03 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00017">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.00017v1 Announce Type: new Abstract: The importance of effective parent-child communication about sexual health is widely acknowledged, but real-world data on these conversations is scarce and challenging to collect, due to their private and sensitive nature. Although LLMs have been...</description>
        </item>
        <item>
            <title>Notepad++ Hosting Breach Attributed to China-Linked Lotus Blossom Hacking Group</title>
            <link>https://thehackernews.com/2026/02/notepad-hosting-breach-attributed-to.html</link>
            <guid>https://thehackernews.com/2026/02/notepad-hosting-breach-attributed-to.html</guid>
            <pubDate>Tue, 03 Feb 2026 04:55:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/notepad-hosting-breach-attributed-to.html">The Hacker News</source>
            <category>security</category>
            <description>A China-linked threat actor known as Lotus Blossom has been attributed with medium confidence to the recently discovered compromise of the infrastructure hosting Notepad++. The attack enabled the state-sponsored hacking group to deliver a previously undocumented backdoor codenamed Chrysalis to...</description>
        </item>
        <item>
            <title>Incident with Actions</title>
            <link>https://www.githubstatus.com/incidents/xwn6hjps36ty</link>
            <guid>https://www.githubstatus.com/incidents/xwn6hjps36ty</guid>
            <pubDate>Tue, 03 Feb 2026 00:56:04 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/xwn6hjps36ty">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 3, 00:56 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Feb 3, 00:56 UTCUpdate - Actions is operating normally.Feb 2, 23:50 UTCUpdate - Based on our...</description>
        </item>
        <item>
            <title>Incident with Codespaces</title>
            <link>https://www.githubstatus.com/incidents/t4s6xgbwv60j</link>
            <guid>https://www.githubstatus.com/incidents/t4s6xgbwv60j</guid>
            <pubDate>Tue, 03 Feb 2026 00:54:54 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/t4s6xgbwv60j">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 3, 00:54 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Feb 3, 00:54 UTCUpdate - Codespaces is operating normally.Feb 3, 00:25 UTCUpdate -...</description>
        </item>
        <item>
            <title>Elevated errors on Claude Opus 4.5</title>
            <link>https://status.claude.com/incidents/lvvsg4wy0mhj</link>
            <guid>https://status.claude.com/incidents/lvvsg4wy0mhj</guid>
            <pubDate>Mon, 02 Feb 2026 23:18:43 +0000</pubDate>
            <source url="https://status.claude.com/incidents/lvvsg4wy0mhj">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 2, 23:18 UTCResolved - Users experienced errors on Opus 4.5 between 15:09 PT / 23:09 UTC to 15:15 PT / 23:15.Feb 2, 23:15 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System</title>
            <link>https://tldr.takara.ai/p/2602.02488</link>
            <guid>https://tldr.takara.ai/p/2602.02488</guid>
            <pubDate>Mon, 02 Feb 2026 18:59:04 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.02488">HF Daily Papers</source>
            <category>open-source</category>
            <description>We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with...</description>
        </item>
        <item>
            <title>What we’ve been getting wrong about AI’s truth crisis</title>
            <link>https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/</link>
            <guid>https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/</guid>
            <pubDate>Mon, 02 Feb 2026 18:09:57 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/">MIT Tech Review AI</source>
            <category>research</category>
            <description>This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;#160;sign up here. What would it take to convince you that the era of truth decay we were long warned about—where AI content dupes us, shapes our beliefs even when we catch...</description>
        </item>
        <item>
            <title>Researchers Find 341 Malicious ClawHub Skills Stealing Data from OpenClaw Users</title>
            <link>https://thehackernews.com/2026/02/researchers-find-341-malicious-clawhub.html</link>
            <guid>https://thehackernews.com/2026/02/researchers-find-341-malicious-clawhub.html</guid>
            <pubDate>Mon, 02 Feb 2026 17:49:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/researchers-find-341-malicious-clawhub.html">The Hacker News</source>
            <category>security</category>
            <description>A security audit of 2,857 skills on ClawHub has found 341 malicious skills across multiple campaigns, according to new findings from Koi Security, exposing users to new supply chain risks. ClawHub is a marketplace designed to make it easy for OpenClaw users to find and install third-party skills....</description>
        </item>
        <item>
            <title>Disruption with some GitHub services</title>
            <link>https://www.githubstatus.com/incidents/vj8q32xs2d32</link>
            <guid>https://www.githubstatus.com/incidents/vj8q32xs2d32</guid>
            <pubDate>Mon, 02 Feb 2026 17:43:51 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/vj8q32xs2d32">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 2, 17:43 UTCResolved - This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.Feb 2, 17:42 UTCUpdate - We’ve observed a low rate (~0.01%) of 5xx errors for HTTP-based...</description>
        </item>
        <item>
            <title>Spark: Modular Spiking Neural Networks</title>
            <link>https://tldr.takara.ai/p/2602.02306</link>
            <guid>https://tldr.takara.ai/p/2602.02306</guid>
            <pubDate>Mon, 02 Feb 2026 16:36:58 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.02306">HF Daily Papers</source>
            <category>open-source</category>
            <description>Nowadays, neural networks act as a synonym for artificial intelligence. Present neural network models, although remarkably powerful, are inefficient both in terms of data and energy. Several alternative forms of neural networks have been proposed to address some of these problems. Specifically,...</description>
        </item>
        <item>
            <title>OpenClaw Bug Enables One-Click Remote Code Execution via Malicious Link</title>
            <link>https://thehackernews.com/2026/02/openclaw-bug-enables-one-click-remote.html</link>
            <guid>https://thehackernews.com/2026/02/openclaw-bug-enables-one-click-remote.html</guid>
            <pubDate>Mon, 02 Feb 2026 16:28:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/openclaw-bug-enables-one-click-remote.html">The Hacker News</source>
            <category>security</category>
            <description>A high-severity security flaw has been disclosed in OpenClaw (formerly referred to as Clawdbot and Moltbot) that could allow remote code execution (RCE) through a crafted malicious link. The issue, which is tracked as CVE-2026-25253 (CVSS score: 8.8), has been addressed in version 2026.1.29...</description>
        </item>
        <item>
            <title>Please Don’t Feed the Scattered Lapsus Shiny Hunters</title>
            <link>https://krebsonsecurity.com/2026/02/please-dont-feed-the-scattered-lapsus-shiny-hunters/</link>
            <guid>https://krebsonsecurity.com/2026/02/please-dont-feed-the-scattered-lapsus-shiny-hunters/</guid>
            <pubDate>Mon, 02 Feb 2026 16:15:16 +0000</pubDate>
            <source url="https://krebsonsecurity.com/2026/02/please-dont-feed-the-scattered-lapsus-shiny-hunters/">Krebs on Security</source>
            <category>security</category>
            <description>A prolific data ransom gang that calls itself Scattered Lapsus Shiny Hunters (SLSH) has a distinctive playbook when it seeks to extort payment from victim firms: Harassing, threatening and even swatting executives and their families, all while notifying journalists and… Read More &amp;#187;</description>
        </item>
        <item>
            <title>Microsoft Begins NTLM Phase-Out With Three-Stage Plan to Move Windows to Kerberos</title>
            <link>https://thehackernews.com/2026/02/microsoft-begins-ntlm-phase-out-with.html</link>
            <guid>https://thehackernews.com/2026/02/microsoft-begins-ntlm-phase-out-with.html</guid>
            <pubDate>Mon, 02 Feb 2026 15:59:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/microsoft-begins-ntlm-phase-out-with.html">The Hacker News</source>
            <category>security</category>
            <description>Microsoft has announced a three-phase approach to phase out New Technology LAN Manager (NTLM) as part of its efforts to shift Windows environments toward stronger, Kerberos-based options. The development comes more than two years after the tech giant revealed its plans to deprecate the legacy...</description>
        </item>
        <item>
            <title>ShinyHunters-Branded Extortion Activity Expands, Escalates</title>
            <link>https://www.securityweek.com/shinyhunters-branded-extortion-activity-expands-escalates/</link>
            <guid>https://www.securityweek.com/shinyhunters-branded-extortion-activity-expands-escalates/</guid>
            <pubDate>Mon, 02 Feb 2026 15:28:16 +0000</pubDate>
            <source url="https://www.securityweek.com/shinyhunters-branded-extortion-activity-expands-escalates/">Security Week</source>
            <category>security</category>
            <description>Hackers rely on evolved vishing and login harvesting to compromise SSO credentials for unauthorized MFA enrollment. The post ShinyHunters-Branded Extortion Activity Expands, Escalates appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>MAIN-VLA: Modeling Abstraction of Intention and eNvironment for Vision-Language-Action Models</title>
            <link>https://tldr.takara.ai/p/2602.02212</link>
            <guid>https://tldr.takara.ai/p/2602.02212</guid>
            <pubDate>Mon, 02 Feb 2026 15:17:49 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.02212">HF Daily Papers</source>
            <category>open-source</category>
            <description>Despite significant progress in Visual-Language-Action (VLA), in highly complex and dynamic environments that involve real-time unpredictable interactions (such as 3D open worlds and large-scale PvP games), existing approaches remain inefficient at extracting action-critical signals from redundant...</description>
        </item>
        <item>
            <title>The crucial first step for designing a successful enterprise AI system</title>
            <link>https://www.technologyreview.com/2026/02/02/1131822/the-crucial-first-step-for-designing-a-successful-enterprise-ai-system/</link>
            <guid>https://www.technologyreview.com/2026/02/02/1131822/the-crucial-first-step-for-designing-a-successful-enterprise-ai-system/</guid>
            <pubDate>Mon, 02 Feb 2026 14:20:29 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/02/1131822/the-crucial-first-step-for-designing-a-successful-enterprise-ai-system/">MIT Tech Review AI</source>
            <category>research</category>
            <description>Many organizations rushed into generative AI, only to see pilots fail to deliver value. Now, companies want measurable outcomes—but how do you design for success? At Mistral AI, we partner with global industry leaders to co-design tailored AI solutions that solve their most difficult problems....</description>
        </item>
        <item>
            <title>Open VSX Publisher Account Hijacked in Fresh GlassWorm Attack</title>
            <link>https://www.securityweek.com/open-vsx-publisher-account-hijacked-in-fresh-glassworm-attack/</link>
            <guid>https://www.securityweek.com/open-vsx-publisher-account-hijacked-in-fresh-glassworm-attack/</guid>
            <pubDate>Mon, 02 Feb 2026 14:12:50 +0000</pubDate>
            <source url="https://www.securityweek.com/open-vsx-publisher-account-hijacked-in-fresh-glassworm-attack/">Security Week</source>
            <category>security</category>
            <description>A hacker published malicious versions of four established VS Code extensions to distribute a GlassWorm malware loader. The post Open VSX Publisher Account Hijacked in Fresh GlassWorm Attack appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Training-free score-based diffusion for parameter-dependent stochastic dynamical systems</title>
            <link>https://tldr.takara.ai/p/2602.02113</link>
            <guid>https://tldr.takara.ai/p/2602.02113</guid>
            <pubDate>Mon, 02 Feb 2026 13:54:36 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.02113">HF Daily Papers</source>
            <category>open-source</category>
            <description>Simulating parameter-dependent stochastic differential equations (SDEs) presents significant computational challenges, as separate high-fidelity simulations are typically required for each parameter value of interest. Despite the success of machine learning methods in learning SDE dynamics,...</description>
        </item>
        <item>
            <title>Default ICS Credentials Exploited in Destructive Attack on Polish Energy Facilities</title>
            <link>https://www.securityweek.com/default-ics-credentials-exploited-in-destructive-attack-on-polish-energy-facilities/</link>
            <guid>https://www.securityweek.com/default-ics-credentials-exploited-in-destructive-attack-on-polish-energy-facilities/</guid>
            <pubDate>Mon, 02 Feb 2026 13:50:53 +0000</pubDate>
            <source url="https://www.securityweek.com/default-ics-credentials-exploited-in-destructive-attack-on-polish-energy-facilities/">Security Week</source>
            <category>security</category>
            <description>Poland’s CERT has published a report on the recent attack, providing new details on targeted ICS and attribution. The post Default ICS Credentials Exploited in Destructive Attack on Polish Energy Facilities appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>The Download: inside a deepfake marketplace, and EV batteries’ future</title>
            <link>https://www.technologyreview.com/2026/02/02/1132049/the-download-inside-a-deepfake-marketplace-and-ev-batteries-future/</link>
            <guid>https://www.technologyreview.com/2026/02/02/1132049/the-download-inside-a-deepfake-marketplace-and-ev-batteries-future/</guid>
            <pubDate>Mon, 02 Feb 2026 13:10:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/02/1132049/the-download-inside-a-deepfake-marketplace-and-ev-batteries-future/">MIT Tech Review AI</source>
            <category>research</category>
            <description>This is today&amp;#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&amp;#8217;s going on in the world of technology. Inside the marketplace powering bespoke AI deepfakes of real women Civitai—an online marketplace for buying and selling AI-generated content, backed...</description>
        </item>
        <item>
            <title>Latest open artifacts (#18): Arcee&#x27;s 400B MoE, LiquidAI&#x27;s underrated 1B model, new Kimi, and anticipation of a busy month</title>
            <link>https://www.interconnects.ai/p/latest-open-artifacts-18-arcees-big</link>
            <guid>https://www.interconnects.ai/p/latest-open-artifacts-18-arcees-big</guid>
            <pubDate>Mon, 02 Feb 2026 13:03:33 +0000</pubDate>
            <source url="https://www.interconnects.ai/p/latest-open-artifacts-18-arcees-big">Interconnects</source>
            <category>open-source</category>
            <description>Tons of useful &quot;niche&quot; models and anticipation of big releases coming soon.</description>
        </item>
        <item>
            <title>Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization</title>
            <link>https://tldr.takara.ai/p/2602.02035</link>
            <guid>https://tldr.takara.ai/p/2602.02035</guid>
            <pubDate>Mon, 02 Feb 2026 12:32:28 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.02035">HF Daily Papers</source>
            <category>open-source</category>
            <description>Multi-agent reinforcement learning systems deployed in real-world robotics applications face severe communication constraints that significantly impact coordination effectiveness. We present a framework that combines information bottleneck theory with vector quantization to enable selective,...</description>
        </item>
        <item>
            <title>Cyber Insights 2026: Malware and Cyberattacks in the Age of AI</title>
            <link>https://www.securityweek.com/cyber-insights-2026-malware-and-cyberattacks-in-the-age-of-ai/</link>
            <guid>https://www.securityweek.com/cyber-insights-2026-malware-and-cyberattacks-in-the-age-of-ai/</guid>
            <pubDate>Mon, 02 Feb 2026 12:00:00 +0000</pubDate>
            <source url="https://www.securityweek.com/cyber-insights-2026-malware-and-cyberattacks-in-the-age-of-ai/">Security Week</source>
            <category>security</category>
            <description>Security leaders share how artificial intelligence is changing malware, ransomware, and identity-led intrusions, and how defenses must evolve. The post Cyber Insights 2026: Malware and Cyberattacks in the Age of AI appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Over 1,400 MongoDB Databases Ransacked by Threat Actor</title>
            <link>https://www.securityweek.com/over-1400-mongodb-databases-ransacked-by-threat-actor/</link>
            <guid>https://www.securityweek.com/over-1400-mongodb-databases-ransacked-by-threat-actor/</guid>
            <pubDate>Mon, 02 Feb 2026 11:45:56 +0000</pubDate>
            <source url="https://www.securityweek.com/over-1400-mongodb-databases-ransacked-by-threat-actor/">Security Week</source>
            <category>security</category>
            <description>Of 3,100 unprotected MongoDB instances, half remain compromised, most of them by a single threat actor. The post Over 1,400 MongoDB Databases Ransacked by Threat Actor appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>What’s next for EV batteries in 2026</title>
            <link>https://www.technologyreview.com/2026/02/02/1132042/whats-next-for-ev-batteries-in-2026/</link>
            <guid>https://www.technologyreview.com/2026/02/02/1132042/whats-next-for-ev-batteries-in-2026/</guid>
            <pubDate>Mon, 02 Feb 2026 10:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/02/1132042/whats-next-for-ev-batteries-in-2026/">MIT Tech Review AI</source>
            <category>research</category>
            <description>MIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them&amp;#160;here. Demand for electric vehicles and the batteries that power them has never been hotter. In 2025, EVs made up over a quarter of...</description>
        </item>
        <item>
            <title>Credit purchase issues &amp; delays</title>
            <link>https://status.claude.com/incidents/qtmzycrwksws</link>
            <guid>https://status.claude.com/incidents/qtmzycrwksws</guid>
            <pubDate>Mon, 02 Feb 2026 02:08:22 +0000</pubDate>
            <source url="https://status.claude.com/incidents/qtmzycrwksws">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 2, 02:08 UTCResolved - The incident has been resolvedFeb 1, 23:47 UTCMonitoring - Purchasing has been confirmed working regularly again, since around 2:30pm Pacific Time. Engineers are monitoring to ensure the system stays healthy.Feb 1, 23:08 UTCIdentified - The root cause has been discovered...</description>
        </item>
        <item>
            <title>Elevated errors on Claude Sonnet 4.5</title>
            <link>https://status.claude.com/incidents/9qghqkbxtvml</link>
            <guid>https://status.claude.com/incidents/9qghqkbxtvml</guid>
            <pubDate>Sun, 01 Feb 2026 12:34:49 +0000</pubDate>
            <source url="https://status.claude.com/incidents/9qghqkbxtvml">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 1, 12:34 UTCResolved - As of 2026-02-01 03:55 PT / 11:55 UTC the errors are back to the baseline.Feb 1, 11:48 UTCUpdate - Start of errors 2026-02-01 03:36 PT / 11:36 UTC.Feb 1, 11:47 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>Elevated errors on Claude Opus 4.5</title>
            <link>https://status.claude.com/incidents/y74v1yzcnzvb</link>
            <guid>https://status.claude.com/incidents/y74v1yzcnzvb</guid>
            <pubDate>Sun, 01 Feb 2026 11:42:07 +0000</pubDate>
            <source url="https://status.claude.com/incidents/y74v1yzcnzvb">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 1, 11:42 UTCResolved - The errors have returned to baseline as of 2026-02-01 02:51 / 10:51 UTC.Feb 1, 10:54 UTCUpdate - We are continuing to investigate this issue.Feb 1, 10:54 UTCInvestigating - We are investigating an issue with Opus 4.5 that started at 2026-02-01 02:41 PT / 10:41 UTC.</description>
        </item>
        <item>
            <title>Some users are experiencing memory leaks in Claude Code 2.0.27</title>
            <link>https://status.claude.com/incidents/rl6pphjrc2r4</link>
            <guid>https://status.claude.com/incidents/rl6pphjrc2r4</guid>
            <pubDate>Sat, 31 Jan 2026 20:18:04 +0000</pubDate>
            <source url="https://status.claude.com/incidents/rl6pphjrc2r4">Anthropic Status</source>
            <category>incidents</category>
            <description>Jan 31, 20:18 UTCIdentified - We have identified the problem and are working on a fix. More details can be found in Github issue #22042.</description>
        </item>
    </channel>
</rss>

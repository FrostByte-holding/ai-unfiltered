<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI Unfiltered</title>
        <link>https://ai-unfiltered.com/</link>
        <description>Chinese AI • Open Source • Security • Incidents. Signal, not noise.</description>
        <language>en-us</language>
        <lastBuildDate>Wed, 04 Feb 2026 13:05:53 +0000</lastBuildDate>
        <atom:link href="https://ai-unfiltered.com/rss.xml" rel="self" type="application/rss+xml"/>
        
        <item>
            <title>Custom GPT updates are failing for users</title>
            <link>https://status.openai.com//incidents/01KGMAYN6EHDVR9KB1CQJP4EGR</link>
            <guid>https://status.openai.com//incidents/01KGMAYN6EHDVR9KB1CQJP4EGR</guid>
            <pubDate>Wed, 04 Feb 2026 12:45:05 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KGMAYN6EHDVR9KB1CQJP4EGR">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: InvestigatingWe are investigating reports of update failures for configuration for Custom GPTs.Affected components GPTs (Degraded performance)</description>
        </item>
        <item>
            <title>Varonis Acquisition of AllTrue.ai Valued at $150 Million</title>
            <link>https://www.securityweek.com/varonis-acquisition-of-alltrue-ai-valued-at-150-million/</link>
            <guid>https://www.securityweek.com/varonis-acquisition-of-alltrue-ai-valued-at-150-million/</guid>
            <pubDate>Wed, 04 Feb 2026 12:39:56 +0000</pubDate>
            <source url="https://www.securityweek.com/varonis-acquisition-of-alltrue-ai-valued-at-150-million/">Security Week</source>
            <category>security</category>
            <description>The data security firm has acquired the AI trust, risk, and security management company to expand its capabilities. The post Varonis Acquisition of AllTrue.ai Valued at $150 Million appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Orion Raises $32 Million for Data Security</title>
            <link>https://www.securityweek.com/orion-raises-32-million-for-data-security/</link>
            <guid>https://www.securityweek.com/orion-raises-32-million-for-data-security/</guid>
            <pubDate>Wed, 04 Feb 2026 12:07:13 +0000</pubDate>
            <source url="https://www.securityweek.com/orion-raises-32-million-for-data-security/">Security Week</source>
            <category>security</category>
            <description>The startup will use the funding to accelerate product development and go-to-market operations. The post Orion Raises $32 Million for Data Security appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Orchid Security Introduces Continuous Identity Observability for Enterprise Applications</title>
            <link>https://thehackernews.com/2026/02/orchid-security-introduces-continuous.html</link>
            <guid>https://thehackernews.com/2026/02/orchid-security-introduces-continuous.html</guid>
            <pubDate>Wed, 04 Feb 2026 11:58:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/orchid-security-introduces-continuous.html">The Hacker News</source>
            <category>security</category>
            <description>An innovative approach to discovering, analyzing, and governing identity usage beyond traditional IAM controls. The Challenge: Identity Lives Outside the Identity Stack Identity and access management tools were built to govern users and directories. Modern enterprises run on applications. Over...</description>
        </item>
        <item>
            <title>DockerDash Flaw in Docker AI Assistant Leads to RCE, Data Theft</title>
            <link>https://www.securityweek.com/dockerdash-flaw-in-docker-ai-assistant-leads-to-rce-data-theft/</link>
            <guid>https://www.securityweek.com/dockerdash-flaw-in-docker-ai-assistant-leads-to-rce-data-theft/</guid>
            <pubDate>Wed, 04 Feb 2026 11:34:55 +0000</pubDate>
            <source url="https://www.securityweek.com/dockerdash-flaw-in-docker-ai-assistant-leads-to-rce-data-theft/">Security Week</source>
            <category>security</category>
            <description>The critical vulnerability exists in the contextual trust in MCP Gateway architecture, as instructions are passed without validation. The post DockerDash Flaw in Docker AI Assistant Leads to RCE, Data Theft appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Elevated errors on Claude Opus 4.5 and Sonnet 4.5</title>
            <link>https://status.claude.com/incidents/vcsmyx922y7z</link>
            <guid>https://status.claude.com/incidents/vcsmyx922y7z</guid>
            <pubDate>Wed, 04 Feb 2026 11:11:13 +0000</pubDate>
            <source url="https://status.claude.com/incidents/vcsmyx922y7z">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 4, 11:11 UTCResolved - The issue hs been fully resolved. The timelines are:* 02:00 PT / 10:00 UTC to 02:35 PT / 10:35 UTC* 02:54 PT / 10:54 UTC to 03:01 PT / 11:01 UTCFeb 4, 11:05 UTCMonitoring - A fix has been implemented and we are monitoring the results.Feb 4, 10:59 UTCIdentified - The issue...</description>
        </item>
        <item>
            <title>Cryptominers, Reverse Shells Dropped in Recent React2Shell Attacks</title>
            <link>https://www.securityweek.com/cryptominers-reverse-shells-dropped-in-recent-react2shell-attacks/</link>
            <guid>https://www.securityweek.com/cryptominers-reverse-shells-dropped-in-recent-react2shell-attacks/</guid>
            <pubDate>Wed, 04 Feb 2026 10:00:14 +0000</pubDate>
            <source url="https://www.securityweek.com/cryptominers-reverse-shells-dropped-in-recent-react2shell-attacks/">Security Week</source>
            <category>security</category>
            <description>Two IP addresses accounted for the majority of the 1.4 million exploitation attempts observed over the past week. The post Cryptominers, Reverse Shells Dropped in Recent React2Shell Attacks appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>The First 90 Seconds: How Early Decisions Shape Incident Response Investigations</title>
            <link>https://thehackernews.com/2026/02/the-first-90-seconds-how-early.html</link>
            <guid>https://thehackernews.com/2026/02/the-first-90-seconds-how-early.html</guid>
            <pubDate>Wed, 04 Feb 2026 10:00:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/the-first-90-seconds-how-early.html">The Hacker News</source>
            <category>security</category>
            <description>Many incident response failures do not come from a lack of tools, intelligence, or technical skills. They come from what happens immediately after detection, when pressure is high, and information is incomplete. I have seen IR teams recover from sophisticated intrusions with limited telemetry. I...</description>
        </item>
        <item>
            <title>Security Analysis of Moltbook Agent Network: Bot-to-Bot Prompt Injection and Data Leaks</title>
            <link>https://www.securityweek.com/security-analysis-of-moltbook-agent-network-bot-to-bot-prompt-injection-and-data-leaks/</link>
            <guid>https://www.securityweek.com/security-analysis-of-moltbook-agent-network-bot-to-bot-prompt-injection-and-data-leaks/</guid>
            <pubDate>Wed, 04 Feb 2026 08:43:18 +0000</pubDate>
            <source url="https://www.securityweek.com/security-analysis-of-moltbook-agent-network-bot-to-bot-prompt-injection-and-data-leaks/">Security Week</source>
            <category>security</category>
            <description>Wiz and Permiso have analyzed the AI agent social network and found serious security issues and threats. The post Security Analysis of Moltbook Agent Network: Bot-to-Bot Prompt Injection and Data Leaks appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Mixue Ice Cream &amp; Tea Recruits Theme Park Roles</title>
            <link>https://pandaily.com/mixue-ice-cream-and-tea-recruits-theme-park-roles</link>
            <guid>https://pandaily.com/mixue-ice-cream-and-tea-recruits-theme-park-roles</guid>
            <pubDate>Wed, 04 Feb 2026 08:19:55 +0000</pubDate>
            <source url="https://pandaily.com/mixue-ice-cream-and-tea-recruits-theme-park-roles">Pandaily</source>
            <category>chinese-ai</category>
            <description>Mixue Ice Cream &amp; Tea is hiring multiple theme park roles with salaries starting at RMB 11,000, sparking speculation that the beverage giant may be planning its own branded amusement park.</description>
        </item>
        <item>
            <title>Former TuSimple Unveils First Gameplay PV After Pivot to Gaming</title>
            <link>https://pandaily.com/former-tu-simple-unveils-first-gameplay-pv-after-pivot-to-gaming</link>
            <guid>https://pandaily.com/former-tu-simple-unveils-first-gameplay-pv-after-pivot-to-gaming</guid>
            <pubDate>Wed, 04 Feb 2026 08:17:20 +0000</pubDate>
            <source url="https://pandaily.com/former-tu-simple-unveils-first-gameplay-pv-after-pivot-to-gaming">Pandaily</source>
            <category>chinese-ai</category>
            <description>Former autonomous driving company TuSimple has revealed the first real gameplay footage of its Legend of the Condor Heroes AAA RPG, marking a major step in its pivot to gaming.</description>
        </item>
        <item>
            <title>XPeng Merges Autonomous Driving and Smart Cockpit Units to Form General AI Center</title>
            <link>https://pandaily.com/x-peng-merges-autonomous-driving-and-smart-cockpit-units-to-form-general-ai-center</link>
            <guid>https://pandaily.com/x-peng-merges-autonomous-driving-and-smart-cockpit-units-to-form-general-ai-center</guid>
            <pubDate>Wed, 04 Feb 2026 08:17:16 +0000</pubDate>
            <source url="https://pandaily.com/x-peng-merges-autonomous-driving-and-smart-cockpit-units-to-form-general-ai-center">Pandaily</source>
            <category>chinese-ai</category>
            <description>XPeng has merged its autonomous driving and smart cockpit teams into a General AI Center, accelerating its push toward embodied intelligence across cars and robots.</description>
        </item>
        <item>
            <title>SJTU–Tsinghua Team Builds Edge AI Leader SiMMIR, Secures Two Nine-Figure RMB Funding Rounds</title>
            <link>https://pandaily.com/sjtu-tsinghua-team-builds-edge-ai-leader-si-mmir-secures-two-nine-figure-rmb-funding-rounds</link>
            <guid>https://pandaily.com/sjtu-tsinghua-team-builds-edge-ai-leader-si-mmir-secures-two-nine-figure-rmb-funding-rounds</guid>
            <pubDate>Wed, 04 Feb 2026 08:17:10 +0000</pubDate>
            <source url="https://pandaily.com/sjtu-tsinghua-team-builds-edge-ai-leader-si-mmir-secures-two-nine-figure-rmb-funding-rounds">Pandaily</source>
            <category>chinese-ai</category>
            <description>Edge AI startup SiMMIR has raised over RMB 100 million in back-to-back funding rounds, betting on integrated sensing–computing chips to power the next wave of physical AI.</description>
        </item>
        <item>
            <title>Tencent Launches “Fire Dragon,” Its First AI-Generated Comic Shorts App</title>
            <link>https://pandaily.com/tencent-launches-fire-dragon-its-first-ai-generated-comic-shorts-app</link>
            <guid>https://pandaily.com/tencent-launches-fire-dragon-its-first-ai-generated-comic-shorts-app</guid>
            <pubDate>Wed, 04 Feb 2026 08:17:02 +0000</pubDate>
            <source url="https://pandaily.com/tencent-launches-fire-dragon-its-first-ai-generated-comic-shorts-app">Pandaily</source>
            <category>chinese-ai</category>
            <description>Tencent has launched Fire Dragon, its first AI-generated comic shorts app, signaling a push into short, vertical storytelling aimed squarely at Gen Z.</description>
        </item>
        <item>
            <title>Microsoft Warns Python Infostealers Target macOS via Fake Ads and Installers</title>
            <link>https://thehackernews.com/2026/02/microsoft-warns-python-infostealers.html</link>
            <guid>https://thehackernews.com/2026/02/microsoft-warns-python-infostealers.html</guid>
            <pubDate>Wed, 04 Feb 2026 07:42:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/microsoft-warns-python-infostealers.html">The Hacker News</source>
            <category>security</category>
            <description>Microsoft has warned that information-stealing attacks are &quot;rapidly expanding&quot; beyond Windows to target Apple macOS environments by leveraging cross-platform languages like Python and abusing trusted platforms for distribution at scale. The tech giant&#x27;s Defender Security Research Team said it...</description>
        </item>
        <item>
            <title>Eclipse Foundation Mandates Pre-Publish Security Checks for Open VSX Extensions</title>
            <link>https://thehackernews.com/2026/02/eclipse-foundation-mandates-pre-publish.html</link>
            <guid>https://thehackernews.com/2026/02/eclipse-foundation-mandates-pre-publish.html</guid>
            <pubDate>Wed, 04 Feb 2026 06:26:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/eclipse-foundation-mandates-pre-publish.html">The Hacker News</source>
            <category>security</category>
            <description>The Eclipse Foundation, which maintains the Open VSX Registry, has announced plans to enforce security checks before Microsoft Visual Studio Code (VS Code) extensions are published to the open-source repository to combat supply chain threats. The move marks a shift from a reactive to a proactive...</description>
        </item>
        <item>
            <title>CISA Adds Actively Exploited SolarWinds Web Help Desk RCE to KEV Catalog</title>
            <link>https://thehackernews.com/2026/02/cisa-adds-actively-exploited-solarwinds.html</link>
            <guid>https://thehackernews.com/2026/02/cisa-adds-actively-exploited-solarwinds.html</guid>
            <pubDate>Wed, 04 Feb 2026 05:50:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/cisa-adds-actively-exploited-solarwinds.html">The Hacker News</source>
            <category>security</category>
            <description>The U.S. Cybersecurity and Infrastructure Security Agency (CISA) on Tuesday added a critical security flaw impacting SolarWinds Web Help Desk (WHD) to its Known Exploited Vulnerabilities (KEV) catalog, flagging it as actively exploited in attacks. The vulnerability, tracked as CVE-2025-40551 (CVSS...</description>
        </item>
        <item>
            <title>POET: Protocol Optimization via Eligibility Tuning</title>
            <link>https://arxiv.org/abs/2602.00370</link>
            <guid>https://arxiv.org/abs/2602.00370</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00370">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00370v1 Announce Type: new Abstract: Eligibility criteria (EC) are essential for clinical trial design, yet drafting them remains a time-intensive and cognitively demanding task for clinicians. Existing automated approaches often fall at two extremes either requiring highly structured...</description>
        </item>
        <item>
            <title>KEPO: Knowledge-Enhanced Preference Optimization for Reinforcement Learning with Reasoning</title>
            <link>https://arxiv.org/abs/2602.00400</link>
            <guid>https://arxiv.org/abs/2602.00400</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00400">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00400v1 Announce Type: new Abstract: Reinforcement learning (RL) has emerged as a promising paradigm for inducing explicit reasoning behaviors in large language and vision-language models. However, reasoning-oriented RL post-training remains fundamentally challenging due to sparse...</description>
        </item>
        <item>
            <title>RobustDebias: Debiasing Language Models using Distributionally Robust Optimization</title>
            <link>https://arxiv.org/abs/2602.00405</link>
            <guid>https://arxiv.org/abs/2602.00405</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00405">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00405v1 Announce Type: new Abstract: Pretrained language models have been shown to exhibit biases and social stereotypes. Prior work on debiasing these models has largely focused on modifying embedding spaces during pretraining, which is not scalable for large models. Fine-tuning...</description>
        </item>
        <item>
            <title>PolarMem: A Training-Free Polarized Latent Graph Memory for Verifiable Multimodal Agents</title>
            <link>https://arxiv.org/abs/2602.00415</link>
            <guid>https://arxiv.org/abs/2602.00415</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00415">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00415v1 Announce Type: new Abstract: As multimodal agents evolve from passive observers to long-horizon decision-makers, they require memory systems that provide not just information availability but logical verifiability. A fundamental limitation of current architectures is the...</description>
        </item>
        <item>
            <title>Do Latent-CoT Models Think Step-by-Step? A Mechanistic Study on Sequential Reasoning Tasks</title>
            <link>https://arxiv.org/abs/2602.00449</link>
            <guid>https://arxiv.org/abs/2602.00449</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00449">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00449v1 Announce Type: new Abstract: Latent Chain-of-Thought (Latent-CoT) aims to enable step-by-step computation without emitting long rationales, yet its mechanisms remain unclear. We study CODI, a continuous-thought teacher-student distillation model, on strictly sequential...</description>
        </item>
        <item>
            <title>UNSO: Unified Newton Schulz Orthogonalization</title>
            <link>https://arxiv.org/abs/2602.02500</link>
            <guid>https://arxiv.org/abs/2602.02500</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02500">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.02500v1 Announce Type: new Abstract: The Newton-Schulz (NS) iteration has gained increasing interest for its role in the Muon optimizer and the Stiefel manifold. However, the conventional NS iteration suffers from inefficiency and instability. Although various improvements have been...</description>
        </item>
        <item>
            <title>Augmenting Parameter-Efficient Pre-trained Language Models with Large Language Models</title>
            <link>https://arxiv.org/abs/2602.02501</link>
            <guid>https://arxiv.org/abs/2602.02501</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02501">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.02501v1 Announce Type: new Abstract: Training AI models in cybersecurity with help of vast datasets offers significant opportunities to mimic real-world behaviors effectively. However, challenges like data drift and scarcity of labelled data lead to frequent updates of models and the...</description>
        </item>
        <item>
            <title>Sparse Adapter Fusion for Continual Learning in NLP</title>
            <link>https://arxiv.org/abs/2602.02502</link>
            <guid>https://arxiv.org/abs/2602.02502</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02502">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.02502v1 Announce Type: new Abstract: Continual learning in natural language processing plays a crucial role in adapting to evolving data and preventing catastrophic forgetting. Despite significant progress, existing methods still face challenges, such as inefficient parameter reuse...</description>
        </item>
        <item>
            <title>Learning ORDER-Aware Multimodal Representations for Composite Materials Design</title>
            <link>https://arxiv.org/abs/2602.02513</link>
            <guid>https://arxiv.org/abs/2602.02513</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02513">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.02513v1 Announce Type: new Abstract: Artificial intelligence (AI) has shown remarkable success in materials discovery and property prediction, particularly for crystalline and polymer systems where material properties and structures are dominated by discrete graph representations. Such...</description>
        </item>
        <item>
            <title>What Drives Length of Stay After Elective Spine Surgery? Insights from a Decade of Predictive Modeling</title>
            <link>https://arxiv.org/abs/2602.02517</link>
            <guid>https://arxiv.org/abs/2602.02517</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02517">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.02517v1 Announce Type: new Abstract: Objective: Predicting length of stay after elective spine surgery is essential for optimizing patient outcomes and hospital resource use. This systematic review synthesizes computational methods used to predict length of stay in this patient...</description>
        </item>
        <item>
            <title>The Hypocrisy Gap: Quantifying Divergence Between Internal Belief and Chain-of-Thought Explanation via Sparse Autoencoders</title>
            <link>https://arxiv.org/abs/2602.02496</link>
            <guid>https://arxiv.org/abs/2602.02496</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02496">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.02496v1 Announce Type: new Abstract: Large Language Models (LLMs) frequently exhibit unfaithful behavior, producing a final answer that differs significantly from their internal chain of thought (CoT) reasoning in order to appease the user they are conversing with. In order to better...</description>
        </item>
        <item>
            <title>STEMVerse: A Dual-Axis Diagnostic Framework for STEM Reasoning in Large Language Models</title>
            <link>https://arxiv.org/abs/2602.02497</link>
            <guid>https://arxiv.org/abs/2602.02497</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02497">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.02497v1 Announce Type: new Abstract: As Large Language Models (LLMs) achieve significant breakthroughs in complex reasoning tasks, evaluating their proficiency in science, technology, engineering, and mathematics (STEM) has become a primary method for measuring machine intelligence....</description>
        </item>
        <item>
            <title>Test-Time Detoxification without Training or Learning Anything</title>
            <link>https://arxiv.org/abs/2602.02498</link>
            <guid>https://arxiv.org/abs/2602.02498</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02498">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.02498v1 Announce Type: new Abstract: Large language models can produce toxic or inappropriate text even for benign inputs, creating risks when deployed at scale. Detoxification is therefore important for safety and user trust, particularly when we want to reduce harmful content without...</description>
        </item>
        <item>
            <title>ROSA-Tuning: Enhancing Long-Context Modeling via Suffix Matching</title>
            <link>https://arxiv.org/abs/2602.02499</link>
            <guid>https://arxiv.org/abs/2602.02499</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02499">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.02499v1 Announce Type: new Abstract: Long-context capability and computational efficiency are among the central challenges facing today&#x27;s large language models. Existing efficient attention methods reduce computational complexity, but they typically suffer from a limited coverage of the...</description>
        </item>
        <item>
            <title>Graph-Augmented Reasoning with Large Language Models for Tobacco Pest and Disease Management</title>
            <link>https://arxiv.org/abs/2602.02635</link>
            <guid>https://arxiv.org/abs/2602.02635</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02635">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.02635v1 Announce Type: new Abstract: This paper proposes a graph-augmented reasoning framework for tobacco pest and disease management that integrates structured domain knowledge into large language models. Building on GraphRAG, we construct a domain-specific knowledge graph and retrieve...</description>
        </item>
        <item>
            <title>[AINews] Context Graphs and Agent Traces</title>
            <link>https://www.latent.space/p/ainews-context-graphs-hype-or-actually</link>
            <guid>https://www.latent.space/p/ainews-context-graphs-hype-or-actually</guid>
            <pubDate>Wed, 04 Feb 2026 03:13:58 +0000</pubDate>
            <source url="https://www.latent.space/p/ainews-context-graphs-hype-or-actually">Latent Space</source>
            <category>open-source</category>
            <description>a quiet day lets us feature a bubbling topic.</description>
        </item>
        <item>
            <title>Some users may experience issues loading or starting conversations</title>
            <link>https://status.openai.com//incidents/01KGK3YJB8CPX0TJY924H02TZW</link>
            <guid>https://status.openai.com//incidents/01KGK3YJB8CPX0TJY924H02TZW</guid>
            <pubDate>Wed, 04 Feb 2026 01:42:51 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KGK3YJB8CPX0TJY924H02TZW">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: MonitoringWe have applied the mitigation and are monitoring the recovery.Affected components Conversations (Degraded performance)</description>
        </item>
        <item>
            <title>Elevated error rates for finetuning jobs</title>
            <link>https://status.openai.com//incidents/01KGJMMMDDYD8RYNEVFNVYG99F</link>
            <guid>https://status.openai.com//incidents/01KGJMMMDDYD8RYNEVFNVYG99F</guid>
            <pubDate>Tue, 03 Feb 2026 23:32:01 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KGJMMMDDYD8RYNEVFNVYG99F">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: ResolvedAll impacted services have now fully recovered.Affected components Fine-tuning (Operational)</description>
        </item>
        <item>
            <title>Elevated errors on Claude Opus 4.5</title>
            <link>https://status.claude.com/incidents/v4v6psj8hkh3</link>
            <guid>https://status.claude.com/incidents/v4v6psj8hkh3</guid>
            <pubDate>Tue, 03 Feb 2026 23:06:21 +0000</pubDate>
            <source url="https://status.claude.com/incidents/v4v6psj8hkh3">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 3, 23:06 UTCResolved - Users experienced errors on Opus 4.5 between 12:08 PM and 2:38 PM PT (20:08 and 22:38 UTC).Feb 3, 21:02 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>Elevated error rates for ChatGPT users</title>
            <link>https://status.openai.com//incidents/01KGJK9Q6PDB3C3VX6MPCY6106</link>
            <guid>https://status.openai.com//incidents/01KGJK9Q6PDB3C3VX6MPCY6106</guid>
            <pubDate>Tue, 03 Feb 2026 20:32:27 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KGJK9Q6PDB3C3VX6MPCY6106">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: IdentifiedWe have identified that users are experiencing elevated errors for the impacted services. We are working on implementing a mitigation.Affected components File uploads (Degraded performance) Voice mode (Degraded performance) Conversations (Degraded performance) Compliance API...</description>
        </item>
        <item>
            <title>SSO and magic link sign-in degraded on Claude Desktop</title>
            <link>https://status.claude.com/incidents/mhxgcgjrjy7k</link>
            <guid>https://status.claude.com/incidents/mhxgcgjrjy7k</guid>
            <pubDate>Tue, 03 Feb 2026 20:30:00 +0000</pubDate>
            <source url="https://status.claude.com/incidents/mhxgcgjrjy7k">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 3, 20:30 UTCResolved - SSO and magic link sign-in degraded on Claude Desktop</description>
        </item>
        <item>
            <title>Elevated error rate establishing new connections to Claude.ai connectors</title>
            <link>https://status.claude.com/incidents/54rr0gbh596p</link>
            <guid>https://status.claude.com/incidents/54rr0gbh596p</guid>
            <pubDate>Tue, 03 Feb 2026 20:26:12 +0000</pubDate>
            <source url="https://status.claude.com/incidents/54rr0gbh596p">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 3, 20:26 UTCMonitoring - A fix has been implemented and we are monitoring the results.Feb 3, 18:42 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>SSO and magic link sign-in degraded on Claude Desktop</title>
            <link>https://status.claude.com/incidents/4z202w15zst2</link>
            <guid>https://status.claude.com/incidents/4z202w15zst2</guid>
            <pubDate>Tue, 03 Feb 2026 20:05:07 +0000</pubDate>
            <source url="https://status.claude.com/incidents/4z202w15zst2">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 3, 20:05 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>Prediction of Critical Heat Flux in Rod Bundles Using Tube-Based Hybrid Machine Learning Models in CTF</title>
            <link>https://tldr.takara.ai/p/2602.03805</link>
            <guid>https://tldr.takara.ai/p/2602.03805</guid>
            <pubDate>Tue, 03 Feb 2026 18:05:16 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.03805">HF Daily Papers</source>
            <category>open-source</category>
            <description>The prediction of critical heat flux (CHF) using machine learning (ML) approaches has become a highly active research activity in recent years, the goal of which is to build models more accurate than current conventional approaches such as empirical correlations or lookup tables (LUTs). Previous...</description>
        </item>
        <item>
            <title>3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation</title>
            <link>https://tldr.takara.ai/p/2602.03796</link>
            <guid>https://tldr.takara.ai/p/2602.03796</guid>
            <pubDate>Tue, 03 Feb 2026 17:59:09 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.03796">HF Daily Papers</source>
            <category>open-source</category>
            <description>Existing methods for human motion control in video generation typically rely on either 2D poses or explicit 3D parametric models (e.g., SMPL) as control signals. However, 2D poses rigidly bind motion to the driving viewpoint, precluding novel-view synthesis. Explicit 3D models, though structurally...</description>
        </item>
        <item>
            <title>H Company&#x27;s new Holo2 model takes the lead in UI Localization</title>
            <link>https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b</link>
            <guid>https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b</guid>
            <pubDate>Tue, 03 Feb 2026 17:40:14 +0000</pubDate>
            <source url="https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
        <item>
            <title>Delays in UI updates for Actions Runs</title>
            <link>https://www.githubstatus.com/incidents/f314nlctbfs5</link>
            <guid>https://www.githubstatus.com/incidents/f314nlctbfs5</guid>
            <pubDate>Tue, 03 Feb 2026 16:51:14 +0000</pubDate>
            <source url="https://www.githubstatus.com/incidents/f314nlctbfs5">GitHub Status</source>
            <category>incidents</category>
            <description>Feb 3, 16:51 UTCUpdate - We&#x27;ve applied a mitigation to improve system throughput and are monitoring for reduced latency for job status updates.Feb 3, 16:10 UTCInvestigating - We are investigating reports of degraded performance for Actions</description>
        </item>
        <item>
            <title>The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+</title>
            <link>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3</link>
            <guid>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3</guid>
            <pubDate>Tue, 03 Feb 2026 15:03:19 +0000</pubDate>
            <source url="https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
        <item>
            <title>Riemannian Neural Optimal Transport</title>
            <link>https://tldr.takara.ai/p/2602.03566</link>
            <guid>https://tldr.takara.ai/p/2602.03566</guid>
            <pubDate>Tue, 03 Feb 2026 14:09:35 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.03566">HF Daily Papers</source>
            <category>open-source</category>
            <description>Computational optimal transport (OT) offers a principled framework for generative modeling. Neural OT methods, which use neural networks to learn an OT map (or potential) from data in an amortized way, can be evaluated out of sample after training, but existing approaches are tailored to Euclidean...</description>
        </item>
        <item>
            <title>Persona Generators: Generating Diverse Synthetic Personas at Scale</title>
            <link>https://tldr.takara.ai/p/2602.03545</link>
            <guid>https://tldr.takara.ai/p/2602.03545</guid>
            <pubDate>Tue, 03 Feb 2026 13:59:03 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.03545">HF Daily Papers</source>
            <category>open-source</category>
            <description>Evaluating AI systems that interact with humans requires understanding their behavior across diverse user populations, but collecting representative human data is often expensive or infeasible, particularly for novel technologies or hypothetical future scenarios. Recent work in Generative...</description>
        </item>
        <item>
            <title>Mitigating Staleness in Asynchronous Pipeline Parallelism via Basis Rotation</title>
            <link>https://tldr.takara.ai/p/2602.03515</link>
            <guid>https://tldr.takara.ai/p/2602.03515</guid>
            <pubDate>Tue, 03 Feb 2026 13:31:51 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.03515">HF Daily Papers</source>
            <category>open-source</category>
            <description>Asynchronous pipeline parallelism maximizes hardware utilization by eliminating the pipeline bubbles inherent in synchronous execution, offering a path toward efficient large-scale distributed training. However, this efficiency gain can be compromised by gradient staleness, where the immediate...</description>
        </item>
        <item>
            <title>The Download: squeezing more metal out of aging mines, and AI’s truth crisis</title>
            <link>https://www.technologyreview.com/2026/02/03/1132105/the-download-squeezing-more-metal-out-of-aging-mines-and-ais-truth-crisis/</link>
            <guid>https://www.technologyreview.com/2026/02/03/1132105/the-download-squeezing-more-metal-out-of-aging-mines-and-ais-truth-crisis/</guid>
            <pubDate>Tue, 03 Feb 2026 13:10:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/03/1132105/the-download-squeezing-more-metal-out-of-aging-mines-and-ais-truth-crisis/">MIT Tech Review AI</source>
            <category>research</category>
            <description>This is today&amp;#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&amp;#8217;s going on in the world of technology. Microbes could extract the metal needed for cleantech In a pine forest on Michigan’s Upper Peninsula, the only active nickel mine in the US is...</description>
        </item>
        <item>
            <title>Training Design for Text-to-Image Models: Lessons from Ablations</title>
            <link>https://huggingface.co/blog/Photoroom/prx-part2</link>
            <guid>https://huggingface.co/blog/Photoroom/prx-part2</guid>
            <pubDate>Tue, 03 Feb 2026 11:25:53 +0000</pubDate>
            <source url="https://huggingface.co/blog/Photoroom/prx-part2">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
    </channel>
</rss>

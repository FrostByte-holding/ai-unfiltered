<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI Unfiltered</title>
        <link>https://ai-unfiltered.com/</link>
        <description>Chinese AI • Open Source • Security • Incidents. Signal, not noise.</description>
        <language>en-us</language>
        <lastBuildDate>Wed, 04 Feb 2026 20:38:35 +0000</lastBuildDate>
        <atom:link href="https://ai-unfiltered.com/rss.xml" rel="self" type="application/rss+xml"/>
        
        <item>
            <title>Why Nvidia builds open models with Bryan Catanzaro</title>
            <link>https://www.interconnects.ai/p/why-nvidia-builds-open-models-with</link>
            <guid>https://www.interconnects.ai/p/why-nvidia-builds-open-models-with</guid>
            <pubDate>Wed, 04 Feb 2026 18:00:28 +0000</pubDate>
            <source url="https://www.interconnects.ai/p/why-nvidia-builds-open-models-with">Interconnects</source>
            <category>open-source</category>
            <description>Interconnects interview #17 on the past, present, and future of the Nemotron project.</description>
        </item>
        <item>
            <title>ChatGPT Availability Impacted</title>
            <link>https://status.openai.com//incidents/01KGMVV926ZSCD1MSDBS07AWYA</link>
            <guid>https://status.openai.com//incidents/01KGMVV926ZSCD1MSDBS07AWYA</guid>
            <pubDate>Wed, 04 Feb 2026 17:43:00 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KGMVV926ZSCD1MSDBS07AWYA">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: MonitoringWe have applied the mitigation and are monitoring the recovery.Affected components File uploads (Operational) GPTs (Operational) Deep Research (Operational) Codex (Operational) Connectors/Apps (Operational) ChatGPT Atlas (Operational) Login (Operational) Voice mode (Operational)...</description>
        </item>
        <item>
            <title>Elevated errors on Claude models</title>
            <link>https://status.claude.com/incidents/pvbysfjjrf8m</link>
            <guid>https://status.claude.com/incidents/pvbysfjjrf8m</guid>
            <pubDate>Wed, 04 Feb 2026 16:53:31 +0000</pubDate>
            <source url="https://status.claude.com/incidents/pvbysfjjrf8m">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 4, 16:53 UTCIdentified - The issue has been identified and a fix is being implemented.Feb 4, 16:39 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3’s Top Model</title>
            <link>https://huggingface.co/blog/nvidia/nemotron-colembed-v2</link>
            <guid>https://huggingface.co/blog/nvidia/nemotron-colembed-v2</guid>
            <pubDate>Wed, 04 Feb 2026 15:00:40 +0000</pubDate>
            <source url="https://huggingface.co/blog/nvidia/nemotron-colembed-v2">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
        <item>
            <title>From guardrails to governance: A CEO’s guide for securing agentic systems</title>
            <link>https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/</link>
            <guid>https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/</guid>
            <pubDate>Wed, 04 Feb 2026 14:00:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/">MIT Tech Review AI</source>
            <category>research</category>
            <description>The previous article in this series, “Rules fail at the prompt, succeed at the boundary,” focused on the first AI-orchestrated espionage campaign and the failure of prompt-level control. This article is the prescription. The question every CEO is now getting from their board is some version of:...</description>
        </item>
        <item>
            <title>The Download: the future of nuclear power plants, and social media-fueled AI hype</title>
            <link>https://www.technologyreview.com/2026/02/04/1132115/the-download-the-future-of-nuclear-power-plants-and-social-media-fueled-ai-hype/</link>
            <guid>https://www.technologyreview.com/2026/02/04/1132115/the-download-the-future-of-nuclear-power-plants-and-social-media-fueled-ai-hype/</guid>
            <pubDate>Wed, 04 Feb 2026 13:10:00 +0000</pubDate>
            <source url="https://www.technologyreview.com/2026/02/04/1132115/the-download-the-future-of-nuclear-power-plants-and-social-media-fueled-ai-hype/">MIT Tech Review AI</source>
            <category>research</category>
            <description>This is today&amp;#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&amp;#8217;s going on in the world of technology. Why AI companies are betting on next-gen nuclear AI is driving unprecedented investment for massive data centers and an energy supply that can...</description>
        </item>
        <item>
            <title>Custom GPT updates are failing for users</title>
            <link>https://status.openai.com//incidents/01KGMAYN6EHDVR9KB1CQJP4EGR</link>
            <guid>https://status.openai.com//incidents/01KGMAYN6EHDVR9KB1CQJP4EGR</guid>
            <pubDate>Wed, 04 Feb 2026 12:45:05 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KGMAYN6EHDVR9KB1CQJP4EGR">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: InvestigatingWe are investigating reports of update failures for configuration for Custom GPTs.Affected components GPTs (Degraded performance)</description>
        </item>
        <item>
            <title>Varonis Acquisition of AllTrue.ai Valued at $150 Million</title>
            <link>https://www.securityweek.com/varonis-acquisition-of-alltrue-ai-valued-at-150-million/</link>
            <guid>https://www.securityweek.com/varonis-acquisition-of-alltrue-ai-valued-at-150-million/</guid>
            <pubDate>Wed, 04 Feb 2026 12:39:56 +0000</pubDate>
            <source url="https://www.securityweek.com/varonis-acquisition-of-alltrue-ai-valued-at-150-million/">Security Week</source>
            <category>security</category>
            <description>The data security firm has acquired the AI trust, risk, and security management company to expand its capabilities. The post Varonis Acquisition of AllTrue.ai Valued at $150 Million appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Orion Raises $32 Million for Data Security</title>
            <link>https://www.securityweek.com/orion-raises-32-million-for-data-security/</link>
            <guid>https://www.securityweek.com/orion-raises-32-million-for-data-security/</guid>
            <pubDate>Wed, 04 Feb 2026 12:07:13 +0000</pubDate>
            <source url="https://www.securityweek.com/orion-raises-32-million-for-data-security/">Security Week</source>
            <category>security</category>
            <description>The startup will use the funding to accelerate product development and go-to-market operations. The post Orion Raises $32 Million for Data Security appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Orchid Security Introduces Continuous Identity Observability for Enterprise Applications</title>
            <link>https://thehackernews.com/2026/02/orchid-security-introduces-continuous.html</link>
            <guid>https://thehackernews.com/2026/02/orchid-security-introduces-continuous.html</guid>
            <pubDate>Wed, 04 Feb 2026 11:58:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/orchid-security-introduces-continuous.html">The Hacker News</source>
            <category>security</category>
            <description>An innovative approach to discovering, analyzing, and governing identity usage beyond traditional IAM controls. The Challenge: Identity Lives Outside the Identity Stack Identity and access management tools were built to govern users and directories. Modern enterprises run on applications. Over...</description>
        </item>
        <item>
            <title>DockerDash Flaw in Docker AI Assistant Leads to RCE, Data Theft</title>
            <link>https://www.securityweek.com/dockerdash-flaw-in-docker-ai-assistant-leads-to-rce-data-theft/</link>
            <guid>https://www.securityweek.com/dockerdash-flaw-in-docker-ai-assistant-leads-to-rce-data-theft/</guid>
            <pubDate>Wed, 04 Feb 2026 11:34:55 +0000</pubDate>
            <source url="https://www.securityweek.com/dockerdash-flaw-in-docker-ai-assistant-leads-to-rce-data-theft/">Security Week</source>
            <category>security</category>
            <description>The critical vulnerability exists in the contextual trust in MCP Gateway architecture, as instructions are passed without validation. The post DockerDash Flaw in Docker AI Assistant Leads to RCE, Data Theft appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Elevated errors on Claude Opus 4.5 and Sonnet 4.5</title>
            <link>https://status.claude.com/incidents/vcsmyx922y7z</link>
            <guid>https://status.claude.com/incidents/vcsmyx922y7z</guid>
            <pubDate>Wed, 04 Feb 2026 11:11:13 +0000</pubDate>
            <source url="https://status.claude.com/incidents/vcsmyx922y7z">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 4, 11:11 UTCResolved - The issue hs been fully resolved. The timelines are:* 02:00 PT / 10:00 UTC to 02:35 PT / 10:35 UTC* 02:54 PT / 10:54 UTC to 03:01 PT / 11:01 UTCFeb 4, 11:05 UTCMonitoring - A fix has been implemented and we are monitoring the results.Feb 4, 10:59 UTCIdentified - The issue...</description>
        </item>
        <item>
            <title>Cryptominers, Reverse Shells Dropped in Recent React2Shell Attacks</title>
            <link>https://www.securityweek.com/cryptominers-reverse-shells-dropped-in-recent-react2shell-attacks/</link>
            <guid>https://www.securityweek.com/cryptominers-reverse-shells-dropped-in-recent-react2shell-attacks/</guid>
            <pubDate>Wed, 04 Feb 2026 10:00:14 +0000</pubDate>
            <source url="https://www.securityweek.com/cryptominers-reverse-shells-dropped-in-recent-react2shell-attacks/">Security Week</source>
            <category>security</category>
            <description>Two IP addresses accounted for the majority of the 1.4 million exploitation attempts observed over the past week. The post Cryptominers, Reverse Shells Dropped in Recent React2Shell Attacks appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>The First 90 Seconds: How Early Decisions Shape Incident Response Investigations</title>
            <link>https://thehackernews.com/2026/02/the-first-90-seconds-how-early.html</link>
            <guid>https://thehackernews.com/2026/02/the-first-90-seconds-how-early.html</guid>
            <pubDate>Wed, 04 Feb 2026 10:00:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/the-first-90-seconds-how-early.html">The Hacker News</source>
            <category>security</category>
            <description>Many incident response failures do not come from a lack of tools, intelligence, or technical skills. They come from what happens immediately after detection, when pressure is high, and information is incomplete. I have seen IR teams recover from sophisticated intrusions with limited telemetry. I...</description>
        </item>
        <item>
            <title>Security Analysis of Moltbook Agent Network: Bot-to-Bot Prompt Injection and Data Leaks</title>
            <link>https://www.securityweek.com/security-analysis-of-moltbook-agent-network-bot-to-bot-prompt-injection-and-data-leaks/</link>
            <guid>https://www.securityweek.com/security-analysis-of-moltbook-agent-network-bot-to-bot-prompt-injection-and-data-leaks/</guid>
            <pubDate>Wed, 04 Feb 2026 08:43:18 +0000</pubDate>
            <source url="https://www.securityweek.com/security-analysis-of-moltbook-agent-network-bot-to-bot-prompt-injection-and-data-leaks/">Security Week</source>
            <category>security</category>
            <description>Wiz and Permiso have analyzed the AI agent social network and found serious security issues and threats. The post Security Analysis of Moltbook Agent Network: Bot-to-Bot Prompt Injection and Data Leaks appeared first on SecurityWeek.</description>
        </item>
        <item>
            <title>Mixue Ice Cream &amp; Tea Recruits Theme Park Roles</title>
            <link>https://pandaily.com/mixue-ice-cream-and-tea-recruits-theme-park-roles</link>
            <guid>https://pandaily.com/mixue-ice-cream-and-tea-recruits-theme-park-roles</guid>
            <pubDate>Wed, 04 Feb 2026 08:19:55 +0000</pubDate>
            <source url="https://pandaily.com/mixue-ice-cream-and-tea-recruits-theme-park-roles">Pandaily</source>
            <category>chinese-ai</category>
            <description>Mixue Ice Cream &amp; Tea is hiring multiple theme park roles with salaries starting at RMB 11,000, sparking speculation that the beverage giant may be planning its own branded amusement park.</description>
        </item>
        <item>
            <title>Former TuSimple Unveils First Gameplay PV After Pivot to Gaming</title>
            <link>https://pandaily.com/former-tu-simple-unveils-first-gameplay-pv-after-pivot-to-gaming</link>
            <guid>https://pandaily.com/former-tu-simple-unveils-first-gameplay-pv-after-pivot-to-gaming</guid>
            <pubDate>Wed, 04 Feb 2026 08:17:20 +0000</pubDate>
            <source url="https://pandaily.com/former-tu-simple-unveils-first-gameplay-pv-after-pivot-to-gaming">Pandaily</source>
            <category>chinese-ai</category>
            <description>Former autonomous driving company TuSimple has revealed the first real gameplay footage of its Legend of the Condor Heroes AAA RPG, marking a major step in its pivot to gaming.</description>
        </item>
        <item>
            <title>XPeng Merges Autonomous Driving and Smart Cockpit Units to Form General AI Center</title>
            <link>https://pandaily.com/x-peng-merges-autonomous-driving-and-smart-cockpit-units-to-form-general-ai-center</link>
            <guid>https://pandaily.com/x-peng-merges-autonomous-driving-and-smart-cockpit-units-to-form-general-ai-center</guid>
            <pubDate>Wed, 04 Feb 2026 08:17:16 +0000</pubDate>
            <source url="https://pandaily.com/x-peng-merges-autonomous-driving-and-smart-cockpit-units-to-form-general-ai-center">Pandaily</source>
            <category>chinese-ai</category>
            <description>XPeng has merged its autonomous driving and smart cockpit teams into a General AI Center, accelerating its push toward embodied intelligence across cars and robots.</description>
        </item>
        <item>
            <title>SJTU–Tsinghua Team Builds Edge AI Leader SiMMIR, Secures Two Nine-Figure RMB Funding Rounds</title>
            <link>https://pandaily.com/sjtu-tsinghua-team-builds-edge-ai-leader-si-mmir-secures-two-nine-figure-rmb-funding-rounds</link>
            <guid>https://pandaily.com/sjtu-tsinghua-team-builds-edge-ai-leader-si-mmir-secures-two-nine-figure-rmb-funding-rounds</guid>
            <pubDate>Wed, 04 Feb 2026 08:17:10 +0000</pubDate>
            <source url="https://pandaily.com/sjtu-tsinghua-team-builds-edge-ai-leader-si-mmir-secures-two-nine-figure-rmb-funding-rounds">Pandaily</source>
            <category>chinese-ai</category>
            <description>Edge AI startup SiMMIR has raised over RMB 100 million in back-to-back funding rounds, betting on integrated sensing–computing chips to power the next wave of physical AI.</description>
        </item>
        <item>
            <title>Tencent Launches “Fire Dragon,” Its First AI-Generated Comic Shorts App</title>
            <link>https://pandaily.com/tencent-launches-fire-dragon-its-first-ai-generated-comic-shorts-app</link>
            <guid>https://pandaily.com/tencent-launches-fire-dragon-its-first-ai-generated-comic-shorts-app</guid>
            <pubDate>Wed, 04 Feb 2026 08:17:02 +0000</pubDate>
            <source url="https://pandaily.com/tencent-launches-fire-dragon-its-first-ai-generated-comic-shorts-app">Pandaily</source>
            <category>chinese-ai</category>
            <description>Tencent has launched Fire Dragon, its first AI-generated comic shorts app, signaling a push into short, vertical storytelling aimed squarely at Gen Z.</description>
        </item>
        <item>
            <title>Microsoft Warns Python Infostealers Target macOS via Fake Ads and Installers</title>
            <link>https://thehackernews.com/2026/02/microsoft-warns-python-infostealers.html</link>
            <guid>https://thehackernews.com/2026/02/microsoft-warns-python-infostealers.html</guid>
            <pubDate>Wed, 04 Feb 2026 07:42:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/microsoft-warns-python-infostealers.html">The Hacker News</source>
            <category>security</category>
            <description>Microsoft has warned that information-stealing attacks are &quot;rapidly expanding&quot; beyond Windows to target Apple macOS environments by leveraging cross-platform languages like Python and abusing trusted platforms for distribution at scale. The tech giant&#x27;s Defender Security Research Team said it...</description>
        </item>
        <item>
            <title>Eclipse Foundation Mandates Pre-Publish Security Checks for Open VSX Extensions</title>
            <link>https://thehackernews.com/2026/02/eclipse-foundation-mandates-pre-publish.html</link>
            <guid>https://thehackernews.com/2026/02/eclipse-foundation-mandates-pre-publish.html</guid>
            <pubDate>Wed, 04 Feb 2026 06:26:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/eclipse-foundation-mandates-pre-publish.html">The Hacker News</source>
            <category>security</category>
            <description>The Eclipse Foundation, which maintains the Open VSX Registry, has announced plans to enforce security checks before Microsoft Visual Studio Code (VS Code) extensions are published to the open-source repository to combat supply chain threats. The move marks a shift from a reactive to a proactive...</description>
        </item>
        <item>
            <title>CISA Adds Actively Exploited SolarWinds Web Help Desk RCE to KEV Catalog</title>
            <link>https://thehackernews.com/2026/02/cisa-adds-actively-exploited-solarwinds.html</link>
            <guid>https://thehackernews.com/2026/02/cisa-adds-actively-exploited-solarwinds.html</guid>
            <pubDate>Wed, 04 Feb 2026 05:50:00 +0000</pubDate>
            <source url="https://thehackernews.com/2026/02/cisa-adds-actively-exploited-solarwinds.html">The Hacker News</source>
            <category>security</category>
            <description>The U.S. Cybersecurity and Infrastructure Security Agency (CISA) on Tuesday added a critical security flaw impacting SolarWinds Web Help Desk (WHD) to its Known Exploited Vulnerabilities (KEV) catalog, flagging it as actively exploited in attacks. The vulnerability, tracked as CVE-2025-40551 (CVSS...</description>
        </item>
        <item>
            <title>POET: Protocol Optimization via Eligibility Tuning</title>
            <link>https://arxiv.org/abs/2602.00370</link>
            <guid>https://arxiv.org/abs/2602.00370</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00370">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00370v1 Announce Type: new Abstract: Eligibility criteria (EC) are essential for clinical trial design, yet drafting them remains a time-intensive and cognitively demanding task for clinicians. Existing automated approaches often fall at two extremes either requiring highly structured...</description>
        </item>
        <item>
            <title>KEPO: Knowledge-Enhanced Preference Optimization for Reinforcement Learning with Reasoning</title>
            <link>https://arxiv.org/abs/2602.00400</link>
            <guid>https://arxiv.org/abs/2602.00400</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00400">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00400v1 Announce Type: new Abstract: Reinforcement learning (RL) has emerged as a promising paradigm for inducing explicit reasoning behaviors in large language and vision-language models. However, reasoning-oriented RL post-training remains fundamentally challenging due to sparse...</description>
        </item>
        <item>
            <title>RobustDebias: Debiasing Language Models using Distributionally Robust Optimization</title>
            <link>https://arxiv.org/abs/2602.00405</link>
            <guid>https://arxiv.org/abs/2602.00405</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00405">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00405v1 Announce Type: new Abstract: Pretrained language models have been shown to exhibit biases and social stereotypes. Prior work on debiasing these models has largely focused on modifying embedding spaces during pretraining, which is not scalable for large models. Fine-tuning...</description>
        </item>
        <item>
            <title>PolarMem: A Training-Free Polarized Latent Graph Memory for Verifiable Multimodal Agents</title>
            <link>https://arxiv.org/abs/2602.00415</link>
            <guid>https://arxiv.org/abs/2602.00415</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00415">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00415v1 Announce Type: new Abstract: As multimodal agents evolve from passive observers to long-horizon decision-makers, they require memory systems that provide not just information availability but logical verifiability. A fundamental limitation of current architectures is the...</description>
        </item>
        <item>
            <title>Do Latent-CoT Models Think Step-by-Step? A Mechanistic Study on Sequential Reasoning Tasks</title>
            <link>https://arxiv.org/abs/2602.00449</link>
            <guid>https://arxiv.org/abs/2602.00449</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.00449">arXiv AI</source>
            <category>research</category>
            <description>arXiv:2602.00449v1 Announce Type: new Abstract: Latent Chain-of-Thought (Latent-CoT) aims to enable step-by-step computation without emitting long rationales, yet its mechanisms remain unclear. We study CODI, a continuous-thought teacher-student distillation model, on strictly sequential...</description>
        </item>
        <item>
            <title>UNSO: Unified Newton Schulz Orthogonalization</title>
            <link>https://arxiv.org/abs/2602.02500</link>
            <guid>https://arxiv.org/abs/2602.02500</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02500">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.02500v1 Announce Type: new Abstract: The Newton-Schulz (NS) iteration has gained increasing interest for its role in the Muon optimizer and the Stiefel manifold. However, the conventional NS iteration suffers from inefficiency and instability. Although various improvements have been...</description>
        </item>
        <item>
            <title>Augmenting Parameter-Efficient Pre-trained Language Models with Large Language Models</title>
            <link>https://arxiv.org/abs/2602.02501</link>
            <guid>https://arxiv.org/abs/2602.02501</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02501">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.02501v1 Announce Type: new Abstract: Training AI models in cybersecurity with help of vast datasets offers significant opportunities to mimic real-world behaviors effectively. However, challenges like data drift and scarcity of labelled data lead to frequent updates of models and the...</description>
        </item>
        <item>
            <title>Sparse Adapter Fusion for Continual Learning in NLP</title>
            <link>https://arxiv.org/abs/2602.02502</link>
            <guid>https://arxiv.org/abs/2602.02502</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02502">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.02502v1 Announce Type: new Abstract: Continual learning in natural language processing plays a crucial role in adapting to evolving data and preventing catastrophic forgetting. Despite significant progress, existing methods still face challenges, such as inefficient parameter reuse...</description>
        </item>
        <item>
            <title>Learning ORDER-Aware Multimodal Representations for Composite Materials Design</title>
            <link>https://arxiv.org/abs/2602.02513</link>
            <guid>https://arxiv.org/abs/2602.02513</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02513">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.02513v1 Announce Type: new Abstract: Artificial intelligence (AI) has shown remarkable success in materials discovery and property prediction, particularly for crystalline and polymer systems where material properties and structures are dominated by discrete graph representations. Such...</description>
        </item>
        <item>
            <title>What Drives Length of Stay After Elective Spine Surgery? Insights from a Decade of Predictive Modeling</title>
            <link>https://arxiv.org/abs/2602.02517</link>
            <guid>https://arxiv.org/abs/2602.02517</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02517">arXiv Machine Learning</source>
            <category>research</category>
            <description>arXiv:2602.02517v1 Announce Type: new Abstract: Objective: Predicting length of stay after elective spine surgery is essential for optimizing patient outcomes and hospital resource use. This systematic review synthesizes computational methods used to predict length of stay in this patient...</description>
        </item>
        <item>
            <title>The Hypocrisy Gap: Quantifying Divergence Between Internal Belief and Chain-of-Thought Explanation via Sparse Autoencoders</title>
            <link>https://arxiv.org/abs/2602.02496</link>
            <guid>https://arxiv.org/abs/2602.02496</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02496">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.02496v1 Announce Type: new Abstract: Large Language Models (LLMs) frequently exhibit unfaithful behavior, producing a final answer that differs significantly from their internal chain of thought (CoT) reasoning in order to appease the user they are conversing with. In order to better...</description>
        </item>
        <item>
            <title>STEMVerse: A Dual-Axis Diagnostic Framework for STEM Reasoning in Large Language Models</title>
            <link>https://arxiv.org/abs/2602.02497</link>
            <guid>https://arxiv.org/abs/2602.02497</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02497">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.02497v1 Announce Type: new Abstract: As Large Language Models (LLMs) achieve significant breakthroughs in complex reasoning tasks, evaluating their proficiency in science, technology, engineering, and mathematics (STEM) has become a primary method for measuring machine intelligence....</description>
        </item>
        <item>
            <title>Test-Time Detoxification without Training or Learning Anything</title>
            <link>https://arxiv.org/abs/2602.02498</link>
            <guid>https://arxiv.org/abs/2602.02498</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02498">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.02498v1 Announce Type: new Abstract: Large language models can produce toxic or inappropriate text even for benign inputs, creating risks when deployed at scale. Detoxification is therefore important for safety and user trust, particularly when we want to reduce harmful content without...</description>
        </item>
        <item>
            <title>ROSA-Tuning: Enhancing Long-Context Modeling via Suffix Matching</title>
            <link>https://arxiv.org/abs/2602.02499</link>
            <guid>https://arxiv.org/abs/2602.02499</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02499">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.02499v1 Announce Type: new Abstract: Long-context capability and computational efficiency are among the central challenges facing today&#x27;s large language models. Existing efficient attention methods reduce computational complexity, but they typically suffer from a limited coverage of the...</description>
        </item>
        <item>
            <title>Graph-Augmented Reasoning with Large Language Models for Tobacco Pest and Disease Management</title>
            <link>https://arxiv.org/abs/2602.02635</link>
            <guid>https://arxiv.org/abs/2602.02635</guid>
            <pubDate>Wed, 04 Feb 2026 05:00:00 +0000</pubDate>
            <source url="https://arxiv.org/abs/2602.02635">arXiv NLP</source>
            <category>research</category>
            <description>arXiv:2602.02635v1 Announce Type: new Abstract: This paper proposes a graph-augmented reasoning framework for tobacco pest and disease management that integrates structured domain knowledge into large language models. Building on GraphRAG, we construct a domain-specific knowledge graph and retrieve...</description>
        </item>
        <item>
            <title>[AINews] Context Graphs and Agent Traces</title>
            <link>https://www.latent.space/p/ainews-context-graphs-hype-or-actually</link>
            <guid>https://www.latent.space/p/ainews-context-graphs-hype-or-actually</guid>
            <pubDate>Wed, 04 Feb 2026 03:13:58 +0000</pubDate>
            <source url="https://www.latent.space/p/ainews-context-graphs-hype-or-actually">Latent Space</source>
            <category>open-source</category>
            <description>a quiet day lets us feature a bubbling topic.</description>
        </item>
        <item>
            <title>Some users may experience issues loading or starting conversations</title>
            <link>https://status.openai.com//incidents/01KGK3YJB8CPX0TJY924H02TZW</link>
            <guid>https://status.openai.com//incidents/01KGK3YJB8CPX0TJY924H02TZW</guid>
            <pubDate>Wed, 04 Feb 2026 01:42:51 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KGK3YJB8CPX0TJY924H02TZW">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: MonitoringWe have applied the mitigation and are monitoring the recovery.Affected components Conversations (Degraded performance)</description>
        </item>
        <item>
            <title>Elevated error rates for finetuning jobs</title>
            <link>https://status.openai.com//incidents/01KGJMMMDDYD8RYNEVFNVYG99F</link>
            <guid>https://status.openai.com//incidents/01KGJMMMDDYD8RYNEVFNVYG99F</guid>
            <pubDate>Tue, 03 Feb 2026 23:32:01 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KGJMMMDDYD8RYNEVFNVYG99F">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: ResolvedAll impacted services have now fully recovered.Affected components Fine-tuning (Operational)</description>
        </item>
        <item>
            <title>Elevated errors on Claude Opus 4.5</title>
            <link>https://status.claude.com/incidents/v4v6psj8hkh3</link>
            <guid>https://status.claude.com/incidents/v4v6psj8hkh3</guid>
            <pubDate>Tue, 03 Feb 2026 23:06:21 +0000</pubDate>
            <source url="https://status.claude.com/incidents/v4v6psj8hkh3">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 3, 23:06 UTCResolved - Users experienced errors on Opus 4.5 between 12:08 PM and 2:38 PM PT (20:08 and 22:38 UTC).Feb 3, 21:02 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>Elevated error rates for ChatGPT users</title>
            <link>https://status.openai.com//incidents/01KGJK9Q6PDB3C3VX6MPCY6106</link>
            <guid>https://status.openai.com//incidents/01KGJK9Q6PDB3C3VX6MPCY6106</guid>
            <pubDate>Tue, 03 Feb 2026 20:32:27 +0000</pubDate>
            <source url="https://status.openai.com//incidents/01KGJK9Q6PDB3C3VX6MPCY6106">OpenAI Status</source>
            <category>incidents</category>
            <description>Status: IdentifiedWe have identified that users are experiencing elevated errors for the impacted services. We are working on implementing a mitigation.Affected components File uploads (Degraded performance) Voice mode (Degraded performance) Conversations (Degraded performance) Compliance API...</description>
        </item>
        <item>
            <title>SSO and magic link sign-in degraded on Claude Desktop</title>
            <link>https://status.claude.com/incidents/mhxgcgjrjy7k</link>
            <guid>https://status.claude.com/incidents/mhxgcgjrjy7k</guid>
            <pubDate>Tue, 03 Feb 2026 20:30:00 +0000</pubDate>
            <source url="https://status.claude.com/incidents/mhxgcgjrjy7k">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 3, 20:30 UTCResolved - SSO and magic link sign-in degraded on Claude Desktop</description>
        </item>
        <item>
            <title>Elevated error rate establishing new connections to Claude.ai connectors</title>
            <link>https://status.claude.com/incidents/54rr0gbh596p</link>
            <guid>https://status.claude.com/incidents/54rr0gbh596p</guid>
            <pubDate>Tue, 03 Feb 2026 20:26:12 +0000</pubDate>
            <source url="https://status.claude.com/incidents/54rr0gbh596p">Anthropic Status</source>
            <category>incidents</category>
            <description>Feb 3, 20:26 UTCMonitoring - A fix has been implemented and we are monitoring the results.Feb 3, 18:42 UTCInvestigating - We are currently investigating this issue.</description>
        </item>
        <item>
            <title>Continuous Control of Editing Models via Adaptive-Origin Guidance</title>
            <link>https://tldr.takara.ai/p/2602.03826</link>
            <guid>https://tldr.takara.ai/p/2602.03826</guid>
            <pubDate>Tue, 03 Feb 2026 18:33:39 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.03826">HF Daily Papers</source>
            <category>open-source</category>
            <description>Diffusion-based editing models have emerged as a powerful tool for semantic image and video manipulation. However, existing models lack a mechanism for smoothly controlling the intensity of text-guided edits. In standard text-conditioned generation, Classifier-Free Guidance (CFG) impacts prompt...</description>
        </item>
        <item>
            <title>Conformal Thinking: Risk Control for Reasoning on a Compute Budget</title>
            <link>https://tldr.takara.ai/p/2602.03814</link>
            <guid>https://tldr.takara.ai/p/2602.03814</guid>
            <pubDate>Tue, 03 Feb 2026 18:17:22 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.03814">HF Daily Papers</source>
            <category>open-source</category>
            <description>Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting...</description>
        </item>
        <item>
            <title>Prediction of Critical Heat Flux in Rod Bundles Using Tube-Based Hybrid Machine Learning Models in CTF</title>
            <link>https://tldr.takara.ai/p/2602.03805</link>
            <guid>https://tldr.takara.ai/p/2602.03805</guid>
            <pubDate>Tue, 03 Feb 2026 18:05:16 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.03805">HF Daily Papers</source>
            <category>open-source</category>
            <description>The prediction of critical heat flux (CHF) using machine learning (ML) approaches has become a highly active research activity in recent years, the goal of which is to build models more accurate than current conventional approaches such as empirical correlations or lookup tables (LUTs). Previous...</description>
        </item>
        <item>
            <title>3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation</title>
            <link>https://tldr.takara.ai/p/2602.03796</link>
            <guid>https://tldr.takara.ai/p/2602.03796</guid>
            <pubDate>Tue, 03 Feb 2026 17:59:09 +0000</pubDate>
            <source url="https://tldr.takara.ai/p/2602.03796">HF Daily Papers</source>
            <category>open-source</category>
            <description>Existing methods for human motion control in video generation typically rely on either 2D poses or explicit 3D parametric models (e.g., SMPL) as control signals. However, 2D poses rigidly bind motion to the driving viewpoint, precluding novel-view synthesis. Explicit 3D models, though structurally...</description>
        </item>
        <item>
            <title>H Company&#x27;s new Holo2 model takes the lead in UI Localization</title>
            <link>https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b</link>
            <guid>https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b</guid>
            <pubDate>Tue, 03 Feb 2026 17:40:14 +0000</pubDate>
            <source url="https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b">Hugging Face Blog</source>
            <category>open-source</category>
            <description></description>
        </item>
    </channel>
</rss>
